{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install ultralytics"
      ],
      "metadata": {
        "id": "VLySZuVvEVbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e45f96a-c9d1-4d5d-91b6-0d663f90c79e"
      },
      "id": "VLySZuVvEVbZ",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.81-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.5-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.81-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.4/869.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ultralytics_thop-2.0.5-py3-none-any.whl (25 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.81 ultralytics-thop-2.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Push-Ups**"
      ],
      "metadata": {
        "id": "ROl-udVDPDls"
      },
      "id": "ROl-udVDPDls"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 Pose model\n",
        "model = YOLO('yolov8n-pose.pt')  # or 'yolov8x-pose.pt' for a larger model\n",
        "video_path = '/content/pushup.mp4'  # Path to your input video\n",
        "out_path = 'results_pushUp.mp4'  # Path to save the output video\n",
        "\n",
        "def calculate_angle(p1, p2, p3):\n",
        "    \"\"\" Calculate the angle between three points. \"\"\"\n",
        "    a = np.array(p1)\n",
        "    b = np.array(p2)\n",
        "    c = np.array(p3)\n",
        "    ab = a - b\n",
        "    bc = c - b\n",
        "    angle = np.arccos(np.clip(np.dot(ab, bc) / (np.linalg.norm(ab) * np.linalg.norm(bc)), -1.0, 1.0))\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def draw_keypoints(frame, keypoints, indices):\n",
        "    \"\"\" Draw specific keypoints on the frame. \"\"\"\n",
        "    for i in indices:\n",
        "        point = keypoints[i]\n",
        "        cv2.circle(frame, tuple(map(int, point)), 10, (255, 0, 0), -1)  # Blue points for selected keypoints\n",
        "\n",
        "def draw_connections(frame, keypoints, connections):\n",
        "    \"\"\" Draw lines between specific keypoints to visualize connections. \"\"\"\n",
        "    for start_idx, end_idx in connections:\n",
        "        start_point = tuple(map(int, keypoints[start_idx]))\n",
        "        end_point = tuple(map(int, keypoints[end_idx]))\n",
        "        cv2.line(frame, start_point, end_point, (0, 255, 0), 5)  # Green lines for connections\n",
        "\n",
        "def main():\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Initialize VideoWriter\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'mp4v' for .mp4 format\n",
        "    out = cv2.VideoWriter(out_path, fourcc, fps, (640, 384))  # Output video resolution\n",
        "\n",
        "    push_up_count = 0\n",
        "    push_up_state = \"up\"\n",
        "\n",
        "    # Define connections based on specific pose estimation keypoints (shoulder, elbow, and wrist)\n",
        "    connections = [\n",
        "        (5, 7),  # Shoulder to Elbow\n",
        "        (7, 9),  # Elbow to Wrist\n",
        "    ]\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Resize the frame to (640, 384)\n",
        "        frame_resized = cv2.resize(frame, (640, 384))\n",
        "\n",
        "        # Preprocess frame for YOLOv8 Pose\n",
        "        results = model(frame_resized)\n",
        "\n",
        "        print(results[0].keypoints)\n",
        "\n",
        "        # Extract keypoints\n",
        "        keypoints = np.array(results[0].keypoints.xy.tolist()).reshape(-1, 2)  # Assuming keypoints are in the first result\n",
        "        if len(keypoints) >= 10:\n",
        "            # Extract keypoints (assuming order is shoulder, elbow, and wrist)\n",
        "            shoulder = keypoints[5]\n",
        "            elbow = keypoints[7]\n",
        "            wrist = keypoints[9]\n",
        "\n",
        "            angle = calculate_angle(shoulder, elbow, wrist)\n",
        "\n",
        "            # Determine push-up state based on angle\n",
        "            if angle < 80:  # Adjust angle threshold based on your observation\n",
        "                if push_up_state == \"up\":\n",
        "                    push_up_count += 1\n",
        "                    push_up_state = \"down\"\n",
        "            elif angle > 150:  # Adjust angle threshold based on your observation\n",
        "                if push_up_state == \"down\":\n",
        "                    push_up_state = \"up\"\n",
        "\n",
        "            # Draw only the shoulder, elbow, and wrist keypoints\n",
        "            draw_keypoints(frame_resized, keypoints, [5, 7, 9])\n",
        "\n",
        "            # Draw connections between shoulder, elbow, and wrist\n",
        "            draw_connections(frame_resized, keypoints, connections)\n",
        "\n",
        "            # Display the angle on the frame\n",
        "            cv2.putText(frame_resized, f\"Angle: {angle:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Display the count and state on the frame\n",
        "        cv2.putText(frame_resized, f\"Push-ups: {push_up_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv2.LINE_AA)\n",
        "        cv2.putText(frame_resized, f\"State: {push_up_state}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Write the frame to the output video\n",
        "        out.write(frame_resized)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPIMwb5ietK7",
        "outputId": "9ecf6955-765a-4955-be82-098e9531961b"
      },
      "id": "FPIMwb5ietK7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6.52M/6.52M [00:00<00:00, 103MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         [ 98.2861, 243.2795],\n",
            "         [ 78.9965, 213.0467]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7881, 0.3247],\n",
            "         [0.7968, 0.3108],\n",
            "         [0.7900, 0.2881],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7587, 0.2089],\n",
            "         [0.7195, 0.2646],\n",
            "         [0.6715, 0.2549],\n",
            "         [0.6593, 0.4499],\n",
            "         [0.6275, 0.5404],\n",
            "         [0.6521, 0.6768],\n",
            "         [0.6249, 0.7576],\n",
            "         [0.4674, 0.4028],\n",
            "         [0.4349, 0.3557],\n",
            "         [0.3651, 0.5605],\n",
            "         [0.3059, 0.4855],\n",
            "         [0.1536, 0.6335],\n",
            "         [0.1234, 0.5548]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.4ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9672, 0.5848, 0.9730, 0.1030, 0.9552, 0.9685, 0.9988, 0.8326, 0.9971, 0.7162, 0.9719, 0.9914, 0.9976, 0.9513, 0.9847, 0.7868, 0.8723]], device='cuda:0')\n",
            "data: tensor([[[5.0302e+02, 1.2372e+02, 9.6723e-01],\n",
            "         [5.0801e+02, 1.1868e+02, 5.8481e-01],\n",
            "         [5.0455e+02, 1.0990e+02, 9.7301e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.0303e-01],\n",
            "         [4.8545e+02, 7.8708e+01, 9.5518e-01],\n",
            "         [4.5984e+02, 1.0037e+02, 9.6847e-01],\n",
            "         [4.2962e+02, 9.4832e+01, 9.9876e-01],\n",
            "         [4.2216e+02, 1.7316e+02, 8.3259e-01],\n",
            "         [4.0272e+02, 2.0462e+02, 9.9714e-01],\n",
            "         [4.1616e+02, 2.5660e+02, 7.1625e-01],\n",
            "         [4.0100e+02, 2.8740e+02, 9.7190e-01],\n",
            "         [2.9633e+02, 1.5428e+02, 9.9139e-01],\n",
            "         [2.7650e+02, 1.3473e+02, 9.9757e-01],\n",
            "         [2.2584e+02, 2.1890e+02, 9.5130e-01],\n",
            "         [1.9254e+02, 1.8719e+02, 9.8473e-01],\n",
            "         [8.9090e+01, 2.4576e+02, 7.8680e-01],\n",
            "         [7.6123e+01, 2.1189e+02, 8.7235e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[503.0229, 123.7160],\n",
            "         [508.0055, 118.6751],\n",
            "         [504.5526, 109.8965],\n",
            "         [  0.0000,   0.0000],\n",
            "         [485.4479,  78.7076],\n",
            "         [459.8423, 100.3717],\n",
            "         [429.6155,  94.8318],\n",
            "         [422.1605, 173.1577],\n",
            "         [402.7157, 204.6167],\n",
            "         [416.1618, 256.5971],\n",
            "         [400.9979, 287.3965],\n",
            "         [296.3311, 154.2752],\n",
            "         [276.4981, 134.7310],\n",
            "         [225.8387, 218.9008],\n",
            "         [192.5390, 187.1934],\n",
            "         [ 89.0904, 245.7604],\n",
            "         [ 76.1226, 211.8904]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7860, 0.3222],\n",
            "         [0.7938, 0.3090],\n",
            "         [0.7884, 0.2862],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7585, 0.2050],\n",
            "         [0.7185, 0.2614],\n",
            "         [0.6713, 0.2470],\n",
            "         [0.6596, 0.4509],\n",
            "         [0.6292, 0.5329],\n",
            "         [0.6503, 0.6682],\n",
            "         [0.6266, 0.7484],\n",
            "         [0.4630, 0.4018],\n",
            "         [0.4320, 0.3509],\n",
            "         [0.3529, 0.5701],\n",
            "         [0.3008, 0.4875],\n",
            "         [0.1392, 0.6400],\n",
            "         [0.1189, 0.5518]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9671, 0.5941, 0.9731, 0.1114, 0.9563, 0.9702, 0.9987, 0.8399, 0.9970, 0.7109, 0.9694, 0.9918, 0.9976, 0.9545, 0.9852, 0.8009, 0.8802]], device='cuda:0')\n",
            "data: tensor([[[5.0091e+02, 1.2313e+02, 9.6708e-01],\n",
            "         [5.0494e+02, 1.1793e+02, 5.9413e-01],\n",
            "         [5.0266e+02, 1.0970e+02, 9.7308e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.1139e-01],\n",
            "         [4.8491e+02, 7.9059e+01, 9.5628e-01],\n",
            "         [4.5882e+02, 9.8248e+01, 9.7025e-01],\n",
            "         [4.2932e+02, 9.3991e+01, 9.9871e-01],\n",
            "         [4.2149e+02, 1.7173e+02, 8.3994e-01],\n",
            "         [4.0313e+02, 2.0414e+02, 9.9696e-01],\n",
            "         [4.1612e+02, 2.5796e+02, 7.1094e-01],\n",
            "         [4.0132e+02, 2.8500e+02, 9.6938e-01],\n",
            "         [2.9842e+02, 1.4829e+02, 9.9176e-01],\n",
            "         [2.7825e+02, 1.2929e+02, 9.9756e-01],\n",
            "         [2.4000e+02, 2.1490e+02, 9.5449e-01],\n",
            "         [1.9759e+02, 1.8084e+02, 9.8517e-01],\n",
            "         [1.1198e+02, 2.4753e+02, 8.0095e-01],\n",
            "         [8.1022e+01, 2.0849e+02, 8.8016e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[500.9137, 123.1290],\n",
            "         [504.9352, 117.9283],\n",
            "         [502.6616, 109.7018],\n",
            "         [  0.0000,   0.0000],\n",
            "         [484.9094,  79.0593],\n",
            "         [458.8196,  98.2481],\n",
            "         [429.3187,  93.9913],\n",
            "         [421.4904, 171.7273],\n",
            "         [403.1304, 204.1359],\n",
            "         [416.1229, 257.9613],\n",
            "         [401.3198, 285.0019],\n",
            "         [298.4158, 148.2866],\n",
            "         [278.2502, 129.2876],\n",
            "         [240.0007, 214.9041],\n",
            "         [197.5852, 180.8371],\n",
            "         [111.9840, 247.5334],\n",
            "         [ 81.0216, 208.4864]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7827, 0.3206],\n",
            "         [0.7890, 0.3071],\n",
            "         [0.7854, 0.2857],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7577, 0.2059],\n",
            "         [0.7169, 0.2559],\n",
            "         [0.6708, 0.2448],\n",
            "         [0.6586, 0.4472],\n",
            "         [0.6299, 0.5316],\n",
            "         [0.6502, 0.6718],\n",
            "         [0.6271, 0.7422],\n",
            "         [0.4663, 0.3862],\n",
            "         [0.4348, 0.3367],\n",
            "         [0.3750, 0.5596],\n",
            "         [0.3087, 0.4709],\n",
            "         [0.1750, 0.6446],\n",
            "         [0.1266, 0.5429]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.4ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9680, 0.5978, 0.9751, 0.1050, 0.9579, 0.9693, 0.9987, 0.8461, 0.9973, 0.7119, 0.9710, 0.9926, 0.9978, 0.9544, 0.9855, 0.7975, 0.8800]], device='cuda:0')\n",
            "data: tensor([[[5.0111e+02, 1.2317e+02, 9.6804e-01],\n",
            "         [5.0485e+02, 1.1774e+02, 5.9783e-01],\n",
            "         [5.0267e+02, 1.0976e+02, 9.7508e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.0498e-01],\n",
            "         [4.8475e+02, 7.9229e+01, 9.5787e-01],\n",
            "         [4.5930e+02, 9.6894e+01, 9.6925e-01],\n",
            "         [4.2838e+02, 9.3115e+01, 9.9872e-01],\n",
            "         [4.2119e+02, 1.7190e+02, 8.4611e-01],\n",
            "         [4.0253e+02, 2.0432e+02, 9.9725e-01],\n",
            "         [4.1750e+02, 2.5675e+02, 7.1188e-01],\n",
            "         [4.0111e+02, 2.8584e+02, 9.7098e-01],\n",
            "         [3.0315e+02, 1.4521e+02, 9.9259e-01],\n",
            "         [2.8003e+02, 1.2726e+02, 9.9783e-01],\n",
            "         [2.5974e+02, 2.1362e+02, 9.5445e-01],\n",
            "         [2.0108e+02, 1.7989e+02, 9.8549e-01],\n",
            "         [1.4212e+02, 2.4612e+02, 7.9754e-01],\n",
            "         [8.2483e+01, 2.0701e+02, 8.7999e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[501.1137, 123.1656],\n",
            "         [504.8548, 117.7428],\n",
            "         [502.6673, 109.7641],\n",
            "         [  0.0000,   0.0000],\n",
            "         [484.7505,  79.2294],\n",
            "         [459.3046,  96.8938],\n",
            "         [428.3837,  93.1152],\n",
            "         [421.1917, 171.8986],\n",
            "         [402.5307, 204.3163],\n",
            "         [417.4969, 256.7520],\n",
            "         [401.1057, 285.8445],\n",
            "         [303.1522, 145.2071],\n",
            "         [280.0287, 127.2638],\n",
            "         [259.7390, 213.6177],\n",
            "         [201.0780, 179.8877],\n",
            "         [142.1245, 246.1228],\n",
            "         [ 82.4825, 207.0110]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7830, 0.3207],\n",
            "         [0.7888, 0.3066],\n",
            "         [0.7854, 0.2858],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7574, 0.2063],\n",
            "         [0.7177, 0.2523],\n",
            "         [0.6693, 0.2425],\n",
            "         [0.6581, 0.4477],\n",
            "         [0.6290, 0.5321],\n",
            "         [0.6523, 0.6686],\n",
            "         [0.6267, 0.7444],\n",
            "         [0.4737, 0.3781],\n",
            "         [0.4375, 0.3314],\n",
            "         [0.4058, 0.5563],\n",
            "         [0.3142, 0.4685],\n",
            "         [0.2221, 0.6409],\n",
            "         [0.1289, 0.5391]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 2.5ms preprocess, 15.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8851, 0.5560, 0.8080, 0.3645, 0.8002, 0.9851, 0.9956, 0.9089, 0.9843, 0.7731, 0.8994, 0.9925, 0.9945, 0.9696, 0.9786, 0.8797, 0.8937]], device='cuda:0')\n",
            "data: tensor([[[4.8460e+02, 1.2062e+02, 8.8509e-01],\n",
            "         [4.8806e+02, 1.1625e+02, 5.5602e-01],\n",
            "         [4.8841e+02, 1.0750e+02, 8.0804e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.6450e-01],\n",
            "         [4.7774e+02, 8.1364e+01, 8.0019e-01],\n",
            "         [4.4918e+02, 1.1226e+02, 9.8506e-01],\n",
            "         [4.3184e+02, 9.6904e+01, 9.9560e-01],\n",
            "         [4.1269e+02, 2.0308e+02, 9.0893e-01],\n",
            "         [4.1387e+02, 2.0105e+02, 9.8428e-01],\n",
            "         [4.0947e+02, 3.0291e+02, 7.7311e-01],\n",
            "         [4.3067e+02, 2.7771e+02, 8.9938e-01],\n",
            "         [2.9247e+02, 1.4965e+02, 9.9253e-01],\n",
            "         [2.8170e+02, 1.2602e+02, 9.9455e-01],\n",
            "         [2.1611e+02, 1.9597e+02, 9.6957e-01],\n",
            "         [2.0328e+02, 1.5963e+02, 9.7860e-01],\n",
            "         [8.2902e+01, 2.2612e+02, 8.7967e-01],\n",
            "         [8.6899e+01, 1.8539e+02, 8.9370e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[484.5984, 120.6150],\n",
            "         [488.0605, 116.2481],\n",
            "         [488.4139, 107.4991],\n",
            "         [  0.0000,   0.0000],\n",
            "         [477.7386,  81.3643],\n",
            "         [449.1806, 112.2564],\n",
            "         [431.8399,  96.9040],\n",
            "         [412.6931, 203.0800],\n",
            "         [413.8716, 201.0480],\n",
            "         [409.4713, 302.9112],\n",
            "         [430.6698, 277.7139],\n",
            "         [292.4682, 149.6471],\n",
            "         [281.6964, 126.0190],\n",
            "         [216.1106, 195.9722],\n",
            "         [203.2807, 159.6332],\n",
            "         [ 82.9017, 226.1151],\n",
            "         [ 86.8989, 185.3939]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7572, 0.3141],\n",
            "         [0.7626, 0.3027],\n",
            "         [0.7631, 0.2799],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7465, 0.2119],\n",
            "         [0.7018, 0.2923],\n",
            "         [0.6747, 0.2524],\n",
            "         [0.6448, 0.5289],\n",
            "         [0.6467, 0.5236],\n",
            "         [0.6398, 0.7888],\n",
            "         [0.6729, 0.7232],\n",
            "         [0.4570, 0.3897],\n",
            "         [0.4402, 0.3282],\n",
            "         [0.3377, 0.5103],\n",
            "         [0.3176, 0.4157],\n",
            "         [0.1295, 0.5888],\n",
            "         [0.1358, 0.4828]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.4ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8964, 0.5799, 0.8267, 0.3789, 0.8193, 0.9859, 0.9960, 0.9085, 0.9852, 0.7689, 0.9025, 0.9922, 0.9945, 0.9675, 0.9777, 0.8697, 0.8870]], device='cuda:0')\n",
            "data: tensor([[[4.8384e+02, 1.1961e+02, 8.9640e-01],\n",
            "         [4.8749e+02, 1.1551e+02, 5.7990e-01],\n",
            "         [4.8792e+02, 1.0613e+02, 8.2673e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.7886e-01],\n",
            "         [4.7750e+02, 7.9570e+01, 8.1927e-01],\n",
            "         [4.4844e+02, 1.1241e+02, 9.8591e-01],\n",
            "         [4.3113e+02, 9.5613e+01, 9.9604e-01],\n",
            "         [4.1205e+02, 2.0349e+02, 9.0847e-01],\n",
            "         [4.1412e+02, 2.0046e+02, 9.8523e-01],\n",
            "         [4.0826e+02, 3.0377e+02, 7.6891e-01],\n",
            "         [4.2995e+02, 2.7755e+02, 9.0246e-01],\n",
            "         [2.9119e+02, 1.5001e+02, 9.9223e-01],\n",
            "         [2.8051e+02, 1.2542e+02, 9.9447e-01],\n",
            "         [2.1642e+02, 1.9715e+02, 9.6750e-01],\n",
            "         [2.0232e+02, 1.5827e+02, 9.7774e-01],\n",
            "         [8.1421e+01, 2.2915e+02, 8.6970e-01],\n",
            "         [8.5265e+01, 1.8553e+02, 8.8696e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[483.8410, 119.6130],\n",
            "         [487.4913, 115.5108],\n",
            "         [487.9227, 106.1255],\n",
            "         [  0.0000,   0.0000],\n",
            "         [477.5043,  79.5703],\n",
            "         [448.4435, 112.4086],\n",
            "         [431.1320,  95.6129],\n",
            "         [412.0489, 203.4909],\n",
            "         [414.1158, 200.4607],\n",
            "         [408.2621, 303.7688],\n",
            "         [429.9543, 277.5517],\n",
            "         [291.1947, 150.0093],\n",
            "         [280.5122, 125.4154],\n",
            "         [216.4210, 197.1472],\n",
            "         [202.3228, 158.2745],\n",
            "         [ 81.4208, 229.1541],\n",
            "         [ 85.2648, 185.5304]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7560, 0.3115],\n",
            "         [0.7617, 0.3008],\n",
            "         [0.7624, 0.2764],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7461, 0.2072],\n",
            "         [0.7007, 0.2927],\n",
            "         [0.6736, 0.2490],\n",
            "         [0.6438, 0.5299],\n",
            "         [0.6471, 0.5220],\n",
            "         [0.6379, 0.7911],\n",
            "         [0.6718, 0.7228],\n",
            "         [0.4550, 0.3906],\n",
            "         [0.4383, 0.3266],\n",
            "         [0.3382, 0.5134],\n",
            "         [0.3161, 0.4122],\n",
            "         [0.1272, 0.5968],\n",
            "         [0.1332, 0.4832]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.5ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8969, 0.5766, 0.8282, 0.3788, 0.8211, 0.9859, 0.9963, 0.9094, 0.9864, 0.7701, 0.9063, 0.9925, 0.9948, 0.9676, 0.9783, 0.8687, 0.8876]], device='cuda:0')\n",
            "data: tensor([[[4.8310e+02, 1.2018e+02, 8.9685e-01],\n",
            "         [4.8670e+02, 1.1605e+02, 5.7655e-01],\n",
            "         [4.8748e+02, 1.0688e+02, 8.2817e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.7875e-01],\n",
            "         [4.7769e+02, 7.9863e+01, 8.2107e-01],\n",
            "         [4.4794e+02, 1.1106e+02, 9.8592e-01],\n",
            "         [4.3069e+02, 9.5482e+01, 9.9629e-01],\n",
            "         [4.1126e+02, 2.0098e+02, 9.0935e-01],\n",
            "         [4.1305e+02, 2.0063e+02, 9.8643e-01],\n",
            "         [4.0929e+02, 3.0293e+02, 7.7005e-01],\n",
            "         [4.2953e+02, 2.7946e+02, 9.0629e-01],\n",
            "         [2.8954e+02, 1.4882e+02, 9.9251e-01],\n",
            "         [2.7897e+02, 1.2476e+02, 9.9482e-01],\n",
            "         [2.1407e+02, 1.9703e+02, 9.6758e-01],\n",
            "         [2.0001e+02, 1.5881e+02, 9.7833e-01],\n",
            "         [8.0034e+01, 2.2805e+02, 8.6872e-01],\n",
            "         [8.3684e+01, 1.8498e+02, 8.8761e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[483.0970, 120.1833],\n",
            "         [486.7003, 116.0495],\n",
            "         [487.4815, 106.8801],\n",
            "         [  0.0000,   0.0000],\n",
            "         [477.6886,  79.8633],\n",
            "         [447.9383, 111.0582],\n",
            "         [430.6851,  95.4822],\n",
            "         [411.2604, 200.9840],\n",
            "         [413.0509, 200.6303],\n",
            "         [409.2899, 302.9332],\n",
            "         [429.5295, 279.4582],\n",
            "         [289.5428, 148.8159],\n",
            "         [278.9688, 124.7577],\n",
            "         [214.0737, 197.0264],\n",
            "         [200.0096, 158.8132],\n",
            "         [ 80.0342, 228.0546],\n",
            "         [ 83.6837, 184.9773]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7548, 0.3130],\n",
            "         [0.7605, 0.3022],\n",
            "         [0.7617, 0.2783],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7464, 0.2080],\n",
            "         [0.6999, 0.2892],\n",
            "         [0.6729, 0.2487],\n",
            "         [0.6426, 0.5234],\n",
            "         [0.6454, 0.5225],\n",
            "         [0.6395, 0.7889],\n",
            "         [0.6711, 0.7278],\n",
            "         [0.4524, 0.3875],\n",
            "         [0.4359, 0.3249],\n",
            "         [0.3345, 0.5131],\n",
            "         [0.3125, 0.4136],\n",
            "         [0.1251, 0.5939],\n",
            "         [0.1308, 0.4817]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9035, 0.5827, 0.8437, 0.3749, 0.8365, 0.9861, 0.9967, 0.9073, 0.9879, 0.7655, 0.9119, 0.9927, 0.9952, 0.9679, 0.9795, 0.8701, 0.8914]], device='cuda:0')\n",
            "data: tensor([[[4.8343e+02, 1.1976e+02, 9.0349e-01],\n",
            "         [4.8718e+02, 1.1573e+02, 5.8272e-01],\n",
            "         [4.8800e+02, 1.0645e+02, 8.4366e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.7486e-01],\n",
            "         [4.7805e+02, 7.9300e+01, 8.3654e-01],\n",
            "         [4.4727e+02, 1.1107e+02, 9.8611e-01],\n",
            "         [4.3034e+02, 9.5365e+01, 9.9671e-01],\n",
            "         [4.1066e+02, 2.0170e+02, 9.0728e-01],\n",
            "         [4.1229e+02, 2.0146e+02, 9.8789e-01],\n",
            "         [4.1093e+02, 3.0275e+02, 7.6546e-01],\n",
            "         [4.2898e+02, 2.8029e+02, 9.1190e-01],\n",
            "         [2.8829e+02, 1.4927e+02, 9.9267e-01],\n",
            "         [2.7795e+02, 1.2528e+02, 9.9517e-01],\n",
            "         [2.1143e+02, 1.9711e+02, 9.6787e-01],\n",
            "         [1.9722e+02, 1.5957e+02, 9.7950e-01],\n",
            "         [7.7825e+01, 2.2680e+02, 8.7014e-01],\n",
            "         [8.1312e+01, 1.8514e+02, 8.9142e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[483.4293, 119.7561],\n",
            "         [487.1774, 115.7274],\n",
            "         [487.9975, 106.4547],\n",
            "         [  0.0000,   0.0000],\n",
            "         [478.0498,  79.3000],\n",
            "         [447.2686, 111.0658],\n",
            "         [430.3367,  95.3653],\n",
            "         [410.6614, 201.6953],\n",
            "         [412.2927, 201.4619],\n",
            "         [410.9279, 302.7469],\n",
            "         [428.9770, 280.2942],\n",
            "         [288.2873, 149.2653],\n",
            "         [277.9535, 125.2783],\n",
            "         [211.4316, 197.1064],\n",
            "         [197.2204, 159.5681],\n",
            "         [ 77.8252, 226.8024],\n",
            "         [ 81.3120, 185.1376]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7554, 0.3119],\n",
            "         [0.7612, 0.3014],\n",
            "         [0.7625, 0.2772],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7470, 0.2065],\n",
            "         [0.6989, 0.2892],\n",
            "         [0.6724, 0.2483],\n",
            "         [0.6417, 0.5252],\n",
            "         [0.6442, 0.5246],\n",
            "         [0.6421, 0.7884],\n",
            "         [0.6703, 0.7299],\n",
            "         [0.4504, 0.3887],\n",
            "         [0.4343, 0.3262],\n",
            "         [0.3304, 0.5133],\n",
            "         [0.3082, 0.4155],\n",
            "         [0.1216, 0.5906],\n",
            "         [0.1270, 0.4821]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9112, 0.6034, 0.8563, 0.3881, 0.8474, 0.9869, 0.9968, 0.9092, 0.9878, 0.7663, 0.9103, 0.9923, 0.9948, 0.9660, 0.9780, 0.8649, 0.8859]], device='cuda:0')\n",
            "data: tensor([[[4.8290e+02, 1.2046e+02, 9.1122e-01],\n",
            "         [4.8670e+02, 1.1652e+02, 6.0336e-01],\n",
            "         [4.8759e+02, 1.0693e+02, 8.5626e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.8805e-01],\n",
            "         [4.7767e+02, 7.9461e+01, 8.4736e-01],\n",
            "         [4.4592e+02, 1.1191e+02, 9.8694e-01],\n",
            "         [4.2970e+02, 9.5392e+01, 9.9680e-01],\n",
            "         [4.0896e+02, 2.0214e+02, 9.0923e-01],\n",
            "         [4.1305e+02, 2.0117e+02, 9.8775e-01],\n",
            "         [4.0893e+02, 3.0400e+02, 7.6634e-01],\n",
            "         [4.3014e+02, 2.8093e+02, 9.1028e-01],\n",
            "         [2.8518e+02, 1.4949e+02, 9.9229e-01],\n",
            "         [2.7526e+02, 1.2491e+02, 9.9482e-01],\n",
            "         [2.1086e+02, 1.9626e+02, 9.6605e-01],\n",
            "         [1.9605e+02, 1.5699e+02, 9.7797e-01],\n",
            "         [7.6297e+01, 2.2710e+02, 8.6487e-01],\n",
            "         [7.9422e+01, 1.8321e+02, 8.8589e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[482.8954, 120.4570],\n",
            "         [486.6974, 116.5216],\n",
            "         [487.5911, 106.9336],\n",
            "         [  0.0000,   0.0000],\n",
            "         [477.6672,  79.4612],\n",
            "         [445.9211, 111.9145],\n",
            "         [429.7000,  95.3921],\n",
            "         [408.9611, 202.1391],\n",
            "         [413.0472, 201.1703],\n",
            "         [408.9300, 304.0020],\n",
            "         [430.1426, 280.9325],\n",
            "         [285.1774, 149.4884],\n",
            "         [275.2622, 124.9139],\n",
            "         [210.8556, 196.2632],\n",
            "         [196.0502, 156.9897],\n",
            "         [ 76.2972, 227.1040],\n",
            "         [ 79.4220, 183.2094]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7545, 0.3137],\n",
            "         [0.7605, 0.3034],\n",
            "         [0.7619, 0.2785],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7464, 0.2069],\n",
            "         [0.6968, 0.2914],\n",
            "         [0.6714, 0.2484],\n",
            "         [0.6390, 0.5264],\n",
            "         [0.6454, 0.5239],\n",
            "         [0.6390, 0.7917],\n",
            "         [0.6721, 0.7316],\n",
            "         [0.4456, 0.3893],\n",
            "         [0.4301, 0.3253],\n",
            "         [0.3295, 0.5111],\n",
            "         [0.3063, 0.4088],\n",
            "         [0.1192, 0.5914],\n",
            "         [0.1241, 0.4771]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9144, 0.6092, 0.8637, 0.3849, 0.8504, 0.9869, 0.9970, 0.9091, 0.9887, 0.7680, 0.9148, 0.9928, 0.9953, 0.9672, 0.9793, 0.8693, 0.8910]], device='cuda:0')\n",
            "data: tensor([[[4.8272e+02, 1.2058e+02, 9.1439e-01],\n",
            "         [4.8681e+02, 1.1673e+02, 6.0917e-01],\n",
            "         [4.8742e+02, 1.0717e+02, 8.6370e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.8495e-01],\n",
            "         [4.7714e+02, 7.9451e+01, 8.5035e-01],\n",
            "         [4.4627e+02, 1.1173e+02, 9.8692e-01],\n",
            "         [4.2855e+02, 9.4797e+01, 9.9700e-01],\n",
            "         [4.0948e+02, 2.0187e+02, 9.0914e-01],\n",
            "         [4.1142e+02, 1.9976e+02, 9.8868e-01],\n",
            "         [4.0986e+02, 3.0192e+02, 7.6799e-01],\n",
            "         [4.2924e+02, 2.7960e+02, 9.1479e-01],\n",
            "         [2.8524e+02, 1.4917e+02, 9.9277e-01],\n",
            "         [2.7435e+02, 1.2455e+02, 9.9530e-01],\n",
            "         [2.0804e+02, 1.9693e+02, 9.6717e-01],\n",
            "         [1.9268e+02, 1.5837e+02, 9.7925e-01],\n",
            "         [7.5484e+01, 2.2394e+02, 8.6929e-01],\n",
            "         [7.8485e+01, 1.8156e+02, 8.9104e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[482.7206, 120.5799],\n",
            "         [486.8088, 116.7275],\n",
            "         [487.4215, 107.1716],\n",
            "         [  0.0000,   0.0000],\n",
            "         [477.1415,  79.4506],\n",
            "         [446.2722, 111.7257],\n",
            "         [428.5499,  94.7970],\n",
            "         [409.4839, 201.8696],\n",
            "         [411.4193, 199.7582],\n",
            "         [409.8624, 301.9219],\n",
            "         [429.2359, 279.6033],\n",
            "         [285.2401, 149.1699],\n",
            "         [274.3461, 124.5489],\n",
            "         [208.0359, 196.9251],\n",
            "         [192.6800, 158.3734],\n",
            "         [ 75.4841, 223.9385],\n",
            "         [ 78.4852, 181.5585]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7543, 0.3140],\n",
            "         [0.7606, 0.3040],\n",
            "         [0.7616, 0.2791],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7455, 0.2069],\n",
            "         [0.6973, 0.2910],\n",
            "         [0.6696, 0.2469],\n",
            "         [0.6398, 0.5257],\n",
            "         [0.6428, 0.5202],\n",
            "         [0.6404, 0.7863],\n",
            "         [0.6707, 0.7281],\n",
            "         [0.4457, 0.3885],\n",
            "         [0.4287, 0.3243],\n",
            "         [0.3251, 0.5128],\n",
            "         [0.3011, 0.4124],\n",
            "         [0.1179, 0.5832],\n",
            "         [0.1226, 0.4728]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 1.4ms preprocess, 14.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9674, 0.8156, 0.9632, 0.3419, 0.9219, 0.9873, 0.9974, 0.9311, 0.9904, 0.8524, 0.9569, 0.9951, 0.9971, 0.9785, 0.9887, 0.9366, 0.9558]], device='cuda:0')\n",
            "data: tensor([[[4.3232e+02, 1.8349e+02, 9.6745e-01],\n",
            "         [4.3701e+02, 1.7914e+02, 8.1558e-01],\n",
            "         [4.3054e+02, 1.7507e+02, 9.6317e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.4187e-01],\n",
            "         [4.1482e+02, 1.6328e+02, 9.2192e-01],\n",
            "         [4.1806e+02, 1.8099e+02, 9.8731e-01],\n",
            "         [3.8270e+02, 1.7976e+02, 9.9741e-01],\n",
            "         [4.1866e+02, 2.2839e+02, 9.3110e-01],\n",
            "         [3.6230e+02, 2.4413e+02, 9.9044e-01],\n",
            "         [4.2352e+02, 2.7593e+02, 8.5235e-01],\n",
            "         [3.5624e+02, 2.9407e+02, 9.5694e-01],\n",
            "         [3.4521e+02, 1.9692e+02, 9.9508e-01],\n",
            "         [3.1911e+02, 1.9196e+02, 9.9714e-01],\n",
            "         [3.4567e+02, 2.3526e+02, 9.7846e-01],\n",
            "         [2.8764e+02, 2.3133e+02, 9.8871e-01],\n",
            "         [2.9674e+02, 2.2621e+02, 9.3656e-01],\n",
            "         [2.3058e+02, 2.2521e+02, 9.5576e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[432.3208, 183.4850],\n",
            "         [437.0102, 179.1382],\n",
            "         [430.5444, 175.0714],\n",
            "         [  0.0000,   0.0000],\n",
            "         [414.8170, 163.2773],\n",
            "         [418.0580, 180.9869],\n",
            "         [382.7025, 179.7567],\n",
            "         [418.6614, 228.3936],\n",
            "         [362.3004, 244.1304],\n",
            "         [423.5203, 275.9295],\n",
            "         [356.2351, 294.0650],\n",
            "         [345.2097, 196.9237],\n",
            "         [319.1052, 191.9563],\n",
            "         [345.6721, 235.2592],\n",
            "         [287.6363, 231.3311],\n",
            "         [296.7413, 226.2108],\n",
            "         [230.5770, 225.2092]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6755, 0.4778],\n",
            "         [0.6828, 0.4665],\n",
            "         [0.6727, 0.4559],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6482, 0.4252],\n",
            "         [0.6532, 0.4713],\n",
            "         [0.5980, 0.4681],\n",
            "         [0.6542, 0.5948],\n",
            "         [0.5661, 0.6358],\n",
            "         [0.6618, 0.7186],\n",
            "         [0.5566, 0.7658],\n",
            "         [0.5394, 0.5128],\n",
            "         [0.4986, 0.4999],\n",
            "         [0.5401, 0.6127],\n",
            "         [0.4494, 0.6024],\n",
            "         [0.4637, 0.5891],\n",
            "         [0.3603, 0.5865]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 1.6ms preprocess, 12.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9682, 0.8205, 0.9640, 0.3473, 0.9226, 0.9874, 0.9974, 0.9314, 0.9904, 0.8519, 0.9567, 0.9951, 0.9972, 0.9784, 0.9887, 0.9362, 0.9555]], device='cuda:0')\n",
            "data: tensor([[[4.3225e+02, 1.8374e+02, 9.6819e-01],\n",
            "         [4.3697e+02, 1.7936e+02, 8.2054e-01],\n",
            "         [4.3041e+02, 1.7529e+02, 9.6403e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.4731e-01],\n",
            "         [4.1471e+02, 1.6351e+02, 9.2262e-01],\n",
            "         [4.1840e+02, 1.8122e+02, 9.8744e-01],\n",
            "         [3.8256e+02, 1.7983e+02, 9.9743e-01],\n",
            "         [4.1860e+02, 2.2843e+02, 9.3137e-01],\n",
            "         [3.6247e+02, 2.4390e+02, 9.9044e-01],\n",
            "         [4.2361e+02, 2.7575e+02, 8.5194e-01],\n",
            "         [3.5657e+02, 2.9373e+02, 9.5673e-01],\n",
            "         [3.4558e+02, 1.9648e+02, 9.9511e-01],\n",
            "         [3.1906e+02, 1.9140e+02, 9.9715e-01],\n",
            "         [3.4693e+02, 2.3553e+02, 9.7844e-01],\n",
            "         [2.8760e+02, 2.3094e+02, 9.8869e-01],\n",
            "         [2.9889e+02, 2.2678e+02, 9.3616e-01],\n",
            "         [2.3061e+02, 2.2480e+02, 9.5554e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[432.2455, 183.7391],\n",
            "         [436.9747, 179.3648],\n",
            "         [430.4114, 175.2947],\n",
            "         [  0.0000,   0.0000],\n",
            "         [414.7131, 163.5139],\n",
            "         [418.4005, 181.2234],\n",
            "         [382.5568, 179.8271],\n",
            "         [418.5995, 228.4342],\n",
            "         [362.4713, 243.8997],\n",
            "         [423.6129, 275.7537],\n",
            "         [356.5712, 293.7312],\n",
            "         [345.5777, 196.4846],\n",
            "         [319.0573, 191.3998],\n",
            "         [346.9292, 235.5336],\n",
            "         [287.5952, 230.9363],\n",
            "         [298.8946, 226.7801],\n",
            "         [230.6090, 224.8026]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6754, 0.4785],\n",
            "         [0.6828, 0.4671],\n",
            "         [0.6725, 0.4565],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6480, 0.4258],\n",
            "         [0.6538, 0.4719],\n",
            "         [0.5977, 0.4683],\n",
            "         [0.6541, 0.5949],\n",
            "         [0.5664, 0.6352],\n",
            "         [0.6619, 0.7181],\n",
            "         [0.5571, 0.7649],\n",
            "         [0.5400, 0.5117],\n",
            "         [0.4985, 0.4984],\n",
            "         [0.5421, 0.6134],\n",
            "         [0.4494, 0.6014],\n",
            "         [0.4670, 0.5906],\n",
            "         [0.3603, 0.5854]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 1.5ms preprocess, 12.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9676, 0.8201, 0.9627, 0.3526, 0.9202, 0.9876, 0.9973, 0.9322, 0.9900, 0.8535, 0.9552, 0.9950, 0.9970, 0.9779, 0.9881, 0.9350, 0.9540]], device='cuda:0')\n",
            "data: tensor([[[4.3221e+02, 1.8377e+02, 9.6757e-01],\n",
            "         [4.3693e+02, 1.7941e+02, 8.2006e-01],\n",
            "         [4.3045e+02, 1.7537e+02, 9.6272e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.5262e-01],\n",
            "         [4.1493e+02, 1.6353e+02, 9.2024e-01],\n",
            "         [4.1823e+02, 1.8107e+02, 9.8757e-01],\n",
            "         [3.8277e+02, 1.8004e+02, 9.9734e-01],\n",
            "         [4.1858e+02, 2.2804e+02, 9.3218e-01],\n",
            "         [3.6232e+02, 2.4436e+02, 9.8996e-01],\n",
            "         [4.2360e+02, 2.7586e+02, 8.5350e-01],\n",
            "         [3.5622e+02, 2.9424e+02, 9.5516e-01],\n",
            "         [3.4475e+02, 1.9703e+02, 9.9497e-01],\n",
            "         [3.1874e+02, 1.9204e+02, 9.9700e-01],\n",
            "         [3.4458e+02, 2.3545e+02, 9.7792e-01],\n",
            "         [2.8744e+02, 2.3110e+02, 9.8813e-01],\n",
            "         [2.9540e+02, 2.2634e+02, 9.3496e-01],\n",
            "         [2.3083e+02, 2.2453e+02, 9.5397e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[432.2109, 183.7686],\n",
            "         [436.9314, 179.4097],\n",
            "         [430.4532, 175.3665],\n",
            "         [  0.0000,   0.0000],\n",
            "         [414.9292, 163.5253],\n",
            "         [418.2273, 181.0738],\n",
            "         [382.7656, 180.0427],\n",
            "         [418.5790, 228.0379],\n",
            "         [362.3231, 244.3578],\n",
            "         [423.6028, 275.8635],\n",
            "         [356.2234, 294.2354],\n",
            "         [344.7531, 197.0343],\n",
            "         [318.7441, 192.0404],\n",
            "         [344.5751, 235.4541],\n",
            "         [287.4374, 231.1046],\n",
            "         [295.4012, 226.3365],\n",
            "         [230.8349, 224.5287]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6753, 0.4786],\n",
            "         [0.6827, 0.4672],\n",
            "         [0.6726, 0.4567],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6483, 0.4258],\n",
            "         [0.6535, 0.4715],\n",
            "         [0.5981, 0.4689],\n",
            "         [0.6540, 0.5938],\n",
            "         [0.5661, 0.6363],\n",
            "         [0.6619, 0.7184],\n",
            "         [0.5566, 0.7662],\n",
            "         [0.5387, 0.5131],\n",
            "         [0.4980, 0.5001],\n",
            "         [0.5384, 0.6132],\n",
            "         [0.4491, 0.6018],\n",
            "         [0.4616, 0.5894],\n",
            "         [0.3607, 0.5847]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9674, 0.8198, 0.9624, 0.3515, 0.9193, 0.9875, 0.9973, 0.9323, 0.9899, 0.8540, 0.9550, 0.9949, 0.9970, 0.9775, 0.9878, 0.9337, 0.9529]], device='cuda:0')\n",
            "data: tensor([[[4.3220e+02, 1.8386e+02, 9.6745e-01],\n",
            "         [4.3692e+02, 1.7944e+02, 8.1979e-01],\n",
            "         [4.3038e+02, 1.7545e+02, 9.6242e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.5154e-01],\n",
            "         [4.1481e+02, 1.6352e+02, 9.1928e-01],\n",
            "         [4.1840e+02, 1.8083e+02, 9.8749e-01],\n",
            "         [3.8271e+02, 1.8002e+02, 9.9731e-01],\n",
            "         [4.1867e+02, 2.2762e+02, 9.3234e-01],\n",
            "         [3.6226e+02, 2.4431e+02, 9.8987e-01],\n",
            "         [4.2343e+02, 2.7591e+02, 8.5396e-01],\n",
            "         [3.5586e+02, 2.9455e+02, 9.5496e-01],\n",
            "         [3.4493e+02, 1.9745e+02, 9.9491e-01],\n",
            "         [3.1877e+02, 1.9252e+02, 9.9695e-01],\n",
            "         [3.4468e+02, 2.3575e+02, 9.7748e-01],\n",
            "         [2.8745e+02, 2.3137e+02, 9.8785e-01],\n",
            "         [2.9543e+02, 2.2660e+02, 9.3365e-01],\n",
            "         [2.3092e+02, 2.2461e+02, 9.5292e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[432.1998, 183.8568],\n",
            "         [436.9165, 179.4449],\n",
            "         [430.3809, 175.4454],\n",
            "         [  0.0000,   0.0000],\n",
            "         [414.8144, 163.5248],\n",
            "         [418.4011, 180.8344],\n",
            "         [382.7089, 180.0152],\n",
            "         [418.6669, 227.6213],\n",
            "         [362.2553, 244.3143],\n",
            "         [423.4295, 275.9113],\n",
            "         [355.8593, 294.5493],\n",
            "         [344.9337, 197.4542],\n",
            "         [318.7672, 192.5228],\n",
            "         [344.6761, 235.7528],\n",
            "         [287.4453, 231.3739],\n",
            "         [295.4342, 226.6046],\n",
            "         [230.9244, 224.6069]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6753, 0.4788],\n",
            "         [0.6827, 0.4673],\n",
            "         [0.6725, 0.4569],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6481, 0.4258],\n",
            "         [0.6538, 0.4709],\n",
            "         [0.5980, 0.4688],\n",
            "         [0.6542, 0.5928],\n",
            "         [0.5660, 0.6362],\n",
            "         [0.6616, 0.7185],\n",
            "         [0.5560, 0.7671],\n",
            "         [0.5390, 0.5142],\n",
            "         [0.4981, 0.5014],\n",
            "         [0.5386, 0.6139],\n",
            "         [0.4491, 0.6025],\n",
            "         [0.4616, 0.5901],\n",
            "         [0.3608, 0.5849]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.4ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9673, 0.8147, 0.9632, 0.3400, 0.9225, 0.9871, 0.9973, 0.9296, 0.9900, 0.8496, 0.9551, 0.9947, 0.9969, 0.9767, 0.9876, 0.9318, 0.9521]], device='cuda:0')\n",
            "data: tensor([[[4.3251e+02, 1.8393e+02, 9.6729e-01],\n",
            "         [4.3710e+02, 1.7933e+02, 8.1473e-01],\n",
            "         [4.3052e+02, 1.7558e+02, 9.6316e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.4004e-01],\n",
            "         [4.1472e+02, 1.6369e+02, 9.2250e-01],\n",
            "         [4.1826e+02, 1.8052e+02, 9.8712e-01],\n",
            "         [3.8252e+02, 1.8030e+02, 9.9735e-01],\n",
            "         [4.1866e+02, 2.2741e+02, 9.2965e-01],\n",
            "         [3.6210e+02, 2.4487e+02, 9.8999e-01],\n",
            "         [4.2351e+02, 2.7599e+02, 8.4959e-01],\n",
            "         [3.5521e+02, 2.9514e+02, 9.5513e-01],\n",
            "         [3.4400e+02, 1.9776e+02, 9.9473e-01],\n",
            "         [3.1788e+02, 1.9307e+02, 9.9691e-01],\n",
            "         [3.4359e+02, 2.3619e+02, 9.7669e-01],\n",
            "         [2.8703e+02, 2.3202e+02, 9.8764e-01],\n",
            "         [2.9502e+02, 2.2666e+02, 9.3183e-01],\n",
            "         [2.3111e+02, 2.2456e+02, 9.5209e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[432.5071, 183.9308],\n",
            "         [437.1016, 179.3278],\n",
            "         [430.5247, 175.5756],\n",
            "         [  0.0000,   0.0000],\n",
            "         [414.7161, 163.6880],\n",
            "         [418.2648, 180.5175],\n",
            "         [382.5181, 180.2980],\n",
            "         [418.6591, 227.4129],\n",
            "         [362.0977, 244.8687],\n",
            "         [423.5129, 275.9854],\n",
            "         [355.2057, 295.1447],\n",
            "         [343.9962, 197.7558],\n",
            "         [317.8797, 193.0663],\n",
            "         [343.5933, 236.1853],\n",
            "         [287.0254, 232.0182],\n",
            "         [295.0180, 226.6561],\n",
            "         [231.1067, 224.5618]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6758, 0.4790],\n",
            "         [0.6830, 0.4670],\n",
            "         [0.6727, 0.4572],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6480, 0.4263],\n",
            "         [0.6535, 0.4701],\n",
            "         [0.5977, 0.4695],\n",
            "         [0.6542, 0.5922],\n",
            "         [0.5658, 0.6377],\n",
            "         [0.6617, 0.7187],\n",
            "         [0.5550, 0.7686],\n",
            "         [0.5375, 0.5150],\n",
            "         [0.4967, 0.5028],\n",
            "         [0.5369, 0.6151],\n",
            "         [0.4485, 0.6042],\n",
            "         [0.4610, 0.5903],\n",
            "         [0.3611, 0.5848]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9598, 0.7805, 0.9531, 0.3094, 0.9081, 0.9855, 0.9968, 0.9286, 0.9889, 0.8548, 0.9543, 0.9943, 0.9965, 0.9749, 0.9862, 0.9264, 0.9466]], device='cuda:0')\n",
            "data: tensor([[[4.3388e+02, 1.8402e+02, 9.5982e-01],\n",
            "         [4.3801e+02, 1.7930e+02, 7.8053e-01],\n",
            "         [4.3177e+02, 1.7593e+02, 9.5313e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.0943e-01],\n",
            "         [4.1569e+02, 1.6403e+02, 9.0805e-01],\n",
            "         [4.1875e+02, 1.7978e+02, 9.8552e-01],\n",
            "         [3.8421e+02, 1.7981e+02, 9.9683e-01],\n",
            "         [4.1935e+02, 2.2752e+02, 9.2862e-01],\n",
            "         [3.6131e+02, 2.4381e+02, 9.8891e-01],\n",
            "         [4.2305e+02, 2.7624e+02, 8.5477e-01],\n",
            "         [3.5503e+02, 2.9435e+02, 9.5426e-01],\n",
            "         [3.4538e+02, 1.9790e+02, 9.9426e-01],\n",
            "         [3.2050e+02, 1.9350e+02, 9.9654e-01],\n",
            "         [3.3904e+02, 2.3497e+02, 9.7493e-01],\n",
            "         [2.8843e+02, 2.3329e+02, 9.8620e-01],\n",
            "         [2.8840e+02, 2.2388e+02, 9.2637e-01],\n",
            "         [2.3179e+02, 2.2493e+02, 9.4656e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[433.8812, 184.0203],\n",
            "         [438.0102, 179.2960],\n",
            "         [431.7720, 175.9271],\n",
            "         [  0.0000,   0.0000],\n",
            "         [415.6936, 164.0324],\n",
            "         [418.7455, 179.7800],\n",
            "         [384.2075, 179.8139],\n",
            "         [419.3521, 227.5173],\n",
            "         [361.3093, 243.8141],\n",
            "         [423.0451, 276.2410],\n",
            "         [355.0270, 294.3503],\n",
            "         [345.3784, 197.8987],\n",
            "         [320.4974, 193.5040],\n",
            "         [339.0393, 234.9684],\n",
            "         [288.4291, 233.2881],\n",
            "         [288.4022, 223.8754],\n",
            "         [231.7920, 224.9253]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6779, 0.4792],\n",
            "         [0.6844, 0.4669],\n",
            "         [0.6746, 0.4581],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6495, 0.4272],\n",
            "         [0.6543, 0.4682],\n",
            "         [0.6003, 0.4683],\n",
            "         [0.6552, 0.5925],\n",
            "         [0.5645, 0.6349],\n",
            "         [0.6610, 0.7194],\n",
            "         [0.5547, 0.7665],\n",
            "         [0.5397, 0.5154],\n",
            "         [0.5008, 0.5039],\n",
            "         [0.5297, 0.6119],\n",
            "         [0.4507, 0.6075],\n",
            "         [0.4506, 0.5830],\n",
            "         [0.3622, 0.5857]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.8ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9516, 0.7406, 0.9429, 0.2748, 0.8974, 0.9854, 0.9964, 0.9371, 0.9888, 0.8660, 0.9540, 0.9953, 0.9970, 0.9778, 0.9870, 0.9316, 0.9486]], device='cuda:0')\n",
            "data: tensor([[[4.3496e+02, 1.8443e+02, 9.5164e-01],\n",
            "         [4.3793e+02, 1.7933e+02, 7.4063e-01],\n",
            "         [4.3230e+02, 1.7692e+02, 9.4287e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.7481e-01],\n",
            "         [4.1585e+02, 1.6689e+02, 8.9737e-01],\n",
            "         [4.1974e+02, 1.8020e+02, 9.8541e-01],\n",
            "         [3.8361e+02, 1.8219e+02, 9.9645e-01],\n",
            "         [4.1849e+02, 2.2583e+02, 9.3715e-01],\n",
            "         [3.5882e+02, 2.4396e+02, 9.8883e-01],\n",
            "         [4.2235e+02, 2.7546e+02, 8.6601e-01],\n",
            "         [3.5398e+02, 2.9603e+02, 9.5396e-01],\n",
            "         [3.4789e+02, 1.9812e+02, 9.9525e-01],\n",
            "         [3.2099e+02, 1.9468e+02, 9.9697e-01],\n",
            "         [3.4916e+02, 2.3625e+02, 9.7784e-01],\n",
            "         [2.9066e+02, 2.3356e+02, 9.8704e-01],\n",
            "         [3.0416e+02, 2.2733e+02, 9.3160e-01],\n",
            "         [2.3115e+02, 2.2425e+02, 9.4864e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[434.9637, 184.4336],\n",
            "         [437.9266, 179.3324],\n",
            "         [432.3042, 176.9247],\n",
            "         [  0.0000,   0.0000],\n",
            "         [415.8506, 166.8865],\n",
            "         [419.7383, 180.1980],\n",
            "         [383.6124, 182.1884],\n",
            "         [418.4898, 225.8328],\n",
            "         [358.8177, 243.9640],\n",
            "         [422.3535, 275.4641],\n",
            "         [353.9849, 296.0345],\n",
            "         [347.8874, 198.1212],\n",
            "         [320.9932, 194.6838],\n",
            "         [349.1604, 236.2498],\n",
            "         [290.6588, 233.5649],\n",
            "         [304.1568, 227.3284],\n",
            "         [231.1502, 224.2507]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6796, 0.4803],\n",
            "         [0.6843, 0.4670],\n",
            "         [0.6755, 0.4607],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6498, 0.4346],\n",
            "         [0.6558, 0.4693],\n",
            "         [0.5994, 0.4744],\n",
            "         [0.6539, 0.5881],\n",
            "         [0.5607, 0.6353],\n",
            "         [0.6599, 0.7174],\n",
            "         [0.5531, 0.7709],\n",
            "         [0.5436, 0.5159],\n",
            "         [0.5016, 0.5070],\n",
            "         [0.5456, 0.6152],\n",
            "         [0.4542, 0.6082],\n",
            "         [0.4752, 0.5920],\n",
            "         [0.3612, 0.5840]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.7ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9428, 0.6935, 0.9353, 0.2452, 0.8960, 0.9833, 0.9960, 0.9305, 0.9882, 0.8594, 0.9518, 0.9941, 0.9963, 0.9726, 0.9839, 0.9203, 0.9395]], device='cuda:0')\n",
            "data: tensor([[[4.3477e+02, 1.8847e+02, 9.4284e-01],\n",
            "         [4.3778e+02, 1.8405e+02, 6.9349e-01],\n",
            "         [4.3333e+02, 1.8098e+02, 9.3534e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4523e-01],\n",
            "         [4.1740e+02, 1.6988e+02, 8.9596e-01],\n",
            "         [4.1661e+02, 1.8444e+02, 9.8331e-01],\n",
            "         [3.8157e+02, 1.8386e+02, 9.9603e-01],\n",
            "         [4.1627e+02, 2.2648e+02, 9.3047e-01],\n",
            "         [3.5270e+02, 2.4167e+02, 9.8819e-01],\n",
            "         [4.2235e+02, 2.7655e+02, 8.5940e-01],\n",
            "         [3.5331e+02, 2.9899e+02, 9.5182e-01],\n",
            "         [3.3993e+02, 2.0441e+02, 9.9410e-01],\n",
            "         [3.1461e+02, 1.9989e+02, 9.9627e-01],\n",
            "         [3.3590e+02, 2.3742e+02, 9.7260e-01],\n",
            "         [2.8495e+02, 2.3355e+02, 9.8391e-01],\n",
            "         [2.9007e+02, 2.2816e+02, 9.2032e-01],\n",
            "         [2.3053e+02, 2.2355e+02, 9.3947e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[434.7684, 188.4720],\n",
            "         [437.7784, 184.0485],\n",
            "         [433.3344, 180.9763],\n",
            "         [  0.0000,   0.0000],\n",
            "         [417.3971, 169.8788],\n",
            "         [416.6064, 184.4394],\n",
            "         [381.5686, 183.8642],\n",
            "         [416.2698, 226.4756],\n",
            "         [352.7021, 241.6718],\n",
            "         [422.3489, 276.5493],\n",
            "         [353.3060, 298.9865],\n",
            "         [339.9315, 204.4054],\n",
            "         [314.6097, 199.8926],\n",
            "         [335.8982, 237.4152],\n",
            "         [284.9514, 233.5492],\n",
            "         [290.0727, 228.1582],\n",
            "         [230.5263, 223.5468]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6793, 0.4908],\n",
            "         [0.6840, 0.4793],\n",
            "         [0.6771, 0.4713],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6522, 0.4424],\n",
            "         [0.6509, 0.4803],\n",
            "         [0.5962, 0.4788],\n",
            "         [0.6504, 0.5898],\n",
            "         [0.5511, 0.6294],\n",
            "         [0.6599, 0.7202],\n",
            "         [0.5520, 0.7786],\n",
            "         [0.5311, 0.5323],\n",
            "         [0.4916, 0.5206],\n",
            "         [0.5248, 0.6183],\n",
            "         [0.4452, 0.6082],\n",
            "         [0.4532, 0.5942],\n",
            "         [0.3602, 0.5822]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.7ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9390, 0.6871, 0.9329, 0.2582, 0.8934, 0.9809, 0.9961, 0.9188, 0.9881, 0.8500, 0.9525, 0.9934, 0.9961, 0.9730, 0.9850, 0.9262, 0.9456]], device='cuda:0')\n",
            "data: tensor([[[4.3510e+02, 1.9288e+02, 9.3900e-01],\n",
            "         [4.3890e+02, 1.8884e+02, 6.8711e-01],\n",
            "         [4.3455e+02, 1.8575e+02, 9.3294e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5816e-01],\n",
            "         [4.1967e+02, 1.7348e+02, 8.9340e-01],\n",
            "         [4.1604e+02, 1.8511e+02, 9.8089e-01],\n",
            "         [3.8362e+02, 1.8613e+02, 9.9609e-01],\n",
            "         [4.1575e+02, 2.2318e+02, 9.1885e-01],\n",
            "         [3.5138e+02, 2.4205e+02, 9.8813e-01],\n",
            "         [4.2277e+02, 2.7693e+02, 8.5004e-01],\n",
            "         [3.5345e+02, 2.9931e+02, 9.5246e-01],\n",
            "         [3.3657e+02, 2.0197e+02, 9.9339e-01],\n",
            "         [3.1438e+02, 1.9830e+02, 9.9609e-01],\n",
            "         [3.2007e+02, 2.3371e+02, 9.7295e-01],\n",
            "         [2.8204e+02, 2.3445e+02, 9.8501e-01],\n",
            "         [2.6901e+02, 2.2179e+02, 9.2616e-01],\n",
            "         [2.3258e+02, 2.2443e+02, 9.4556e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[435.0990, 192.8777],\n",
            "         [438.8975, 188.8438],\n",
            "         [434.5486, 185.7510],\n",
            "         [  0.0000,   0.0000],\n",
            "         [419.6699, 173.4765],\n",
            "         [416.0386, 185.1140],\n",
            "         [383.6167, 186.1335],\n",
            "         [415.7452, 223.1827],\n",
            "         [351.3755, 242.0464],\n",
            "         [422.7661, 276.9290],\n",
            "         [353.4498, 299.3065],\n",
            "         [336.5655, 201.9686],\n",
            "         [314.3810, 198.2982],\n",
            "         [320.0702, 233.7085],\n",
            "         [282.0441, 234.4481],\n",
            "         [269.0057, 221.7888],\n",
            "         [232.5760, 224.4279]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6798, 0.5023],\n",
            "         [0.6858, 0.4918],\n",
            "         [0.6790, 0.4837],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6557, 0.4518],\n",
            "         [0.6501, 0.4821],\n",
            "         [0.5994, 0.4847],\n",
            "         [0.6496, 0.5812],\n",
            "         [0.5490, 0.6303],\n",
            "         [0.6606, 0.7212],\n",
            "         [0.5523, 0.7794],\n",
            "         [0.5259, 0.5260],\n",
            "         [0.4912, 0.5164],\n",
            "         [0.5001, 0.6086],\n",
            "         [0.4407, 0.6105],\n",
            "         [0.4203, 0.5776],\n",
            "         [0.3634, 0.5844]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 1.6ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9362, 0.6781, 0.9306, 0.2585, 0.8930, 0.9798, 0.9957, 0.9164, 0.9870, 0.8496, 0.9498, 0.9923, 0.9953, 0.9682, 0.9816, 0.9147, 0.9353]], device='cuda:0')\n",
            "data: tensor([[[4.3771e+02, 1.9676e+02, 9.3625e-01],\n",
            "         [4.4181e+02, 1.9347e+02, 6.7812e-01],\n",
            "         [4.3825e+02, 1.8941e+02, 9.3058e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5851e-01],\n",
            "         [4.2367e+02, 1.7657e+02, 8.9299e-01],\n",
            "         [4.1526e+02, 1.8986e+02, 9.7977e-01],\n",
            "         [3.8574e+02, 1.8830e+02, 9.9567e-01],\n",
            "         [4.1334e+02, 2.2458e+02, 9.1640e-01],\n",
            "         [3.5026e+02, 2.4021e+02, 9.8701e-01],\n",
            "         [4.2246e+02, 2.7670e+02, 8.4965e-01],\n",
            "         [3.5331e+02, 2.9848e+02, 9.4977e-01],\n",
            "         [3.3602e+02, 2.0582e+02, 9.9227e-01],\n",
            "         [3.1556e+02, 2.0118e+02, 9.9531e-01],\n",
            "         [3.1864e+02, 2.3463e+02, 9.6816e-01],\n",
            "         [2.8137e+02, 2.3410e+02, 9.8164e-01],\n",
            "         [2.6926e+02, 2.2232e+02, 9.1468e-01],\n",
            "         [2.3363e+02, 2.2398e+02, 9.3531e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[437.7061, 196.7587],\n",
            "         [441.8062, 193.4682],\n",
            "         [438.2524, 189.4121],\n",
            "         [  0.0000,   0.0000],\n",
            "         [423.6689, 176.5704],\n",
            "         [415.2564, 189.8602],\n",
            "         [385.7424, 188.3045],\n",
            "         [413.3355, 224.5850],\n",
            "         [350.2560, 240.2068],\n",
            "         [422.4615, 276.6981],\n",
            "         [353.3133, 298.4784],\n",
            "         [336.0235, 205.8224],\n",
            "         [315.5644, 201.1792],\n",
            "         [318.6401, 234.6266],\n",
            "         [281.3653, 234.1046],\n",
            "         [269.2592, 222.3166],\n",
            "         [233.6285, 223.9793]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6839, 0.5124],\n",
            "         [0.6903, 0.5038],\n",
            "         [0.6848, 0.4933],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6620, 0.4598],\n",
            "         [0.6488, 0.4944],\n",
            "         [0.6027, 0.4904],\n",
            "         [0.6458, 0.5849],\n",
            "         [0.5473, 0.6255],\n",
            "         [0.6601, 0.7206],\n",
            "         [0.5521, 0.7773],\n",
            "         [0.5250, 0.5360],\n",
            "         [0.4931, 0.5239],\n",
            "         [0.4979, 0.6110],\n",
            "         [0.4396, 0.6096],\n",
            "         [0.4207, 0.5789],\n",
            "         [0.3650, 0.5833]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 1.5ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9429, 0.6881, 0.9359, 0.2485, 0.8917, 0.9799, 0.9957, 0.9192, 0.9874, 0.8645, 0.9573, 0.9921, 0.9954, 0.9685, 0.9817, 0.9266, 0.9432]], device='cuda:0')\n",
            "data: tensor([[[4.3768e+02, 2.0329e+02, 9.4293e-01],\n",
            "         [4.4164e+02, 2.0024e+02, 6.8808e-01],\n",
            "         [4.3757e+02, 1.9562e+02, 9.3589e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4852e-01],\n",
            "         [4.2271e+02, 1.8027e+02, 8.9168e-01],\n",
            "         [4.1668e+02, 1.9558e+02, 9.7993e-01],\n",
            "         [3.8544e+02, 1.9008e+02, 9.9566e-01],\n",
            "         [4.1038e+02, 2.3155e+02, 9.1921e-01],\n",
            "         [3.5199e+02, 2.4307e+02, 9.8736e-01],\n",
            "         [4.1866e+02, 2.7754e+02, 8.6454e-01],\n",
            "         [3.5799e+02, 2.9531e+02, 9.5727e-01],\n",
            "         [3.3810e+02, 2.1436e+02, 9.9207e-01],\n",
            "         [3.1883e+02, 2.0727e+02, 9.9539e-01],\n",
            "         [3.1606e+02, 2.4144e+02, 9.6854e-01],\n",
            "         [2.8803e+02, 2.3406e+02, 9.8171e-01],\n",
            "         [2.5891e+02, 2.2983e+02, 9.2660e-01],\n",
            "         [2.4501e+02, 2.2291e+02, 9.4323e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[437.6782, 203.2947],\n",
            "         [441.6354, 200.2364],\n",
            "         [437.5739, 195.6234],\n",
            "         [  0.0000,   0.0000],\n",
            "         [422.7064, 180.2709],\n",
            "         [416.6765, 195.5764],\n",
            "         [385.4377, 190.0829],\n",
            "         [410.3834, 231.5471],\n",
            "         [351.9923, 243.0700],\n",
            "         [418.6642, 277.5412],\n",
            "         [357.9932, 295.3086],\n",
            "         [338.1001, 214.3556],\n",
            "         [318.8332, 207.2724],\n",
            "         [316.0570, 241.4433],\n",
            "         [288.0266, 234.0593],\n",
            "         [258.9077, 229.8349],\n",
            "         [245.0137, 222.9143]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6839, 0.5294],\n",
            "         [0.6901, 0.5214],\n",
            "         [0.6837, 0.5094],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6605, 0.4695],\n",
            "         [0.6511, 0.5093],\n",
            "         [0.6022, 0.4950],\n",
            "         [0.6412, 0.6030],\n",
            "         [0.5500, 0.6330],\n",
            "         [0.6542, 0.7228],\n",
            "         [0.5594, 0.7690],\n",
            "         [0.5283, 0.5582],\n",
            "         [0.4982, 0.5398],\n",
            "         [0.4938, 0.6288],\n",
            "         [0.4500, 0.6095],\n",
            "         [0.4045, 0.5985],\n",
            "         [0.3828, 0.5805]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 1.8ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9439, 0.7000, 0.9359, 0.2516, 0.8878, 0.9807, 0.9950, 0.9264, 0.9854, 0.8753, 0.9539, 0.9922, 0.9950, 0.9681, 0.9795, 0.9237, 0.9369]], device='cuda:0')\n",
            "data: tensor([[[4.3936e+02, 2.0819e+02, 9.4388e-01],\n",
            "         [4.4292e+02, 2.0448e+02, 7.0004e-01],\n",
            "         [4.3838e+02, 2.0084e+02, 9.3594e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5162e-01],\n",
            "         [4.2267e+02, 1.8615e+02, 8.8780e-01],\n",
            "         [4.1700e+02, 1.9827e+02, 9.8069e-01],\n",
            "         [3.8652e+02, 1.9402e+02, 9.9500e-01],\n",
            "         [4.0810e+02, 2.2994e+02, 9.2640e-01],\n",
            "         [3.4940e+02, 2.4150e+02, 9.8539e-01],\n",
            "         [4.1754e+02, 2.7672e+02, 8.7533e-01],\n",
            "         [3.5575e+02, 2.9501e+02, 9.5394e-01],\n",
            "         [3.3768e+02, 2.1677e+02, 9.9222e-01],\n",
            "         [3.1865e+02, 2.1047e+02, 9.9503e-01],\n",
            "         [3.1650e+02, 2.4432e+02, 9.6811e-01],\n",
            "         [2.8964e+02, 2.3802e+02, 9.7950e-01],\n",
            "         [2.6169e+02, 2.3169e+02, 9.2367e-01],\n",
            "         [2.4513e+02, 2.2403e+02, 9.3694e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[439.3565, 208.1891],\n",
            "         [442.9220, 204.4834],\n",
            "         [438.3844, 200.8414],\n",
            "         [  0.0000,   0.0000],\n",
            "         [422.6714, 186.1461],\n",
            "         [417.0039, 198.2664],\n",
            "         [386.5184, 194.0200],\n",
            "         [408.0961, 229.9368],\n",
            "         [349.4043, 241.4968],\n",
            "         [417.5395, 276.7203],\n",
            "         [355.7503, 295.0110],\n",
            "         [337.6811, 216.7662],\n",
            "         [318.6527, 210.4747],\n",
            "         [316.4951, 244.3237],\n",
            "         [289.6430, 238.0232],\n",
            "         [261.6934, 231.6880],\n",
            "         [245.1269, 224.0306]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6865, 0.5422],\n",
            "         [0.6921, 0.5325],\n",
            "         [0.6850, 0.5230],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6604, 0.4848],\n",
            "         [0.6516, 0.5163],\n",
            "         [0.6039, 0.5053],\n",
            "         [0.6377, 0.5988],\n",
            "         [0.5459, 0.6289],\n",
            "         [0.6524, 0.7206],\n",
            "         [0.5559, 0.7683],\n",
            "         [0.5276, 0.5645],\n",
            "         [0.4979, 0.5481],\n",
            "         [0.4945, 0.6363],\n",
            "         [0.4526, 0.6199],\n",
            "         [0.4089, 0.6034],\n",
            "         [0.3830, 0.5834]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.6ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9385, 0.6367, 0.9404, 0.1989, 0.9083, 0.9732, 0.9955, 0.8975, 0.9888, 0.8467, 0.9627, 0.9903, 0.9951, 0.9619, 0.9803, 0.9143, 0.9375]], device='cuda:0')\n",
            "data: tensor([[[4.3966e+02, 2.1489e+02, 9.3855e-01],\n",
            "         [4.4244e+02, 2.1074e+02, 6.3673e-01],\n",
            "         [4.3874e+02, 2.0800e+02, 9.4036e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.9894e-01],\n",
            "         [4.2354e+02, 1.9208e+02, 9.0828e-01],\n",
            "         [4.1339e+02, 1.9991e+02, 9.7323e-01],\n",
            "         [3.8814e+02, 1.9685e+02, 9.9555e-01],\n",
            "         [4.0274e+02, 2.2977e+02, 8.9754e-01],\n",
            "         [3.4704e+02, 2.4137e+02, 9.8879e-01],\n",
            "         [4.1624e+02, 2.7729e+02, 8.4669e-01],\n",
            "         [3.5513e+02, 2.9508e+02, 9.6271e-01],\n",
            "         [3.3158e+02, 2.1993e+02, 9.9029e-01],\n",
            "         [3.1618e+02, 2.1428e+02, 9.9507e-01],\n",
            "         [3.0721e+02, 2.4432e+02, 9.6190e-01],\n",
            "         [2.8680e+02, 2.4068e+02, 9.8033e-01],\n",
            "         [2.5032e+02, 2.3102e+02, 9.1430e-01],\n",
            "         [2.3841e+02, 2.2650e+02, 9.3754e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[439.6609, 214.8909],\n",
            "         [442.4373, 210.7418],\n",
            "         [438.7444, 207.9968],\n",
            "         [  0.0000,   0.0000],\n",
            "         [423.5375, 192.0806],\n",
            "         [413.3924, 199.9073],\n",
            "         [388.1369, 196.8475],\n",
            "         [402.7405, 229.7700],\n",
            "         [347.0375, 241.3651],\n",
            "         [416.2401, 277.2853],\n",
            "         [355.1320, 295.0834],\n",
            "         [331.5849, 219.9263],\n",
            "         [316.1848, 214.2819],\n",
            "         [307.2086, 244.3175],\n",
            "         [286.7953, 240.6751],\n",
            "         [250.3210, 231.0178],\n",
            "         [238.4142, 226.4959]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6870, 0.5596],\n",
            "         [0.6913, 0.5488],\n",
            "         [0.6855, 0.5417],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6618, 0.5002],\n",
            "         [0.6459, 0.5206],\n",
            "         [0.6065, 0.5126],\n",
            "         [0.6293, 0.5984],\n",
            "         [0.5422, 0.6286],\n",
            "         [0.6504, 0.7221],\n",
            "         [0.5549, 0.7684],\n",
            "         [0.5181, 0.5727],\n",
            "         [0.4940, 0.5580],\n",
            "         [0.4800, 0.6362],\n",
            "         [0.4481, 0.6268],\n",
            "         [0.3911, 0.6016],\n",
            "         [0.3725, 0.5898]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.7ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9320, 0.6238, 0.9346, 0.1974, 0.9030, 0.9713, 0.9952, 0.8931, 0.9878, 0.8399, 0.9600, 0.9894, 0.9946, 0.9582, 0.9781, 0.9092, 0.9336]], device='cuda:0')\n",
            "data: tensor([[[4.4262e+02, 2.2178e+02, 9.3196e-01],\n",
            "         [4.4567e+02, 2.1807e+02, 6.2377e-01],\n",
            "         [4.4222e+02, 2.1496e+02, 9.3460e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.9740e-01],\n",
            "         [4.2711e+02, 1.9874e+02, 9.0304e-01],\n",
            "         [4.1632e+02, 2.0695e+02, 9.7127e-01],\n",
            "         [3.9028e+02, 2.0211e+02, 9.9518e-01],\n",
            "         [4.0459e+02, 2.3434e+02, 8.9310e-01],\n",
            "         [3.4737e+02, 2.4257e+02, 9.8784e-01],\n",
            "         [4.1523e+02, 2.7936e+02, 8.3989e-01],\n",
            "         [3.5364e+02, 2.9530e+02, 9.5996e-01],\n",
            "         [3.3415e+02, 2.2458e+02, 9.8943e-01],\n",
            "         [3.1846e+02, 2.1810e+02, 9.9461e-01],\n",
            "         [3.0540e+02, 2.4794e+02, 9.5821e-01],\n",
            "         [2.8630e+02, 2.4305e+02, 9.7810e-01],\n",
            "         [2.5112e+02, 2.2967e+02, 9.0925e-01],\n",
            "         [2.4294e+02, 2.2381e+02, 9.3359e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[442.6153, 221.7797],\n",
            "         [445.6716, 218.0681],\n",
            "         [442.2167, 214.9568],\n",
            "         [  0.0000,   0.0000],\n",
            "         [427.1050, 198.7393],\n",
            "         [416.3159, 206.9463],\n",
            "         [390.2806, 202.1097],\n",
            "         [404.5874, 234.3407],\n",
            "         [347.3728, 242.5681],\n",
            "         [415.2350, 279.3604],\n",
            "         [353.6391, 295.3011],\n",
            "         [334.1485, 224.5764],\n",
            "         [318.4597, 218.1040],\n",
            "         [305.3960, 247.9419],\n",
            "         [286.3040, 243.0479],\n",
            "         [251.1195, 229.6723],\n",
            "         [242.9351, 223.8054]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6916, 0.5776],\n",
            "         [0.6964, 0.5679],\n",
            "         [0.6910, 0.5598],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6674, 0.5176],\n",
            "         [0.6505, 0.5389],\n",
            "         [0.6098, 0.5263],\n",
            "         [0.6322, 0.6103],\n",
            "         [0.5428, 0.6317],\n",
            "         [0.6488, 0.7275],\n",
            "         [0.5526, 0.7690],\n",
            "         [0.5221, 0.5848],\n",
            "         [0.4976, 0.5680],\n",
            "         [0.4772, 0.6457],\n",
            "         [0.4473, 0.6329],\n",
            "         [0.3924, 0.5981],\n",
            "         [0.3796, 0.5828]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9085, 0.5971, 0.9047, 0.2038, 0.8657, 0.9707, 0.9931, 0.9058, 0.9830, 0.8617, 0.9496, 0.9908, 0.9942, 0.9621, 0.9763, 0.9140, 0.9304]], device='cuda:0')\n",
            "data: tensor([[[4.4396e+02, 2.2879e+02, 9.0848e-01],\n",
            "         [4.4739e+02, 2.2540e+02, 5.9713e-01],\n",
            "         [4.4458e+02, 2.2164e+02, 9.0471e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.0379e-01],\n",
            "         [4.2951e+02, 2.0587e+02, 8.6574e-01],\n",
            "         [4.1557e+02, 2.1496e+02, 9.7071e-01],\n",
            "         [3.9139e+02, 2.0800e+02, 9.9306e-01],\n",
            "         [4.0581e+02, 2.4180e+02, 9.0579e-01],\n",
            "         [3.4683e+02, 2.4561e+02, 9.8301e-01],\n",
            "         [4.1878e+02, 2.8063e+02, 8.6172e-01],\n",
            "         [3.5294e+02, 3.0196e+02, 9.4961e-01],\n",
            "         [3.3189e+02, 2.2467e+02, 9.9078e-01],\n",
            "         [3.1595e+02, 2.1783e+02, 9.9416e-01],\n",
            "         [3.0537e+02, 2.4940e+02, 9.6206e-01],\n",
            "         [2.8200e+02, 2.4732e+02, 9.7634e-01],\n",
            "         [2.5779e+02, 2.2064e+02, 9.1401e-01],\n",
            "         [2.3448e+02, 2.2086e+02, 9.3041e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[443.9625, 228.7867],\n",
            "         [447.3859, 225.3962],\n",
            "         [444.5773, 221.6411],\n",
            "         [  0.0000,   0.0000],\n",
            "         [429.5076, 205.8693],\n",
            "         [415.5664, 214.9621],\n",
            "         [391.3896, 208.0045],\n",
            "         [405.8083, 241.8007],\n",
            "         [346.8256, 245.6096],\n",
            "         [418.7809, 280.6278],\n",
            "         [352.9412, 301.9557],\n",
            "         [331.8860, 224.6695],\n",
            "         [315.9525, 217.8342],\n",
            "         [305.3675, 249.3967],\n",
            "         [282.0005, 247.3238],\n",
            "         [257.7910, 220.6426],\n",
            "         [234.4822, 220.8569]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6937, 0.5958],\n",
            "         [0.6990, 0.5870],\n",
            "         [0.6947, 0.5772],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6711, 0.5361],\n",
            "         [0.6493, 0.5598],\n",
            "         [0.6115, 0.5417],\n",
            "         [0.6341, 0.6297],\n",
            "         [0.5419, 0.6396],\n",
            "         [0.6543, 0.7308],\n",
            "         [0.5515, 0.7863],\n",
            "         [0.5186, 0.5851],\n",
            "         [0.4937, 0.5673],\n",
            "         [0.4771, 0.6495],\n",
            "         [0.4406, 0.6441],\n",
            "         [0.4028, 0.5746],\n",
            "         [0.3664, 0.5751]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.5ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8827, 0.5078, 0.8848, 0.1678, 0.8583, 0.9602, 0.9933, 0.8750, 0.9858, 0.8427, 0.9585, 0.9898, 0.9947, 0.9667, 0.9829, 0.9339, 0.9526]], device='cuda:0')\n",
            "data: tensor([[[4.4406e+02, 2.3530e+02, 8.8270e-01],\n",
            "         [4.4732e+02, 2.3218e+02, 5.0784e-01],\n",
            "         [4.4553e+02, 2.2882e+02, 8.8477e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.6781e-01],\n",
            "         [4.3244e+02, 2.1294e+02, 8.5826e-01],\n",
            "         [4.1568e+02, 2.2347e+02, 9.6019e-01],\n",
            "         [3.9389e+02, 2.1154e+02, 9.9330e-01],\n",
            "         [4.0480e+02, 2.5288e+02, 8.7501e-01],\n",
            "         [3.4332e+02, 2.4372e+02, 9.8584e-01],\n",
            "         [4.1935e+02, 2.8386e+02, 8.4274e-01],\n",
            "         [3.5382e+02, 3.0135e+02, 9.5847e-01],\n",
            "         [3.2996e+02, 2.3144e+02, 9.8977e-01],\n",
            "         [3.1656e+02, 2.2299e+02, 9.9470e-01],\n",
            "         [2.9246e+02, 2.4714e+02, 9.6673e-01],\n",
            "         [2.7992e+02, 2.4648e+02, 9.8289e-01],\n",
            "         [2.4853e+02, 2.1863e+02, 9.3387e-01],\n",
            "         [2.3819e+02, 2.2316e+02, 9.5264e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[444.0643, 235.3005],\n",
            "         [447.3154, 232.1848],\n",
            "         [445.5298, 228.8203],\n",
            "         [  0.0000,   0.0000],\n",
            "         [432.4359, 212.9376],\n",
            "         [415.6799, 223.4652],\n",
            "         [393.8857, 211.5388],\n",
            "         [404.7968, 252.8795],\n",
            "         [343.3156, 243.7221],\n",
            "         [419.3464, 283.8625],\n",
            "         [353.8192, 301.3548],\n",
            "         [329.9568, 231.4357],\n",
            "         [316.5568, 222.9857],\n",
            "         [292.4613, 247.1394],\n",
            "         [279.9218, 246.4768],\n",
            "         [248.5312, 218.6341],\n",
            "         [238.1882, 223.1632]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6939, 0.6128],\n",
            "         [0.6989, 0.6046],\n",
            "         [0.6961, 0.5959],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6757, 0.5545],\n",
            "         [0.6495, 0.5819],\n",
            "         [0.6154, 0.5509],\n",
            "         [0.6325, 0.6585],\n",
            "         [0.5364, 0.6347],\n",
            "         [0.6552, 0.7392],\n",
            "         [0.5528, 0.7848],\n",
            "         [0.5156, 0.6027],\n",
            "         [0.4946, 0.5807],\n",
            "         [0.4570, 0.6436],\n",
            "         [0.4374, 0.6419],\n",
            "         [0.3883, 0.5694],\n",
            "         [0.3722, 0.5812]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 1.7ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9245, 0.6601, 0.9230, 0.2458, 0.8763, 0.9688, 0.9943, 0.8806, 0.9848, 0.8501, 0.9559, 0.9893, 0.9942, 0.9684, 0.9831, 0.9404, 0.9566]], device='cuda:0')\n",
            "data: tensor([[[4.4477e+02, 2.4028e+02, 9.2452e-01],\n",
            "         [4.4993e+02, 2.3807e+02, 6.6011e-01],\n",
            "         [4.4694e+02, 2.3328e+02, 9.2295e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4575e-01],\n",
            "         [4.3432e+02, 2.1772e+02, 8.7629e-01],\n",
            "         [4.1850e+02, 2.3266e+02, 9.6884e-01],\n",
            "         [3.9368e+02, 2.1788e+02, 9.9429e-01],\n",
            "         [4.0605e+02, 2.5727e+02, 8.8058e-01],\n",
            "         [3.4218e+02, 2.4675e+02, 9.8479e-01],\n",
            "         [4.2015e+02, 2.8320e+02, 8.5009e-01],\n",
            "         [3.5439e+02, 3.0220e+02, 9.5591e-01],\n",
            "         [3.2933e+02, 2.3585e+02, 9.8929e-01],\n",
            "         [3.1459e+02, 2.2589e+02, 9.9421e-01],\n",
            "         [2.8681e+02, 2.4616e+02, 9.6844e-01],\n",
            "         [2.7503e+02, 2.4311e+02, 9.8310e-01],\n",
            "         [2.4044e+02, 2.1944e+02, 9.4038e-01],\n",
            "         [2.3827e+02, 2.2287e+02, 9.5665e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[444.7677, 240.2835],\n",
            "         [449.9308, 238.0678],\n",
            "         [446.9428, 233.2762],\n",
            "         [  0.0000,   0.0000],\n",
            "         [434.3178, 217.7177],\n",
            "         [418.5049, 232.6578],\n",
            "         [393.6805, 217.8753],\n",
            "         [406.0452, 257.2721],\n",
            "         [342.1804, 246.7514],\n",
            "         [420.1514, 283.1992],\n",
            "         [354.3878, 302.2002],\n",
            "         [329.3285, 235.8505],\n",
            "         [314.5901, 225.8896],\n",
            "         [286.8080, 246.1643],\n",
            "         [275.0339, 243.1129],\n",
            "         [240.4363, 219.4405],\n",
            "         [238.2729, 222.8749]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6949, 0.6257],\n",
            "         [0.7030, 0.6200],\n",
            "         [0.6983, 0.6075],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6786, 0.5670],\n",
            "         [0.6539, 0.6059],\n",
            "         [0.6151, 0.5674],\n",
            "         [0.6344, 0.6700],\n",
            "         [0.5347, 0.6426],\n",
            "         [0.6565, 0.7375],\n",
            "         [0.5537, 0.7870],\n",
            "         [0.5146, 0.6142],\n",
            "         [0.4915, 0.5883],\n",
            "         [0.4481, 0.6411],\n",
            "         [0.4297, 0.6331],\n",
            "         [0.3757, 0.5715],\n",
            "         [0.3723, 0.5804]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.4ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9135, 0.6156, 0.9197, 0.2409, 0.8871, 0.9619, 0.9945, 0.8503, 0.9861, 0.8260, 0.9584, 0.9869, 0.9937, 0.9634, 0.9827, 0.9349, 0.9564]], device='cuda:0')\n",
            "data: tensor([[[4.4543e+02, 2.4680e+02, 9.1351e-01],\n",
            "         [4.5089e+02, 2.4518e+02, 6.1555e-01],\n",
            "         [4.4907e+02, 2.3993e+02, 9.1968e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4088e-01],\n",
            "         [4.3859e+02, 2.2472e+02, 8.8709e-01],\n",
            "         [4.1597e+02, 2.3982e+02, 9.6186e-01],\n",
            "         [3.9645e+02, 2.2421e+02, 9.9450e-01],\n",
            "         [4.0053e+02, 2.6022e+02, 8.5033e-01],\n",
            "         [3.4015e+02, 2.4940e+02, 9.8611e-01],\n",
            "         [4.2211e+02, 2.8275e+02, 8.2597e-01],\n",
            "         [3.5548e+02, 3.0289e+02, 9.5842e-01],\n",
            "         [3.2577e+02, 2.3871e+02, 9.8688e-01],\n",
            "         [3.1442e+02, 2.2887e+02, 9.9372e-01],\n",
            "         [2.8773e+02, 2.4605e+02, 9.6339e-01],\n",
            "         [2.7810e+02, 2.4347e+02, 9.8273e-01],\n",
            "         [2.4248e+02, 2.1744e+02, 9.3494e-01],\n",
            "         [2.4139e+02, 2.2250e+02, 9.5635e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[445.4340, 246.8044],\n",
            "         [450.8946, 245.1764],\n",
            "         [449.0715, 239.9294],\n",
            "         [  0.0000,   0.0000],\n",
            "         [438.5859, 224.7201],\n",
            "         [415.9661, 239.8179],\n",
            "         [396.4468, 224.2072],\n",
            "         [400.5272, 260.2173],\n",
            "         [340.1517, 249.4022],\n",
            "         [422.1071, 282.7512],\n",
            "         [355.4812, 302.8865],\n",
            "         [325.7730, 238.7053],\n",
            "         [314.4194, 228.8741],\n",
            "         [287.7275, 246.0466],\n",
            "         [278.0979, 243.4680],\n",
            "         [242.4775, 217.4401],\n",
            "         [241.3907, 222.4992]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6960, 0.6427],\n",
            "         [0.7045, 0.6385],\n",
            "         [0.7017, 0.6248],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6853, 0.5852],\n",
            "         [0.6499, 0.6245],\n",
            "         [0.6194, 0.5839],\n",
            "         [0.6258, 0.6776],\n",
            "         [0.5315, 0.6495],\n",
            "         [0.6595, 0.7363],\n",
            "         [0.5554, 0.7888],\n",
            "         [0.5090, 0.6216],\n",
            "         [0.4913, 0.5960],\n",
            "         [0.4496, 0.6407],\n",
            "         [0.4345, 0.6340],\n",
            "         [0.3789, 0.5663],\n",
            "         [0.3772, 0.5794]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 1.5ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8661, 0.4929, 0.8789, 0.1984, 0.8619, 0.9490, 0.9932, 0.8325, 0.9863, 0.8095, 0.9578, 0.9870, 0.9941, 0.9616, 0.9829, 0.9285, 0.9541]], device='cuda:0')\n",
            "data: tensor([[[4.4523e+02, 2.5681e+02, 8.6614e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 4.9293e-01],\n",
            "         [4.4943e+02, 2.5091e+02, 8.7892e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.9844e-01],\n",
            "         [4.4027e+02, 2.3559e+02, 8.6189e-01],\n",
            "         [4.1605e+02, 2.4479e+02, 9.4898e-01],\n",
            "         [3.9817e+02, 2.3060e+02, 9.9323e-01],\n",
            "         [3.9964e+02, 2.5965e+02, 8.3255e-01],\n",
            "         [3.4187e+02, 2.5034e+02, 9.8631e-01],\n",
            "         [4.2366e+02, 2.8249e+02, 8.0951e-01],\n",
            "         [3.5541e+02, 3.0377e+02, 9.5784e-01],\n",
            "         [3.2725e+02, 2.3971e+02, 9.8702e-01],\n",
            "         [3.1636e+02, 2.3014e+02, 9.9415e-01],\n",
            "         [2.9095e+02, 2.5230e+02, 9.6162e-01],\n",
            "         [2.7949e+02, 2.4795e+02, 9.8288e-01],\n",
            "         [2.5095e+02, 2.2238e+02, 9.2852e-01],\n",
            "         [2.4317e+02, 2.2378e+02, 9.5411e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[445.2342, 256.8133],\n",
            "         [  0.0000,   0.0000],\n",
            "         [449.4325, 250.9085],\n",
            "         [  0.0000,   0.0000],\n",
            "         [440.2705, 235.5928],\n",
            "         [416.0492, 244.7877],\n",
            "         [398.1729, 230.5954],\n",
            "         [399.6431, 259.6537],\n",
            "         [341.8661, 250.3384],\n",
            "         [423.6620, 282.4868],\n",
            "         [355.4150, 303.7676],\n",
            "         [327.2476, 239.7140],\n",
            "         [316.3578, 230.1378],\n",
            "         [290.9488, 252.2970],\n",
            "         [279.4929, 247.9546],\n",
            "         [250.9517, 222.3788],\n",
            "         [243.1656, 223.7766]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6957, 0.6688],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7022, 0.6534],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6879, 0.6135],\n",
            "         [0.6501, 0.6375],\n",
            "         [0.6221, 0.6005],\n",
            "         [0.6244, 0.6762],\n",
            "         [0.5342, 0.6519],\n",
            "         [0.6620, 0.7356],\n",
            "         [0.5553, 0.7911],\n",
            "         [0.5113, 0.6243],\n",
            "         [0.4943, 0.5993],\n",
            "         [0.4546, 0.6570],\n",
            "         [0.4367, 0.6457],\n",
            "         [0.3921, 0.5791],\n",
            "         [0.3799, 0.5828]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.7ms preprocess, 10.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9198, 0.6113, 0.9354, 0.2391, 0.9141, 0.9548, 0.9958, 0.8183, 0.9905, 0.7886, 0.9680, 0.9841, 0.9942, 0.9553, 0.9834, 0.9185, 0.9530]], device='cuda:0')\n",
            "data: tensor([[[4.4740e+02, 2.6031e+02, 9.1982e-01],\n",
            "         [4.5254e+02, 2.5807e+02, 6.1131e-01],\n",
            "         [4.4984e+02, 2.5352e+02, 9.3540e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.3906e-01],\n",
            "         [4.3981e+02, 2.3741e+02, 9.1409e-01],\n",
            "         [4.2117e+02, 2.4853e+02, 9.5484e-01],\n",
            "         [4.0095e+02, 2.3438e+02, 9.9581e-01],\n",
            "         [4.0299e+02, 2.6066e+02, 8.1828e-01],\n",
            "         [3.4407e+02, 2.5222e+02, 9.9050e-01],\n",
            "         [4.2333e+02, 2.8279e+02, 7.8855e-01],\n",
            "         [3.5204e+02, 3.0023e+02, 9.6795e-01],\n",
            "         [3.3533e+02, 2.4247e+02, 9.8415e-01],\n",
            "         [3.2511e+02, 2.3260e+02, 9.9424e-01],\n",
            "         [2.9655e+02, 2.5093e+02, 9.5525e-01],\n",
            "         [2.8739e+02, 2.4453e+02, 9.8336e-01],\n",
            "         [2.4599e+02, 2.2885e+02, 9.1855e-01],\n",
            "         [2.5063e+02, 2.2755e+02, 9.5305e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[447.4023, 260.3104],\n",
            "         [452.5415, 258.0708],\n",
            "         [449.8419, 253.5202],\n",
            "         [  0.0000,   0.0000],\n",
            "         [439.8141, 237.4149],\n",
            "         [421.1657, 248.5336],\n",
            "         [400.9544, 234.3753],\n",
            "         [402.9911, 260.6614],\n",
            "         [344.0712, 252.2243],\n",
            "         [423.3300, 282.7899],\n",
            "         [352.0363, 300.2314],\n",
            "         [335.3347, 242.4681],\n",
            "         [325.1074, 232.5981],\n",
            "         [296.5518, 250.9344],\n",
            "         [287.3908, 244.5339],\n",
            "         [245.9883, 228.8488],\n",
            "         [250.6273, 227.5471]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6991, 0.6779],\n",
            "         [0.7071, 0.6721],\n",
            "         [0.7029, 0.6602],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6872, 0.6183],\n",
            "         [0.6581, 0.6472],\n",
            "         [0.6265, 0.6104],\n",
            "         [0.6297, 0.6788],\n",
            "         [0.5376, 0.6568],\n",
            "         [0.6615, 0.7364],\n",
            "         [0.5501, 0.7819],\n",
            "         [0.5240, 0.6314],\n",
            "         [0.5080, 0.6057],\n",
            "         [0.4634, 0.6535],\n",
            "         [0.4490, 0.6368],\n",
            "         [0.3844, 0.5960],\n",
            "         [0.3916, 0.5926]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 1.2ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9049, 0.5857, 0.9190, 0.2272, 0.8937, 0.9555, 0.9951, 0.8433, 0.9895, 0.8151, 0.9668, 0.9879, 0.9952, 0.9661, 0.9862, 0.9393, 0.9628]], device='cuda:0')\n",
            "data: tensor([[[4.4808e+02, 2.6381e+02, 9.0495e-01],\n",
            "         [4.5301e+02, 2.6196e+02, 5.8569e-01],\n",
            "         [4.5028e+02, 2.5805e+02, 9.1895e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.2719e-01],\n",
            "         [4.3900e+02, 2.4380e+02, 8.9370e-01],\n",
            "         [4.2254e+02, 2.5151e+02, 9.5546e-01],\n",
            "         [4.0095e+02, 2.4132e+02, 9.9510e-01],\n",
            "         [4.1153e+02, 2.5801e+02, 8.4329e-01],\n",
            "         [3.4599e+02, 2.5585e+02, 9.8947e-01],\n",
            "         [4.2953e+02, 2.8206e+02, 8.1514e-01],\n",
            "         [3.5189e+02, 3.0020e+02, 9.6676e-01],\n",
            "         [3.4094e+02, 2.4181e+02, 9.8792e-01],\n",
            "         [3.2967e+02, 2.3425e+02, 9.9519e-01],\n",
            "         [2.9539e+02, 2.4769e+02, 9.6610e-01],\n",
            "         [2.8551e+02, 2.4821e+02, 9.8623e-01],\n",
            "         [2.4749e+02, 2.1872e+02, 9.3927e-01],\n",
            "         [2.5286e+02, 2.2620e+02, 9.6278e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[448.0770, 263.8109],\n",
            "         [453.0116, 261.9571],\n",
            "         [450.2788, 258.0530],\n",
            "         [  0.0000,   0.0000],\n",
            "         [439.0011, 243.7951],\n",
            "         [422.5400, 251.5114],\n",
            "         [400.9500, 241.3173],\n",
            "         [411.5326, 258.0097],\n",
            "         [345.9901, 255.8549],\n",
            "         [429.5348, 282.0624],\n",
            "         [351.8857, 300.2048],\n",
            "         [340.9386, 241.8136],\n",
            "         [329.6660, 234.2483],\n",
            "         [295.3885, 247.6865],\n",
            "         [285.5142, 248.2106],\n",
            "         [247.4948, 218.7211],\n",
            "         [252.8593, 226.2014]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7001, 0.6870],\n",
            "         [0.7078, 0.6822],\n",
            "         [0.7036, 0.6720],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6859, 0.6349],\n",
            "         [0.6602, 0.6550],\n",
            "         [0.6265, 0.6284],\n",
            "         [0.6430, 0.6719],\n",
            "         [0.5406, 0.6663],\n",
            "         [0.6711, 0.7345],\n",
            "         [0.5498, 0.7818],\n",
            "         [0.5327, 0.6297],\n",
            "         [0.5151, 0.6100],\n",
            "         [0.4615, 0.6450],\n",
            "         [0.4461, 0.6464],\n",
            "         [0.3867, 0.5696],\n",
            "         [0.3951, 0.5891]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 1.4ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9245, 0.6654, 0.9367, 0.2588, 0.8979, 0.9532, 0.9954, 0.8280, 0.9901, 0.8065, 0.9689, 0.9868, 0.9951, 0.9639, 0.9864, 0.9379, 0.9641]], device='cuda:0')\n",
            "data: tensor([[[4.4664e+02, 2.7300e+02, 9.2452e-01],\n",
            "         [4.5275e+02, 2.7124e+02, 6.6541e-01],\n",
            "         [4.4892e+02, 2.6664e+02, 9.3670e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5878e-01],\n",
            "         [4.3797e+02, 2.4957e+02, 8.9792e-01],\n",
            "         [4.2546e+02, 2.5675e+02, 9.5321e-01],\n",
            "         [4.0073e+02, 2.4439e+02, 9.9545e-01],\n",
            "         [4.1386e+02, 2.6141e+02, 8.2805e-01],\n",
            "         [3.4684e+02, 2.5596e+02, 9.9005e-01],\n",
            "         [4.2847e+02, 2.8243e+02, 8.0650e-01],\n",
            "         [3.5028e+02, 2.9866e+02, 9.6893e-01],\n",
            "         [3.4519e+02, 2.4439e+02, 9.8683e-01],\n",
            "         [3.3203e+02, 2.3578e+02, 9.9513e-01],\n",
            "         [2.9676e+02, 2.5028e+02, 9.6390e-01],\n",
            "         [2.8456e+02, 2.4991e+02, 9.8641e-01],\n",
            "         [2.4872e+02, 2.1733e+02, 9.3795e-01],\n",
            "         [2.5484e+02, 2.2585e+02, 9.6407e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[446.6420, 273.0043],\n",
            "         [452.7547, 271.2427],\n",
            "         [448.9248, 266.6364],\n",
            "         [  0.0000,   0.0000],\n",
            "         [437.9658, 249.5711],\n",
            "         [425.4617, 256.7515],\n",
            "         [400.7287, 244.3885],\n",
            "         [413.8576, 261.4119],\n",
            "         [346.8374, 255.9605],\n",
            "         [428.4704, 282.4317],\n",
            "         [350.2814, 298.6617],\n",
            "         [345.1899, 244.3885],\n",
            "         [332.0268, 235.7849],\n",
            "         [296.7634, 250.2842],\n",
            "         [284.5609, 249.9097],\n",
            "         [248.7213, 217.3338],\n",
            "         [254.8380, 225.8511]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6979, 0.7109],\n",
            "         [0.7074, 0.7064],\n",
            "         [0.7014, 0.6944],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6843, 0.6499],\n",
            "         [0.6648, 0.6686],\n",
            "         [0.6261, 0.6364],\n",
            "         [0.6467, 0.6808],\n",
            "         [0.5419, 0.6666],\n",
            "         [0.6695, 0.7355],\n",
            "         [0.5473, 0.7778],\n",
            "         [0.5394, 0.6364],\n",
            "         [0.5188, 0.6140],\n",
            "         [0.4637, 0.6518],\n",
            "         [0.4446, 0.6508],\n",
            "         [0.3886, 0.5660],\n",
            "         [0.3982, 0.5882]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 1.3ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8306, 0.3982, 0.8678, 0.1343, 0.8640, 0.9227, 0.9941, 0.7775, 0.9909, 0.7868, 0.9722, 0.9893, 0.9965, 0.9735, 0.9914, 0.9569, 0.9776]], device='cuda:0')\n",
            "data: tensor([[[4.4925e+02, 2.7623e+02, 8.3061e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 3.9818e-01],\n",
            "         [4.5240e+02, 2.7087e+02, 8.6779e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.3428e-01],\n",
            "         [4.4045e+02, 2.5550e+02, 8.6397e-01],\n",
            "         [4.2301e+02, 2.6037e+02, 9.2266e-01],\n",
            "         [3.9933e+02, 2.4811e+02, 9.9414e-01],\n",
            "         [4.1159e+02, 2.6534e+02, 7.7750e-01],\n",
            "         [3.4422e+02, 2.5885e+02, 9.9087e-01],\n",
            "         [4.3077e+02, 2.8326e+02, 7.8680e-01],\n",
            "         [3.5180e+02, 3.0514e+02, 9.7216e-01],\n",
            "         [3.3635e+02, 2.4918e+02, 9.8935e-01],\n",
            "         [3.2236e+02, 2.4061e+02, 9.9646e-01],\n",
            "         [2.8756e+02, 2.5527e+02, 9.7345e-01],\n",
            "         [2.7840e+02, 2.5625e+02, 9.9138e-01],\n",
            "         [2.4380e+02, 2.1508e+02, 9.5688e-01],\n",
            "         [2.4845e+02, 2.2584e+02, 9.7758e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[449.2457, 276.2288],\n",
            "         [  0.0000,   0.0000],\n",
            "         [452.4041, 270.8663],\n",
            "         [  0.0000,   0.0000],\n",
            "         [440.4461, 255.5019],\n",
            "         [423.0136, 260.3712],\n",
            "         [399.3314, 248.1142],\n",
            "         [411.5947, 265.3448],\n",
            "         [344.2234, 258.8483],\n",
            "         [430.7710, 283.2646],\n",
            "         [351.7978, 305.1372],\n",
            "         [336.3503, 249.1761],\n",
            "         [322.3641, 240.6068],\n",
            "         [287.5604, 255.2697],\n",
            "         [278.3956, 256.2451],\n",
            "         [243.7994, 215.0819],\n",
            "         [248.4460, 225.8373]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7019, 0.7193],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7069, 0.7054],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6882, 0.6654],\n",
            "         [0.6610, 0.6781],\n",
            "         [0.6240, 0.6461],\n",
            "         [0.6431, 0.6910],\n",
            "         [0.5378, 0.6741],\n",
            "         [0.6731, 0.7377],\n",
            "         [0.5497, 0.7946],\n",
            "         [0.5255, 0.6489],\n",
            "         [0.5037, 0.6266],\n",
            "         [0.4493, 0.6648],\n",
            "         [0.4350, 0.6673],\n",
            "         [0.3809, 0.5601],\n",
            "         [0.3882, 0.5881]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 1.8ms preprocess, 13.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8903, 0.5096, 0.9264, 0.1506, 0.9085, 0.9212, 0.9955, 0.7406, 0.9923, 0.7676, 0.9761, 0.9866, 0.9961, 0.9683, 0.9909, 0.9519, 0.9769]], device='cuda:0')\n",
            "data: tensor([[[4.5047e+02, 2.8368e+02, 8.9026e-01],\n",
            "         [4.5785e+02, 2.8212e+02, 5.0958e-01],\n",
            "         [4.5333e+02, 2.7684e+02, 9.2640e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.5061e-01],\n",
            "         [4.3939e+02, 2.5855e+02, 9.0852e-01],\n",
            "         [4.2286e+02, 2.6526e+02, 9.2116e-01],\n",
            "         [3.9749e+02, 2.5068e+02, 9.9555e-01],\n",
            "         [4.0785e+02, 2.6751e+02, 7.4064e-01],\n",
            "         [3.4403e+02, 2.5810e+02, 9.9230e-01],\n",
            "         [4.2622e+02, 2.8261e+02, 7.6756e-01],\n",
            "         [3.5179e+02, 3.0382e+02, 9.7610e-01],\n",
            "         [3.3504e+02, 2.5209e+02, 9.8665e-01],\n",
            "         [3.2011e+02, 2.4289e+02, 9.9614e-01],\n",
            "         [2.8403e+02, 2.5529e+02, 9.6825e-01],\n",
            "         [2.7329e+02, 2.5619e+02, 9.9089e-01],\n",
            "         [2.4358e+02, 2.1315e+02, 9.5195e-01],\n",
            "         [2.5038e+02, 2.2624e+02, 9.7688e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.4736, 283.6782],\n",
            "         [457.8524, 282.1159],\n",
            "         [453.3257, 276.8368],\n",
            "         [  0.0000,   0.0000],\n",
            "         [439.3916, 258.5453],\n",
            "         [422.8585, 265.2632],\n",
            "         [397.4873, 250.6812],\n",
            "         [407.8456, 267.5106],\n",
            "         [344.0336, 258.0966],\n",
            "         [426.2242, 282.6103],\n",
            "         [351.7860, 303.8203],\n",
            "         [335.0371, 252.0907],\n",
            "         [320.1069, 242.8913],\n",
            "         [284.0274, 255.2864],\n",
            "         [273.2888, 256.1876],\n",
            "         [243.5828, 213.1519],\n",
            "         [250.3832, 226.2387]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7039, 0.7387],\n",
            "         [0.7154, 0.7347],\n",
            "         [0.7083, 0.7209],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6865, 0.6733],\n",
            "         [0.6607, 0.6908],\n",
            "         [0.6211, 0.6528],\n",
            "         [0.6373, 0.6966],\n",
            "         [0.5376, 0.6721],\n",
            "         [0.6660, 0.7360],\n",
            "         [0.5497, 0.7912],\n",
            "         [0.5235, 0.6565],\n",
            "         [0.5002, 0.6325],\n",
            "         [0.4438, 0.6648],\n",
            "         [0.4270, 0.6672],\n",
            "         [0.3806, 0.5551],\n",
            "         [0.3912, 0.5892]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 1.4ms preprocess, 14.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9135, 0.6021, 0.9367, 0.2264, 0.9065, 0.9318, 0.9951, 0.7685, 0.9907, 0.7728, 0.9710, 0.9788, 0.9934, 0.9476, 0.9827, 0.9182, 0.9556]], device='cuda:0')\n",
            "data: tensor([[[4.4748e+02, 2.8927e+02, 9.1354e-01],\n",
            "         [4.5512e+02, 2.8742e+02, 6.0214e-01],\n",
            "         [4.5151e+02, 2.8219e+02, 9.3665e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.2640e-01],\n",
            "         [4.4129e+02, 2.6188e+02, 9.0647e-01],\n",
            "         [4.2103e+02, 2.6885e+02, 9.3183e-01],\n",
            "         [4.0113e+02, 2.5299e+02, 9.9508e-01],\n",
            "         [4.0583e+02, 2.7048e+02, 7.6852e-01],\n",
            "         [3.4730e+02, 2.5673e+02, 9.9071e-01],\n",
            "         [4.2567e+02, 2.8961e+02, 7.7277e-01],\n",
            "         [3.5230e+02, 2.9807e+02, 9.7104e-01],\n",
            "         [3.3534e+02, 2.5186e+02, 9.7883e-01],\n",
            "         [3.2525e+02, 2.4218e+02, 9.9335e-01],\n",
            "         [2.8351e+02, 2.5007e+02, 9.4757e-01],\n",
            "         [2.7211e+02, 2.5105e+02, 9.8266e-01],\n",
            "         [2.4755e+02, 2.1307e+02, 9.1816e-01],\n",
            "         [2.5331e+02, 2.2719e+02, 9.5560e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[447.4815, 289.2737],\n",
            "         [455.1234, 287.4213],\n",
            "         [451.5145, 282.1899],\n",
            "         [  0.0000,   0.0000],\n",
            "         [441.2918, 261.8775],\n",
            "         [421.0283, 268.8544],\n",
            "         [401.1322, 252.9893],\n",
            "         [405.8303, 270.4771],\n",
            "         [347.2954, 256.7343],\n",
            "         [425.6715, 289.6106],\n",
            "         [352.2967, 298.0748],\n",
            "         [335.3398, 251.8640],\n",
            "         [325.2527, 242.1835],\n",
            "         [283.5149, 250.0688],\n",
            "         [272.1111, 251.0479],\n",
            "         [247.5494, 213.0708],\n",
            "         [253.3098, 227.1903]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6992, 0.7533],\n",
            "         [0.7111, 0.7485],\n",
            "         [0.7055, 0.7349],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6895, 0.6820],\n",
            "         [0.6579, 0.7001],\n",
            "         [0.6268, 0.6588],\n",
            "         [0.6341, 0.7044],\n",
            "         [0.5426, 0.6686],\n",
            "         [0.6651, 0.7542],\n",
            "         [0.5505, 0.7762],\n",
            "         [0.5240, 0.6559],\n",
            "         [0.5082, 0.6307],\n",
            "         [0.4430, 0.6512],\n",
            "         [0.4252, 0.6538],\n",
            "         [0.3868, 0.5549],\n",
            "         [0.3958, 0.5916]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 1.5ms preprocess, 15.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8836, 0.4921, 0.9189, 0.1758, 0.9028, 0.9198, 0.9945, 0.7641, 0.9907, 0.7788, 0.9714, 0.9800, 0.9937, 0.9530, 0.9843, 0.9284, 0.9607]], device='cuda:0')\n",
            "data: tensor([[[4.4833e+02, 2.9131e+02, 8.8365e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 4.9208e-01],\n",
            "         [4.5188e+02, 2.8505e+02, 9.1886e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.7577e-01],\n",
            "         [4.4079e+02, 2.6569e+02, 9.0279e-01],\n",
            "         [4.1817e+02, 2.6589e+02, 9.1980e-01],\n",
            "         [4.0164e+02, 2.5720e+02, 9.9446e-01],\n",
            "         [4.0654e+02, 2.6111e+02, 7.6413e-01],\n",
            "         [3.4970e+02, 2.5980e+02, 9.9069e-01],\n",
            "         [4.3075e+02, 2.8075e+02, 7.7876e-01],\n",
            "         [3.5347e+02, 2.9951e+02, 9.7140e-01],\n",
            "         [3.3264e+02, 2.5165e+02, 9.8000e-01],\n",
            "         [3.2462e+02, 2.4519e+02, 9.9373e-01],\n",
            "         [2.7905e+02, 2.4644e+02, 9.5295e-01],\n",
            "         [2.7005e+02, 2.5207e+02, 9.8430e-01],\n",
            "         [2.4774e+02, 2.1023e+02, 9.2838e-01],\n",
            "         [2.5352e+02, 2.2755e+02, 9.6067e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[448.3266, 291.3134],\n",
            "         [  0.0000,   0.0000],\n",
            "         [451.8819, 285.0540],\n",
            "         [  0.0000,   0.0000],\n",
            "         [440.7866, 265.6875],\n",
            "         [418.1682, 265.8902],\n",
            "         [401.6414, 257.2029],\n",
            "         [406.5445, 261.1074],\n",
            "         [349.6973, 259.8048],\n",
            "         [430.7462, 280.7452],\n",
            "         [353.4710, 299.5089],\n",
            "         [332.6382, 251.6505],\n",
            "         [324.6189, 245.1879],\n",
            "         [279.0488, 246.4409],\n",
            "         [270.0544, 252.0666],\n",
            "         [247.7384, 210.2264],\n",
            "         [253.5226, 227.5532]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7005, 0.7586],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7061, 0.7423],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6887, 0.6919],\n",
            "         [0.6534, 0.6924],\n",
            "         [0.6276, 0.6698],\n",
            "         [0.6352, 0.6800],\n",
            "         [0.5464, 0.6766],\n",
            "         [0.6730, 0.7311],\n",
            "         [0.5523, 0.7800],\n",
            "         [0.5197, 0.6553],\n",
            "         [0.5072, 0.6385],\n",
            "         [0.4360, 0.6418],\n",
            "         [0.4220, 0.6564],\n",
            "         [0.3871, 0.5475],\n",
            "         [0.3961, 0.5926]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8904, 0.5287, 0.9237, 0.1781, 0.8979, 0.9128, 0.9937, 0.7725, 0.9897, 0.8069, 0.9716, 0.9803, 0.9935, 0.9517, 0.9826, 0.9213, 0.9548]], device='cuda:0')\n",
            "data: tensor([[[4.4910e+02, 2.9681e+02, 8.9037e-01],\n",
            "         [4.5584e+02, 2.9371e+02, 5.2875e-01],\n",
            "         [4.5189e+02, 2.9077e+02, 9.2366e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.7809e-01],\n",
            "         [4.3984e+02, 2.7186e+02, 8.9787e-01],\n",
            "         [4.2234e+02, 2.6479e+02, 9.1281e-01],\n",
            "         [4.0112e+02, 2.6386e+02, 9.9370e-01],\n",
            "         [4.1197e+02, 2.4057e+02, 7.7247e-01],\n",
            "         [3.5022e+02, 2.6048e+02, 9.8967e-01],\n",
            "         [4.2572e+02, 2.4971e+02, 8.0689e-01],\n",
            "         [3.5276e+02, 2.9768e+02, 9.7160e-01],\n",
            "         [3.3856e+02, 2.4973e+02, 9.8030e-01],\n",
            "         [3.2739e+02, 2.4580e+02, 9.9350e-01],\n",
            "         [2.8174e+02, 2.4731e+02, 9.5166e-01],\n",
            "         [2.6901e+02, 2.5385e+02, 9.8260e-01],\n",
            "         [2.4948e+02, 2.1206e+02, 9.2126e-01],\n",
            "         [2.5430e+02, 2.2792e+02, 9.5482e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[449.1013, 296.8055],\n",
            "         [455.8397, 293.7108],\n",
            "         [451.8912, 290.7698],\n",
            "         [  0.0000,   0.0000],\n",
            "         [439.8392, 271.8610],\n",
            "         [422.3389, 264.7940],\n",
            "         [401.1163, 263.8551],\n",
            "         [411.9672, 240.5657],\n",
            "         [350.2159, 260.4759],\n",
            "         [425.7250, 249.7116],\n",
            "         [352.7635, 297.6770],\n",
            "         [338.5638, 249.7269],\n",
            "         [327.3914, 245.7981],\n",
            "         [281.7391, 247.3058],\n",
            "         [269.0147, 253.8485],\n",
            "         [249.4817, 212.0584],\n",
            "         [254.3018, 227.9160]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7017, 0.7729],\n",
            "         [0.7122, 0.7649],\n",
            "         [0.7061, 0.7572],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6872, 0.7080],\n",
            "         [0.6599, 0.6896],\n",
            "         [0.6267, 0.6871],\n",
            "         [0.6437, 0.6265],\n",
            "         [0.5472, 0.6783],\n",
            "         [0.6652, 0.6503],\n",
            "         [0.5512, 0.7752],\n",
            "         [0.5290, 0.6503],\n",
            "         [0.5115, 0.6401],\n",
            "         [0.4402, 0.6440],\n",
            "         [0.4203, 0.6611],\n",
            "         [0.3898, 0.5522],\n",
            "         [0.3973, 0.5935]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.6ms preprocess, 14.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9171, 0.6566, 0.9359, 0.2631, 0.8933, 0.9358, 0.9935, 0.8213, 0.9870, 0.8392, 0.9664, 0.9827, 0.9931, 0.9554, 0.9807, 0.9222, 0.9501]], device='cuda:0')\n",
            "data: tensor([[[4.4899e+02, 2.9701e+02, 9.1710e-01],\n",
            "         [4.5670e+02, 2.9490e+02, 6.5662e-01],\n",
            "         [4.5205e+02, 2.9129e+02, 9.3588e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.6314e-01],\n",
            "         [4.4061e+02, 2.7493e+02, 8.9326e-01],\n",
            "         [4.2451e+02, 2.6720e+02, 9.3581e-01],\n",
            "         [4.0202e+02, 2.6916e+02, 9.9350e-01],\n",
            "         [4.1317e+02, 2.3338e+02, 8.2127e-01],\n",
            "         [3.5154e+02, 2.6354e+02, 9.8702e-01],\n",
            "         [4.2202e+02, 2.4165e+02, 8.3921e-01],\n",
            "         [3.5276e+02, 2.9737e+02, 9.6637e-01],\n",
            "         [3.4162e+02, 2.4836e+02, 9.8274e-01],\n",
            "         [3.2923e+02, 2.4532e+02, 9.9307e-01],\n",
            "         [2.8766e+02, 2.4723e+02, 9.5541e-01],\n",
            "         [2.7124e+02, 2.5379e+02, 9.8066e-01],\n",
            "         [2.5098e+02, 2.1365e+02, 9.2221e-01],\n",
            "         [2.5557e+02, 2.2899e+02, 9.5011e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[448.9922, 297.0098],\n",
            "         [456.7025, 294.9021],\n",
            "         [452.0472, 291.2926],\n",
            "         [  0.0000,   0.0000],\n",
            "         [440.6088, 274.9250],\n",
            "         [424.5098, 267.2009],\n",
            "         [402.0171, 269.1591],\n",
            "         [413.1708, 233.3814],\n",
            "         [351.5410, 263.5448],\n",
            "         [422.0190, 241.6508],\n",
            "         [352.7650, 297.3682],\n",
            "         [341.6188, 248.3570],\n",
            "         [329.2326, 245.3225],\n",
            "         [287.6648, 247.2261],\n",
            "         [271.2358, 253.7921],\n",
            "         [250.9785, 213.6464],\n",
            "         [255.5688, 228.9883]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7016, 0.7735],\n",
            "         [0.7136, 0.7680],\n",
            "         [0.7063, 0.7586],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6885, 0.7160],\n",
            "         [0.6633, 0.6958],\n",
            "         [0.6282, 0.7009],\n",
            "         [0.6456, 0.6078],\n",
            "         [0.5493, 0.6863],\n",
            "         [0.6594, 0.6293],\n",
            "         [0.5512, 0.7744],\n",
            "         [0.5338, 0.6468],\n",
            "         [0.5144, 0.6389],\n",
            "         [0.4495, 0.6438],\n",
            "         [0.4238, 0.6609],\n",
            "         [0.3922, 0.5564],\n",
            "         [0.3993, 0.5963]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 1.7ms preprocess, 16.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9089, 0.6379, 0.9274, 0.2519, 0.8815, 0.9351, 0.9929, 0.8289, 0.9862, 0.8474, 0.9656, 0.9836, 0.9931, 0.9581, 0.9812, 0.9263, 0.9517]], device='cuda:0')\n",
            "data: tensor([[[4.4918e+02, 2.9831e+02, 9.0889e-01],\n",
            "         [4.5668e+02, 2.9617e+02, 6.3794e-01],\n",
            "         [4.5217e+02, 2.9266e+02, 9.2738e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5189e-01],\n",
            "         [4.4062e+02, 2.7623e+02, 8.8154e-01],\n",
            "         [4.2609e+02, 2.6726e+02, 9.3509e-01],\n",
            "         [4.0187e+02, 2.7094e+02, 9.9287e-01],\n",
            "         [4.1817e+02, 2.3148e+02, 8.2889e-01],\n",
            "         [3.5246e+02, 2.6607e+02, 9.8619e-01],\n",
            "         [4.2630e+02, 2.3844e+02, 8.4737e-01],\n",
            "         [3.5310e+02, 2.9786e+02, 9.6557e-01],\n",
            "         [3.4392e+02, 2.4790e+02, 9.8356e-01],\n",
            "         [3.3062e+02, 2.4550e+02, 9.9310e-01],\n",
            "         [2.8988e+02, 2.4630e+02, 9.5809e-01],\n",
            "         [2.7251e+02, 2.5371e+02, 9.8118e-01],\n",
            "         [2.5197e+02, 2.1268e+02, 9.2630e-01],\n",
            "         [2.5648e+02, 2.2880e+02, 9.5174e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[449.1763, 298.3051],\n",
            "         [456.6793, 296.1737],\n",
            "         [452.1667, 292.6589],\n",
            "         [  0.0000,   0.0000],\n",
            "         [440.6215, 276.2277],\n",
            "         [426.0916, 267.2565],\n",
            "         [401.8709, 270.9393],\n",
            "         [418.1711, 231.4844],\n",
            "         [352.4612, 266.0708],\n",
            "         [426.3002, 238.4425],\n",
            "         [353.0984, 297.8568],\n",
            "         [343.9209, 247.9033],\n",
            "         [330.6228, 245.4995],\n",
            "         [289.8764, 246.2956],\n",
            "         [272.5063, 253.7058],\n",
            "         [251.9728, 212.6781],\n",
            "         [256.4788, 228.8035]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7018, 0.7768],\n",
            "         [0.7136, 0.7713],\n",
            "         [0.7065, 0.7621],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6885, 0.7193],\n",
            "         [0.6658, 0.6960],\n",
            "         [0.6279, 0.7056],\n",
            "         [0.6534, 0.6028],\n",
            "         [0.5507, 0.6929],\n",
            "         [0.6661, 0.6209],\n",
            "         [0.5517, 0.7757],\n",
            "         [0.5374, 0.6456],\n",
            "         [0.5166, 0.6393],\n",
            "         [0.4529, 0.6414],\n",
            "         [0.4258, 0.6607],\n",
            "         [0.3937, 0.5538],\n",
            "         [0.4007, 0.5958]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 1.5ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8731, 0.5618, 0.8891, 0.2290, 0.8409, 0.9352, 0.9904, 0.8548, 0.9823, 0.8662, 0.9594, 0.9856, 0.9929, 0.9631, 0.9804, 0.9314, 0.9499]], device='cuda:0')\n",
            "data: tensor([[[4.5098e+02, 3.0010e+02, 8.7311e-01],\n",
            "         [4.5769e+02, 2.9777e+02, 5.6184e-01],\n",
            "         [4.5387e+02, 2.9515e+02, 8.8908e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.2903e-01],\n",
            "         [4.4208e+02, 2.7970e+02, 8.4094e-01],\n",
            "         [4.2686e+02, 2.6640e+02, 9.3516e-01],\n",
            "         [4.0265e+02, 2.7472e+02, 9.9043e-01],\n",
            "         [4.1959e+02, 2.2921e+02, 8.5478e-01],\n",
            "         [3.5337e+02, 2.7160e+02, 9.8235e-01],\n",
            "         [4.2798e+02, 2.3920e+02, 8.6618e-01],\n",
            "         [3.5298e+02, 2.9787e+02, 9.5936e-01],\n",
            "         [3.4435e+02, 2.4642e+02, 9.8562e-01],\n",
            "         [3.3107e+02, 2.4588e+02, 9.9288e-01],\n",
            "         [2.8941e+02, 2.4597e+02, 9.6309e-01],\n",
            "         [2.7244e+02, 2.5559e+02, 9.8042e-01],\n",
            "         [2.5263e+02, 2.1202e+02, 9.3143e-01],\n",
            "         [2.5669e+02, 2.2863e+02, 9.4994e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.9825, 300.1041],\n",
            "         [457.6907, 297.7736],\n",
            "         [453.8736, 295.1520],\n",
            "         [  0.0000,   0.0000],\n",
            "         [442.0789, 279.6969],\n",
            "         [426.8606, 266.4048],\n",
            "         [402.6515, 274.7234],\n",
            "         [419.5869, 229.2105],\n",
            "         [353.3702, 271.6009],\n",
            "         [427.9775, 239.1982],\n",
            "         [352.9788, 297.8733],\n",
            "         [344.3457, 246.4152],\n",
            "         [331.0702, 245.8789],\n",
            "         [289.4098, 245.9715],\n",
            "         [272.4397, 255.5917],\n",
            "         [252.6309, 212.0169],\n",
            "         [256.6861, 228.6273]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7047, 0.7815],\n",
            "         [0.7151, 0.7755],\n",
            "         [0.7092, 0.7686],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6907, 0.7284],\n",
            "         [0.6670, 0.6938],\n",
            "         [0.6291, 0.7154],\n",
            "         [0.6556, 0.5969],\n",
            "         [0.5521, 0.7073],\n",
            "         [0.6687, 0.6229],\n",
            "         [0.5515, 0.7757],\n",
            "         [0.5380, 0.6417],\n",
            "         [0.5173, 0.6403],\n",
            "         [0.4522, 0.6406],\n",
            "         [0.4257, 0.6656],\n",
            "         [0.3947, 0.5521],\n",
            "         [0.4011, 0.5954]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 1.7ms preprocess, 12.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8538, 0.5496, 0.8590, 0.2422, 0.8004, 0.9402, 0.9883, 0.8790, 0.9783, 0.8835, 0.9529, 0.9871, 0.9925, 0.9659, 0.9789, 0.9344, 0.9473]], device='cuda:0')\n",
            "data: tensor([[[4.5060e+02, 3.0104e+02, 8.5377e-01],\n",
            "         [4.5690e+02, 2.9843e+02, 5.4958e-01],\n",
            "         [4.5345e+02, 2.9635e+02, 8.5898e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4222e-01],\n",
            "         [4.4208e+02, 2.8110e+02, 8.0044e-01],\n",
            "         [4.2806e+02, 2.6437e+02, 9.4024e-01],\n",
            "         [4.0360e+02, 2.7692e+02, 9.8832e-01],\n",
            "         [4.2185e+02, 2.2516e+02, 8.7904e-01],\n",
            "         [3.5501e+02, 2.7552e+02, 9.7829e-01],\n",
            "         [4.2845e+02, 2.3973e+02, 8.8347e-01],\n",
            "         [3.5346e+02, 2.9947e+02, 9.5291e-01],\n",
            "         [3.4705e+02, 2.4445e+02, 9.8711e-01],\n",
            "         [3.3369e+02, 2.4553e+02, 9.9253e-01],\n",
            "         [2.9254e+02, 2.4498e+02, 9.6586e-01],\n",
            "         [2.7481e+02, 2.5626e+02, 9.7889e-01],\n",
            "         [2.5430e+02, 2.1003e+02, 9.3443e-01],\n",
            "         [2.5792e+02, 2.2675e+02, 9.4730e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.6044, 301.0397],\n",
            "         [456.9007, 298.4261],\n",
            "         [453.4468, 296.3493],\n",
            "         [  0.0000,   0.0000],\n",
            "         [442.0810, 281.1000],\n",
            "         [428.0582, 264.3671],\n",
            "         [403.6027, 276.9227],\n",
            "         [421.8538, 225.1627],\n",
            "         [355.0119, 275.5154],\n",
            "         [428.4470, 239.7275],\n",
            "         [353.4617, 299.4726],\n",
            "         [347.0484, 244.4510],\n",
            "         [333.6895, 245.5332],\n",
            "         [292.5372, 244.9788],\n",
            "         [274.8088, 256.2638],\n",
            "         [254.3010, 210.0251],\n",
            "         [257.9230, 226.7480]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7041, 0.7840],\n",
            "         [0.7139, 0.7772],\n",
            "         [0.7085, 0.7717],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6908, 0.7320],\n",
            "         [0.6688, 0.6885],\n",
            "         [0.6306, 0.7212],\n",
            "         [0.6591, 0.5864],\n",
            "         [0.5547, 0.7175],\n",
            "         [0.6694, 0.6243],\n",
            "         [0.5523, 0.7799],\n",
            "         [0.5423, 0.6366],\n",
            "         [0.5214, 0.6394],\n",
            "         [0.4571, 0.6380],\n",
            "         [0.4294, 0.6674],\n",
            "         [0.3973, 0.5469],\n",
            "         [0.4030, 0.5905]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 1.3ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8681, 0.5712, 0.8826, 0.2369, 0.8274, 0.9346, 0.9896, 0.8587, 0.9807, 0.8683, 0.9567, 0.9859, 0.9926, 0.9620, 0.9789, 0.9290, 0.9468]], device='cuda:0')\n",
            "data: tensor([[[4.5025e+02, 3.0326e+02, 8.6811e-01],\n",
            "         [4.5688e+02, 3.0068e+02, 5.7125e-01],\n",
            "         [4.5286e+02, 2.9821e+02, 8.8261e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.3686e-01],\n",
            "         [4.4088e+02, 2.8221e+02, 8.2743e-01],\n",
            "         [4.2871e+02, 2.6581e+02, 9.3457e-01],\n",
            "         [4.0234e+02, 2.7778e+02, 9.8959e-01],\n",
            "         [4.2286e+02, 2.2638e+02, 8.5865e-01],\n",
            "         [3.5443e+02, 2.7631e+02, 9.8069e-01],\n",
            "         [4.2697e+02, 2.4155e+02, 8.6826e-01],\n",
            "         [3.5487e+02, 3.0053e+02, 9.5669e-01],\n",
            "         [3.4861e+02, 2.4456e+02, 9.8586e-01],\n",
            "         [3.3394e+02, 2.4540e+02, 9.9265e-01],\n",
            "         [2.9485e+02, 2.4660e+02, 9.6198e-01],\n",
            "         [2.7519e+02, 2.5763e+02, 9.7895e-01],\n",
            "         [2.5328e+02, 2.0954e+02, 9.2896e-01],\n",
            "         [2.5688e+02, 2.2650e+02, 9.4680e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.2516, 303.2617],\n",
            "         [456.8766, 300.6812],\n",
            "         [452.8650, 298.2072],\n",
            "         [  0.0000,   0.0000],\n",
            "         [440.8832, 282.2092],\n",
            "         [428.7124, 265.8119],\n",
            "         [402.3382, 277.7844],\n",
            "         [422.8575, 226.3765],\n",
            "         [354.4270, 276.3146],\n",
            "         [426.9670, 241.5518],\n",
            "         [354.8665, 300.5278],\n",
            "         [348.6071, 244.5558],\n",
            "         [333.9414, 245.4043],\n",
            "         [294.8499, 246.6021],\n",
            "         [275.1947, 257.6313],\n",
            "         [253.2800, 209.5350],\n",
            "         [256.8844, 226.4954]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7035, 0.7897],\n",
            "         [0.7139, 0.7830],\n",
            "         [0.7076, 0.7766],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6889, 0.7349],\n",
            "         [0.6699, 0.6922],\n",
            "         [0.6287, 0.7234],\n",
            "         [0.6607, 0.5895],\n",
            "         [0.5538, 0.7196],\n",
            "         [0.6671, 0.6290],\n",
            "         [0.5545, 0.7826],\n",
            "         [0.5447, 0.6369],\n",
            "         [0.5218, 0.6391],\n",
            "         [0.4607, 0.6422],\n",
            "         [0.4300, 0.6709],\n",
            "         [0.3958, 0.5457],\n",
            "         [0.4014, 0.5898]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 1.6ms preprocess, 13.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8596, 0.5582, 0.8692, 0.2423, 0.8126, 0.9386, 0.9888, 0.8716, 0.9788, 0.8784, 0.9537, 0.9864, 0.9923, 0.9642, 0.9785, 0.9327, 0.9469]], device='cuda:0')\n",
            "data: tensor([[[4.5030e+02, 3.0384e+02, 8.5963e-01],\n",
            "         [4.5668e+02, 3.0112e+02, 5.5817e-01],\n",
            "         [4.5332e+02, 2.9893e+02, 8.6917e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4230e-01],\n",
            "         [4.4203e+02, 2.8280e+02, 8.1262e-01],\n",
            "         [4.2772e+02, 2.6529e+02, 9.3861e-01],\n",
            "         [4.0300e+02, 2.7878e+02, 9.8879e-01],\n",
            "         [4.2196e+02, 2.2611e+02, 8.7156e-01],\n",
            "         [3.5477e+02, 2.7882e+02, 9.7876e-01],\n",
            "         [4.2741e+02, 2.4049e+02, 8.7836e-01],\n",
            "         [3.5492e+02, 2.9989e+02, 9.5368e-01],\n",
            "         [3.4664e+02, 2.4505e+02, 9.8638e-01],\n",
            "         [3.3311e+02, 2.4649e+02, 9.9234e-01],\n",
            "         [2.9283e+02, 2.4509e+02, 9.6420e-01],\n",
            "         [2.7401e+02, 2.5685e+02, 9.7855e-01],\n",
            "         [2.5302e+02, 2.0878e+02, 9.3268e-01],\n",
            "         [2.5654e+02, 2.2604e+02, 9.4692e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.2997, 303.8394],\n",
            "         [456.6832, 301.1190],\n",
            "         [453.3206, 298.9290],\n",
            "         [  0.0000,   0.0000],\n",
            "         [442.0319, 282.7953],\n",
            "         [427.7198, 265.2899],\n",
            "         [402.9958, 278.7759],\n",
            "         [421.9613, 226.1072],\n",
            "         [354.7699, 278.8174],\n",
            "         [427.4127, 240.4881],\n",
            "         [354.9189, 299.8887],\n",
            "         [346.6399, 245.0494],\n",
            "         [333.1099, 246.4942],\n",
            "         [292.8314, 245.0935],\n",
            "         [274.0148, 256.8509],\n",
            "         [253.0239, 208.7837],\n",
            "         [256.5443, 226.0378]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7036, 0.7912],\n",
            "         [0.7136, 0.7842],\n",
            "         [0.7083, 0.7785],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6907, 0.7364],\n",
            "         [0.6683, 0.6909],\n",
            "         [0.6297, 0.7260],\n",
            "         [0.6593, 0.5888],\n",
            "         [0.5543, 0.7261],\n",
            "         [0.6678, 0.6263],\n",
            "         [0.5546, 0.7810],\n",
            "         [0.5416, 0.6381],\n",
            "         [0.5205, 0.6419],\n",
            "         [0.4575, 0.6383],\n",
            "         [0.4281, 0.6689],\n",
            "         [0.3953, 0.5437],\n",
            "         [0.4009, 0.5886]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 1.7ms preprocess, 14.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8666, 0.5805, 0.8746, 0.2618, 0.8154, 0.9416, 0.9891, 0.8739, 0.9782, 0.8781, 0.9518, 0.9861, 0.9920, 0.9629, 0.9773, 0.9301, 0.9443]], device='cuda:0')\n",
            "data: tensor([[[4.5014e+02, 3.0391e+02, 8.6662e-01],\n",
            "         [4.5643e+02, 3.0130e+02, 5.8050e-01],\n",
            "         [4.5350e+02, 2.9911e+02, 8.7462e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.6176e-01],\n",
            "         [4.4285e+02, 2.8294e+02, 8.1544e-01],\n",
            "         [4.2780e+02, 2.6468e+02, 9.4159e-01],\n",
            "         [4.0361e+02, 2.7959e+02, 9.8907e-01],\n",
            "         [4.2173e+02, 2.2530e+02, 8.7387e-01],\n",
            "         [3.5562e+02, 2.8104e+02, 9.7817e-01],\n",
            "         [4.2500e+02, 2.4104e+02, 8.7812e-01],\n",
            "         [3.5526e+02, 3.0040e+02, 9.5179e-01],\n",
            "         [3.4646e+02, 2.4513e+02, 9.8609e-01],\n",
            "         [3.3321e+02, 2.4695e+02, 9.9204e-01],\n",
            "         [2.9345e+02, 2.4538e+02, 9.6291e-01],\n",
            "         [2.7390e+02, 2.5706e+02, 9.7734e-01],\n",
            "         [2.5270e+02, 2.0901e+02, 9.3013e-01],\n",
            "         [2.5601e+02, 2.2561e+02, 9.4434e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.1367, 303.9059],\n",
            "         [456.4332, 301.3007],\n",
            "         [453.4990, 299.1096],\n",
            "         [  0.0000,   0.0000],\n",
            "         [442.8497, 282.9440],\n",
            "         [427.8012, 264.6805],\n",
            "         [403.6133, 279.5886],\n",
            "         [421.7330, 225.3004],\n",
            "         [355.6229, 281.0350],\n",
            "         [424.9990, 241.0365],\n",
            "         [355.2595, 300.3965],\n",
            "         [346.4604, 245.1330],\n",
            "         [333.2100, 246.9501],\n",
            "         [293.4500, 245.3802],\n",
            "         [273.9003, 257.0580],\n",
            "         [252.7023, 209.0086],\n",
            "         [256.0116, 225.6066]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7033, 0.7914],\n",
            "         [0.7132, 0.7846],\n",
            "         [0.7086, 0.7789],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6920, 0.7368],\n",
            "         [0.6684, 0.6893],\n",
            "         [0.6306, 0.7281],\n",
            "         [0.6590, 0.5867],\n",
            "         [0.5557, 0.7319],\n",
            "         [0.6641, 0.6277],\n",
            "         [0.5551, 0.7823],\n",
            "         [0.5413, 0.6384],\n",
            "         [0.5206, 0.6431],\n",
            "         [0.4585, 0.6390],\n",
            "         [0.4280, 0.6694],\n",
            "         [0.3948, 0.5443],\n",
            "         [0.4000, 0.5875]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 1.5ms preprocess, 12.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8700, 0.5871, 0.8784, 0.2655, 0.8193, 0.9425, 0.9893, 0.8745, 0.9785, 0.8786, 0.9521, 0.9863, 0.9922, 0.9634, 0.9777, 0.9317, 0.9456]], device='cuda:0')\n",
            "data: tensor([[[4.5055e+02, 3.0426e+02, 8.6997e-01],\n",
            "         [4.5701e+02, 3.0166e+02, 5.8711e-01],\n",
            "         [4.5393e+02, 2.9938e+02, 8.7839e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.6550e-01],\n",
            "         [4.4316e+02, 2.8321e+02, 8.1926e-01],\n",
            "         [4.2768e+02, 2.6528e+02, 9.4248e-01],\n",
            "         [4.0402e+02, 2.7991e+02, 9.8932e-01],\n",
            "         [4.2125e+02, 2.2556e+02, 8.7450e-01],\n",
            "         [3.5580e+02, 2.8088e+02, 9.7847e-01],\n",
            "         [4.2500e+02, 2.4114e+02, 8.7862e-01],\n",
            "         [3.5519e+02, 3.0052e+02, 9.5214e-01],\n",
            "         [3.4617e+02, 2.4561e+02, 9.8631e-01],\n",
            "         [3.3317e+02, 2.4735e+02, 9.9218e-01],\n",
            "         [2.9306e+02, 2.4545e+02, 9.6343e-01],\n",
            "         [2.7357e+02, 2.5720e+02, 9.7769e-01],\n",
            "         [2.5250e+02, 2.0821e+02, 9.3166e-01],\n",
            "         [2.5586e+02, 2.2506e+02, 9.4558e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.5467, 304.2567],\n",
            "         [457.0147, 301.6588],\n",
            "         [453.9305, 299.3760],\n",
            "         [  0.0000,   0.0000],\n",
            "         [443.1621, 283.2060],\n",
            "         [427.6797, 265.2814],\n",
            "         [404.0195, 279.9120],\n",
            "         [421.2494, 225.5618],\n",
            "         [355.7965, 280.8808],\n",
            "         [424.9970, 241.1384],\n",
            "         [355.1910, 300.5192],\n",
            "         [346.1720, 245.6114],\n",
            "         [333.1729, 247.3494],\n",
            "         [293.0636, 245.4514],\n",
            "         [273.5687, 257.1985],\n",
            "         [252.5018, 208.2079],\n",
            "         [255.8554, 225.0634]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7040, 0.7923],\n",
            "         [0.7141, 0.7856],\n",
            "         [0.7093, 0.7796],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6924, 0.7375],\n",
            "         [0.6682, 0.6908],\n",
            "         [0.6313, 0.7289],\n",
            "         [0.6582, 0.5874],\n",
            "         [0.5559, 0.7315],\n",
            "         [0.6641, 0.6280],\n",
            "         [0.5550, 0.7826],\n",
            "         [0.5409, 0.6396],\n",
            "         [0.5206, 0.6441],\n",
            "         [0.4579, 0.6392],\n",
            "         [0.4275, 0.6698],\n",
            "         [0.3945, 0.5422],\n",
            "         [0.3998, 0.5861]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 1.3ms preprocess, 14.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8636, 0.5695, 0.8727, 0.2538, 0.8157, 0.9407, 0.9891, 0.8730, 0.9787, 0.8777, 0.9528, 0.9863, 0.9923, 0.9636, 0.9781, 0.9316, 0.9459]], device='cuda:0')\n",
            "data: tensor([[[4.5014e+02, 3.0352e+02, 8.6363e-01],\n",
            "         [4.5645e+02, 3.0083e+02, 5.6950e-01],\n",
            "         [4.5339e+02, 2.9865e+02, 8.7269e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5377e-01],\n",
            "         [4.4252e+02, 2.8244e+02, 8.1567e-01],\n",
            "         [4.2736e+02, 2.6448e+02, 9.4065e-01],\n",
            "         [4.0353e+02, 2.7911e+02, 9.8914e-01],\n",
            "         [4.2130e+02, 2.2560e+02, 8.7299e-01],\n",
            "         [3.5580e+02, 2.8063e+02, 9.7874e-01],\n",
            "         [4.2554e+02, 2.4110e+02, 8.7772e-01],\n",
            "         [3.5558e+02, 3.0032e+02, 9.5283e-01],\n",
            "         [3.4615e+02, 2.4507e+02, 9.8633e-01],\n",
            "         [3.3311e+02, 2.4686e+02, 9.9226e-01],\n",
            "         [2.9325e+02, 2.4523e+02, 9.6363e-01],\n",
            "         [2.7408e+02, 2.5712e+02, 9.7807e-01],\n",
            "         [2.5242e+02, 2.0868e+02, 9.3157e-01],\n",
            "         [2.5585e+02, 2.2575e+02, 9.4586e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.1371, 303.5186],\n",
            "         [456.4457, 300.8317],\n",
            "         [453.3945, 298.6500],\n",
            "         [  0.0000,   0.0000],\n",
            "         [442.5236, 282.4385],\n",
            "         [427.3614, 264.4841],\n",
            "         [403.5262, 279.1077],\n",
            "         [421.2990, 225.5970],\n",
            "         [355.8021, 280.6349],\n",
            "         [425.5364, 241.1042],\n",
            "         [355.5838, 300.3233],\n",
            "         [346.1536, 245.0671],\n",
            "         [333.1098, 246.8578],\n",
            "         [293.2514, 245.2278],\n",
            "         [274.0767, 257.1248],\n",
            "         [252.4151, 208.6750],\n",
            "         [255.8482, 225.7483]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7033, 0.7904],\n",
            "         [0.7132, 0.7834],\n",
            "         [0.7084, 0.7777],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6914, 0.7355],\n",
            "         [0.6678, 0.6888],\n",
            "         [0.6305, 0.7268],\n",
            "         [0.6583, 0.5875],\n",
            "         [0.5559, 0.7308],\n",
            "         [0.6649, 0.6279],\n",
            "         [0.5556, 0.7821],\n",
            "         [0.5409, 0.6382],\n",
            "         [0.5205, 0.6429],\n",
            "         [0.4582, 0.6386],\n",
            "         [0.4282, 0.6696],\n",
            "         [0.3944, 0.5434],\n",
            "         [0.3998, 0.5879]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.3ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8614, 0.5653, 0.8705, 0.2479, 0.8116, 0.9377, 0.9890, 0.8685, 0.9794, 0.8753, 0.9545, 0.9861, 0.9924, 0.9628, 0.9783, 0.9302, 0.9460]], device='cuda:0')\n",
            "data: tensor([[[4.4979e+02, 3.0246e+02, 8.6136e-01],\n",
            "         [4.5638e+02, 2.9994e+02, 5.6534e-01],\n",
            "         [4.5289e+02, 2.9742e+02, 8.7045e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4792e-01],\n",
            "         [4.4188e+02, 2.8145e+02, 8.1159e-01],\n",
            "         [4.2811e+02, 2.6542e+02, 9.3766e-01],\n",
            "         [4.0314e+02, 2.7723e+02, 9.8895e-01],\n",
            "         [4.2190e+02, 2.2650e+02, 8.6848e-01],\n",
            "         [3.5476e+02, 2.7627e+02, 9.7943e-01],\n",
            "         [4.2713e+02, 2.4146e+02, 8.7535e-01],\n",
            "         [3.5510e+02, 2.9955e+02, 9.5455e-01],\n",
            "         [3.4699e+02, 2.4437e+02, 9.8614e-01],\n",
            "         [3.3326e+02, 2.4506e+02, 9.9239e-01],\n",
            "         [2.9385e+02, 2.4505e+02, 9.6283e-01],\n",
            "         [2.7466e+02, 2.5578e+02, 9.7830e-01],\n",
            "         [2.5273e+02, 2.0856e+02, 9.3023e-01],\n",
            "         [2.5611e+02, 2.2515e+02, 9.4598e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[449.7885, 302.4587],\n",
            "         [456.3796, 299.9403],\n",
            "         [452.8870, 297.4203],\n",
            "         [  0.0000,   0.0000],\n",
            "         [441.8753, 281.4523],\n",
            "         [428.1050, 265.4194],\n",
            "         [403.1415, 277.2331],\n",
            "         [421.8992, 226.5015],\n",
            "         [354.7552, 276.2664],\n",
            "         [427.1329, 241.4606],\n",
            "         [355.1033, 299.5497],\n",
            "         [346.9905, 244.3702],\n",
            "         [333.2582, 245.0608],\n",
            "         [293.8472, 245.0540],\n",
            "         [274.6592, 255.7821],\n",
            "         [252.7264, 208.5567],\n",
            "         [256.1129, 225.1546]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7028, 0.7877],\n",
            "         [0.7131, 0.7811],\n",
            "         [0.7076, 0.7745],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6904, 0.7329],\n",
            "         [0.6689, 0.6912],\n",
            "         [0.6299, 0.7220],\n",
            "         [0.6592, 0.5898],\n",
            "         [0.5543, 0.7194],\n",
            "         [0.6674, 0.6288],\n",
            "         [0.5548, 0.7801],\n",
            "         [0.5422, 0.6364],\n",
            "         [0.5207, 0.6382],\n",
            "         [0.4591, 0.6382],\n",
            "         [0.4292, 0.6661],\n",
            "         [0.3949, 0.5431],\n",
            "         [0.4002, 0.5863]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 2.1ms preprocess, 17.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8577, 0.5541, 0.8652, 0.2442, 0.8090, 0.9408, 0.9894, 0.8766, 0.9807, 0.8819, 0.9575, 0.9883, 0.9936, 0.9692, 0.9821, 0.9413, 0.9547]], device='cuda:0')\n",
            "data: tensor([[[4.5130e+02, 3.0022e+02, 8.5774e-01],\n",
            "         [4.5749e+02, 2.9775e+02, 5.5415e-01],\n",
            "         [4.5411e+02, 2.9551e+02, 8.6517e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4424e-01],\n",
            "         [4.4305e+02, 2.8040e+02, 8.0903e-01],\n",
            "         [4.2852e+02, 2.6445e+02, 9.4078e-01],\n",
            "         [4.0551e+02, 2.7602e+02, 9.8943e-01],\n",
            "         [4.2137e+02, 2.2603e+02, 8.7663e-01],\n",
            "         [3.5519e+02, 2.7458e+02, 9.8068e-01],\n",
            "         [4.2785e+02, 2.3816e+02, 8.8192e-01],\n",
            "         [3.5457e+02, 2.9674e+02, 9.5755e-01],\n",
            "         [3.4893e+02, 2.4612e+02, 9.8832e-01],\n",
            "         [3.3625e+02, 2.4689e+02, 9.9356e-01],\n",
            "         [2.9621e+02, 2.4642e+02, 9.6924e-01],\n",
            "         [2.7926e+02, 2.5759e+02, 9.8210e-01],\n",
            "         [2.5451e+02, 2.1119e+02, 9.4125e-01],\n",
            "         [2.5863e+02, 2.2803e+02, 9.5467e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[451.3028, 300.2199],\n",
            "         [457.4934, 297.7468],\n",
            "         [454.1113, 295.5125],\n",
            "         [  0.0000,   0.0000],\n",
            "         [443.0482, 280.3966],\n",
            "         [428.5175, 264.4527],\n",
            "         [405.5135, 276.0165],\n",
            "         [421.3689, 226.0257],\n",
            "         [355.1889, 274.5838],\n",
            "         [427.8511, 238.1557],\n",
            "         [354.5697, 296.7448],\n",
            "         [348.9307, 246.1178],\n",
            "         [336.2458, 246.8855],\n",
            "         [296.2131, 246.4233],\n",
            "         [279.2637, 257.5854],\n",
            "         [254.5102, 211.1929],\n",
            "         [258.6302, 228.0322]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7052, 0.7818],\n",
            "         [0.7148, 0.7754],\n",
            "         [0.7095, 0.7696],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6923, 0.7302],\n",
            "         [0.6696, 0.6887],\n",
            "         [0.6336, 0.7188],\n",
            "         [0.6584, 0.5886],\n",
            "         [0.5550, 0.7151],\n",
            "         [0.6685, 0.6202],\n",
            "         [0.5540, 0.7728],\n",
            "         [0.5452, 0.6409],\n",
            "         [0.5254, 0.6429],\n",
            "         [0.4628, 0.6417],\n",
            "         [0.4363, 0.6708],\n",
            "         [0.3977, 0.5500],\n",
            "         [0.4041, 0.5938]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 1.6ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8881, 0.5693, 0.9124, 0.2173, 0.8747, 0.9288, 0.9925, 0.8244, 0.9865, 0.8456, 0.9666, 0.9844, 0.9936, 0.9614, 0.9829, 0.9332, 0.9565]], device='cuda:0')\n",
            "data: tensor([[[4.5038e+02, 2.9885e+02, 8.8808e-01],\n",
            "         [4.5746e+02, 2.9632e+02, 5.6927e-01],\n",
            "         [4.5329e+02, 2.9321e+02, 9.1242e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.1731e-01],\n",
            "         [4.4145e+02, 2.7645e+02, 8.7469e-01],\n",
            "         [4.2496e+02, 2.6574e+02, 9.2877e-01],\n",
            "         [4.0253e+02, 2.7105e+02, 9.9252e-01],\n",
            "         [4.1492e+02, 2.3133e+02, 8.2440e-01],\n",
            "         [3.5213e+02, 2.6843e+02, 9.8650e-01],\n",
            "         [4.2462e+02, 2.3781e+02, 8.4563e-01],\n",
            "         [3.5431e+02, 2.9746e+02, 9.6662e-01],\n",
            "         [3.4370e+02, 2.4747e+02, 9.8440e-01],\n",
            "         [3.3143e+02, 2.4601e+02, 9.9357e-01],\n",
            "         [2.9057e+02, 2.4546e+02, 9.6142e-01],\n",
            "         [2.7448e+02, 2.5409e+02, 9.8291e-01],\n",
            "         [2.5277e+02, 2.1097e+02, 9.3317e-01],\n",
            "         [2.5755e+02, 2.2774e+02, 9.5654e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.3820, 298.8538],\n",
            "         [457.4557, 296.3243],\n",
            "         [453.2929, 293.2103],\n",
            "         [  0.0000,   0.0000],\n",
            "         [441.4462, 276.4544],\n",
            "         [424.9626, 265.7363],\n",
            "         [402.5341, 271.0492],\n",
            "         [414.9212, 231.3300],\n",
            "         [352.1290, 268.4285],\n",
            "         [424.6182, 237.8118],\n",
            "         [354.3127, 297.4607],\n",
            "         [343.6973, 247.4749],\n",
            "         [331.4256, 246.0099],\n",
            "         [290.5705, 245.4567],\n",
            "         [274.4756, 254.0926],\n",
            "         [252.7669, 210.9728],\n",
            "         [257.5470, 227.7392]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7037, 0.7783],\n",
            "         [0.7148, 0.7717],\n",
            "         [0.7083, 0.7636],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6898, 0.7199],\n",
            "         [0.6640, 0.6920],\n",
            "         [0.6290, 0.7059],\n",
            "         [0.6483, 0.6024],\n",
            "         [0.5502, 0.6990],\n",
            "         [0.6635, 0.6193],\n",
            "         [0.5536, 0.7746],\n",
            "         [0.5370, 0.6445],\n",
            "         [0.5179, 0.6407],\n",
            "         [0.4540, 0.6392],\n",
            "         [0.4289, 0.6617],\n",
            "         [0.3949, 0.5494],\n",
            "         [0.4024, 0.5931]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.3ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8895, 0.5353, 0.9222, 0.1977, 0.8985, 0.9205, 0.9938, 0.7877, 0.9891, 0.8128, 0.9695, 0.9814, 0.9935, 0.9527, 0.9819, 0.9210, 0.9529]], device='cuda:0')\n",
            "data: tensor([[[4.4840e+02, 2.9450e+02, 8.8946e-01],\n",
            "         [4.5517e+02, 2.9162e+02, 5.3533e-01],\n",
            "         [4.5161e+02, 2.8846e+02, 9.2218e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.9767e-01],\n",
            "         [4.4009e+02, 2.7006e+02, 8.9850e-01],\n",
            "         [4.1888e+02, 2.6180e+02, 9.2049e-01],\n",
            "         [4.0176e+02, 2.6442e+02, 9.9381e-01],\n",
            "         [4.0479e+02, 2.3592e+02, 7.8770e-01],\n",
            "         [3.5139e+02, 2.6566e+02, 9.8906e-01],\n",
            "         [4.1840e+02, 2.4214e+02, 8.1284e-01],\n",
            "         [3.5408e+02, 2.9848e+02, 9.6946e-01],\n",
            "         [3.3765e+02, 2.4734e+02, 9.8136e-01],\n",
            "         [3.2862e+02, 2.4510e+02, 9.9348e-01],\n",
            "         [2.8664e+02, 2.4766e+02, 9.5269e-01],\n",
            "         [2.7399e+02, 2.5539e+02, 9.8194e-01],\n",
            "         [2.5168e+02, 2.1028e+02, 9.2102e-01],\n",
            "         [2.5668e+02, 2.2684e+02, 9.5294e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[448.4029, 294.5013],\n",
            "         [455.1745, 291.6196],\n",
            "         [451.6076, 288.4579],\n",
            "         [  0.0000,   0.0000],\n",
            "         [440.0921, 270.0602],\n",
            "         [418.8753, 261.7966],\n",
            "         [401.7633, 264.4244],\n",
            "         [404.7896, 235.9182],\n",
            "         [351.3885, 265.6623],\n",
            "         [418.3969, 242.1432],\n",
            "         [354.0847, 298.4755],\n",
            "         [337.6533, 247.3432],\n",
            "         [328.6233, 245.0970],\n",
            "         [286.6429, 247.6634],\n",
            "         [273.9878, 255.3906],\n",
            "         [251.6824, 210.2820],\n",
            "         [256.6759, 226.8426]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7006, 0.7669],\n",
            "         [0.7112, 0.7594],\n",
            "         [0.7056, 0.7512],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6876, 0.7033],\n",
            "         [0.6545, 0.6818],\n",
            "         [0.6278, 0.6886],\n",
            "         [0.6325, 0.6144],\n",
            "         [0.5490, 0.6918],\n",
            "         [0.6537, 0.6306],\n",
            "         [0.5533, 0.7773],\n",
            "         [0.5276, 0.6441],\n",
            "         [0.5135, 0.6383],\n",
            "         [0.4479, 0.6450],\n",
            "         [0.4281, 0.6651],\n",
            "         [0.3933, 0.5476],\n",
            "         [0.4011, 0.5907]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 1.4ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9302, 0.6644, 0.9489, 0.2606, 0.9166, 0.9422, 0.9957, 0.7817, 0.9910, 0.7777, 0.9705, 0.9808, 0.9938, 0.9522, 0.9840, 0.9228, 0.9581]], device='cuda:0')\n",
            "data: tensor([[[4.4749e+02, 2.8914e+02, 9.3024e-01],\n",
            "         [4.5552e+02, 2.8756e+02, 6.6443e-01],\n",
            "         [4.5126e+02, 2.8229e+02, 9.4885e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.6065e-01],\n",
            "         [4.4066e+02, 2.6293e+02, 9.1661e-01],\n",
            "         [4.2258e+02, 2.6968e+02, 9.4222e-01],\n",
            "         [4.0180e+02, 2.5473e+02, 9.9571e-01],\n",
            "         [4.1072e+02, 2.7027e+02, 7.8166e-01],\n",
            "         [3.5174e+02, 2.5905e+02, 9.9096e-01],\n",
            "         [4.3227e+02, 2.8883e+02, 7.7769e-01],\n",
            "         [3.5346e+02, 2.9937e+02, 9.7046e-01],\n",
            "         [3.3652e+02, 2.5090e+02, 9.8076e-01],\n",
            "         [3.2587e+02, 2.4125e+02, 9.9384e-01],\n",
            "         [2.8256e+02, 2.5110e+02, 9.5216e-01],\n",
            "         [2.7052e+02, 2.5197e+02, 9.8405e-01],\n",
            "         [2.4602e+02, 2.1494e+02, 9.2279e-01],\n",
            "         [2.5219e+02, 2.2920e+02, 9.5805e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[447.4871, 289.1427],\n",
            "         [455.5165, 287.5590],\n",
            "         [451.2595, 282.2898],\n",
            "         [  0.0000,   0.0000],\n",
            "         [440.6608, 262.9308],\n",
            "         [422.5791, 269.6842],\n",
            "         [401.7973, 254.7323],\n",
            "         [410.7177, 270.2743],\n",
            "         [351.7411, 259.0504],\n",
            "         [432.2660, 288.8312],\n",
            "         [353.4642, 299.3661],\n",
            "         [336.5209, 250.8953],\n",
            "         [325.8679, 241.2452],\n",
            "         [282.5605, 251.0967],\n",
            "         [270.5197, 251.9677],\n",
            "         [246.0150, 214.9409],\n",
            "         [252.1894, 229.2045]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6992, 0.7530],\n",
            "         [0.7117, 0.7489],\n",
            "         [0.7051, 0.7351],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6885, 0.6847],\n",
            "         [0.6603, 0.7023],\n",
            "         [0.6278, 0.6634],\n",
            "         [0.6417, 0.7038],\n",
            "         [0.5496, 0.6746],\n",
            "         [0.6754, 0.7522],\n",
            "         [0.5523, 0.7796],\n",
            "         [0.5258, 0.6534],\n",
            "         [0.5092, 0.6282],\n",
            "         [0.4415, 0.6539],\n",
            "         [0.4227, 0.6562],\n",
            "         [0.3844, 0.5597],\n",
            "         [0.3940, 0.5969]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.5ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8636, 0.4491, 0.9009, 0.1492, 0.8930, 0.9279, 0.9951, 0.7690, 0.9916, 0.7798, 0.9732, 0.9883, 0.9963, 0.9727, 0.9915, 0.9567, 0.9780]], device='cuda:0')\n",
            "data: tensor([[[4.5032e+02, 2.7917e+02, 8.6364e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 4.4907e-01],\n",
            "         [4.5385e+02, 2.7388e+02, 9.0092e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.4924e-01],\n",
            "         [4.4143e+02, 2.5881e+02, 8.9304e-01],\n",
            "         [4.2149e+02, 2.6525e+02, 9.2785e-01],\n",
            "         [4.0079e+02, 2.5048e+02, 9.9507e-01],\n",
            "         [4.0935e+02, 2.6839e+02, 7.6903e-01],\n",
            "         [3.4805e+02, 2.5620e+02, 9.9164e-01],\n",
            "         [4.3093e+02, 2.8439e+02, 7.7984e-01],\n",
            "         [3.5125e+02, 3.0394e+02, 9.7321e-01],\n",
            "         [3.3341e+02, 2.5180e+02, 9.8831e-01],\n",
            "         [3.2149e+02, 2.4195e+02, 9.9631e-01],\n",
            "         [2.8030e+02, 2.5403e+02, 9.7275e-01],\n",
            "         [2.7266e+02, 2.5360e+02, 9.9147e-01],\n",
            "         [2.4270e+02, 2.1746e+02, 9.5674e-01],\n",
            "         [2.4863e+02, 2.2815e+02, 9.7802e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.3215, 279.1674],\n",
            "         [  0.0000,   0.0000],\n",
            "         [453.8487, 273.8802],\n",
            "         [  0.0000,   0.0000],\n",
            "         [441.4310, 258.8079],\n",
            "         [421.4948, 265.2521],\n",
            "         [400.7858, 250.4789],\n",
            "         [409.3541, 268.3915],\n",
            "         [348.0535, 256.1984],\n",
            "         [430.9288, 284.3855],\n",
            "         [351.2465, 303.9414],\n",
            "         [333.4052, 251.8024],\n",
            "         [321.4854, 241.9473],\n",
            "         [280.3032, 254.0275],\n",
            "         [272.6565, 253.6027],\n",
            "         [242.7022, 217.4577],\n",
            "         [248.6316, 228.1500]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7036, 0.7270],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7091, 0.7132],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6897, 0.6740],\n",
            "         [0.6586, 0.6908],\n",
            "         [0.6262, 0.6523],\n",
            "         [0.6396, 0.6989],\n",
            "         [0.5438, 0.6672],\n",
            "         [0.6733, 0.7406],\n",
            "         [0.5488, 0.7915],\n",
            "         [0.5209, 0.6557],\n",
            "         [0.5023, 0.6301],\n",
            "         [0.4380, 0.6615],\n",
            "         [0.4260, 0.6604],\n",
            "         [0.3792, 0.5663],\n",
            "         [0.3885, 0.5941]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 1.4ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9180, 0.6212, 0.9324, 0.2300, 0.9019, 0.9558, 0.9954, 0.8442, 0.9903, 0.8245, 0.9701, 0.9890, 0.9958, 0.9722, 0.9890, 0.9522, 0.9713]], device='cuda:0')\n",
            "data: tensor([[[4.5171e+02, 2.7253e+02, 9.1804e-01],\n",
            "         [4.5744e+02, 2.7064e+02, 6.2121e-01],\n",
            "         [4.5362e+02, 2.6679e+02, 9.3242e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.3004e-01],\n",
            "         [4.4112e+02, 2.5194e+02, 9.0194e-01],\n",
            "         [4.2498e+02, 2.5885e+02, 9.5583e-01],\n",
            "         [4.0353e+02, 2.4630e+02, 9.9544e-01],\n",
            "         [4.1135e+02, 2.6221e+02, 8.4416e-01],\n",
            "         [3.4930e+02, 2.5350e+02, 9.9034e-01],\n",
            "         [4.2778e+02, 2.8251e+02, 8.2447e-01],\n",
            "         [3.5075e+02, 2.9792e+02, 9.7006e-01],\n",
            "         [3.4036e+02, 2.4580e+02, 9.8903e-01],\n",
            "         [3.2903e+02, 2.3714e+02, 9.9579e-01],\n",
            "         [2.8884e+02, 2.4754e+02, 9.7221e-01],\n",
            "         [2.8002e+02, 2.4807e+02, 9.8902e-01],\n",
            "         [2.4601e+02, 2.1788e+02, 9.5225e-01],\n",
            "         [2.5206e+02, 2.2722e+02, 9.7129e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[451.7131, 272.5287],\n",
            "         [457.4371, 270.6420],\n",
            "         [453.6224, 266.7943],\n",
            "         [  0.0000,   0.0000],\n",
            "         [441.1199, 251.9378],\n",
            "         [424.9846, 258.8463],\n",
            "         [403.5264, 246.2981],\n",
            "         [411.3534, 262.2143],\n",
            "         [349.3013, 253.4972],\n",
            "         [427.7763, 282.5065],\n",
            "         [350.7504, 297.9232],\n",
            "         [340.3593, 245.8025],\n",
            "         [329.0337, 237.1355],\n",
            "         [288.8416, 247.5352],\n",
            "         [280.0220, 248.0744],\n",
            "         [246.0133, 217.8848],\n",
            "         [252.0585, 227.2250]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7058, 0.7097],\n",
            "         [0.7147, 0.7048],\n",
            "         [0.7088, 0.6948],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6892, 0.6561],\n",
            "         [0.6640, 0.6741],\n",
            "         [0.6305, 0.6414],\n",
            "         [0.6427, 0.6828],\n",
            "         [0.5458, 0.6601],\n",
            "         [0.6684, 0.7357],\n",
            "         [0.5480, 0.7758],\n",
            "         [0.5318, 0.6401],\n",
            "         [0.5141, 0.6175],\n",
            "         [0.4513, 0.6446],\n",
            "         [0.4375, 0.6460],\n",
            "         [0.3844, 0.5674],\n",
            "         [0.3938, 0.5917]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 1.4ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9012, 0.5471, 0.9176, 0.1965, 0.8986, 0.9563, 0.9954, 0.8490, 0.9904, 0.8237, 0.9695, 0.9898, 0.9960, 0.9742, 0.9895, 0.9542, 0.9720]], device='cuda:0')\n",
            "data: tensor([[[4.5337e+02, 2.6365e+02, 9.0122e-01],\n",
            "         [4.5788e+02, 2.6127e+02, 5.4712e-01],\n",
            "         [4.5500e+02, 2.5803e+02, 9.1765e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.9650e-01],\n",
            "         [4.4239e+02, 2.4374e+02, 8.9858e-01],\n",
            "         [4.2386e+02, 2.5158e+02, 9.5635e-01],\n",
            "         [4.0485e+02, 2.3924e+02, 9.9536e-01],\n",
            "         [4.0806e+02, 2.6129e+02, 8.4897e-01],\n",
            "         [3.4901e+02, 2.5145e+02, 9.9036e-01],\n",
            "         [4.2667e+02, 2.8197e+02, 8.2372e-01],\n",
            "         [3.5077e+02, 2.9749e+02, 9.6946e-01],\n",
            "         [3.3912e+02, 2.4404e+02, 9.8982e-01],\n",
            "         [3.2943e+02, 2.3534e+02, 9.9602e-01],\n",
            "         [2.8952e+02, 2.4813e+02, 9.7415e-01],\n",
            "         [2.8383e+02, 2.4707e+02, 9.8954e-01],\n",
            "         [2.4685e+02, 2.2201e+02, 9.5419e-01],\n",
            "         [2.5254e+02, 2.2752e+02, 9.7201e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[453.3700, 263.6514],\n",
            "         [457.8802, 261.2725],\n",
            "         [454.9991, 258.0251],\n",
            "         [  0.0000,   0.0000],\n",
            "         [442.3943, 243.7361],\n",
            "         [423.8648, 251.5776],\n",
            "         [404.8511, 239.2404],\n",
            "         [408.0554, 261.2937],\n",
            "         [349.0107, 251.4457],\n",
            "         [426.6706, 281.9746],\n",
            "         [350.7714, 297.4936],\n",
            "         [339.1175, 244.0426],\n",
            "         [329.4341, 235.3415],\n",
            "         [289.5236, 248.1299],\n",
            "         [283.8315, 247.0719],\n",
            "         [246.8486, 222.0116],\n",
            "         [252.5356, 227.5209]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7084, 0.6866],\n",
            "         [0.7154, 0.6804],\n",
            "         [0.7109, 0.6719],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6912, 0.6347],\n",
            "         [0.6623, 0.6552],\n",
            "         [0.6326, 0.6230],\n",
            "         [0.6376, 0.6805],\n",
            "         [0.5453, 0.6548],\n",
            "         [0.6667, 0.7343],\n",
            "         [0.5481, 0.7747],\n",
            "         [0.5299, 0.6355],\n",
            "         [0.5147, 0.6129],\n",
            "         [0.4524, 0.6462],\n",
            "         [0.4435, 0.6434],\n",
            "         [0.3857, 0.5782],\n",
            "         [0.3946, 0.5925]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.7ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9115, 0.5778, 0.9271, 0.2236, 0.9056, 0.9534, 0.9957, 0.8249, 0.9907, 0.7971, 0.9684, 0.9861, 0.9950, 0.9618, 0.9856, 0.9333, 0.9613]], device='cuda:0')\n",
            "data: tensor([[[4.5069e+02, 2.5931e+02, 9.1152e-01],\n",
            "         [4.5606e+02, 2.5718e+02, 5.7784e-01],\n",
            "         [4.5350e+02, 2.5266e+02, 9.2711e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.2356e-01],\n",
            "         [4.4320e+02, 2.3577e+02, 9.0564e-01],\n",
            "         [4.2221e+02, 2.4660e+02, 9.5338e-01],\n",
            "         [4.0431e+02, 2.3179e+02, 9.9571e-01],\n",
            "         [4.0158e+02, 2.5881e+02, 8.2494e-01],\n",
            "         [3.4926e+02, 2.4787e+02, 9.9072e-01],\n",
            "         [4.2121e+02, 2.8165e+02, 7.9708e-01],\n",
            "         [3.5248e+02, 2.9792e+02, 9.6838e-01],\n",
            "         [3.3562e+02, 2.4397e+02, 9.8608e-01],\n",
            "         [3.2643e+02, 2.3364e+02, 9.9495e-01],\n",
            "         [2.9212e+02, 2.5100e+02, 9.6176e-01],\n",
            "         [2.8434e+02, 2.4410e+02, 9.8558e-01],\n",
            "         [2.4847e+02, 2.2614e+02, 9.3326e-01],\n",
            "         [2.5386e+02, 2.2483e+02, 9.6133e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.6890, 259.3138],\n",
            "         [456.0610, 257.1764],\n",
            "         [453.5020, 252.6566],\n",
            "         [  0.0000,   0.0000],\n",
            "         [443.2014, 235.7686],\n",
            "         [422.2067, 246.5992],\n",
            "         [404.3130, 231.7861],\n",
            "         [401.5849, 258.8086],\n",
            "         [349.2584, 247.8736],\n",
            "         [421.2150, 281.6519],\n",
            "         [352.4802, 297.9212],\n",
            "         [335.6171, 243.9687],\n",
            "         [326.4283, 233.6416],\n",
            "         [292.1221, 250.9959],\n",
            "         [284.3433, 244.0988],\n",
            "         [248.4702, 226.1410],\n",
            "         [253.8560, 224.8260]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7042, 0.6753],\n",
            "         [0.7126, 0.6697],\n",
            "         [0.7086, 0.6580],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6925, 0.6140],\n",
            "         [0.6597, 0.6422],\n",
            "         [0.6317, 0.6036],\n",
            "         [0.6275, 0.6740],\n",
            "         [0.5457, 0.6455],\n",
            "         [0.6581, 0.7335],\n",
            "         [0.5508, 0.7758],\n",
            "         [0.5244, 0.6353],\n",
            "         [0.5100, 0.6084],\n",
            "         [0.4564, 0.6536],\n",
            "         [0.4443, 0.6357],\n",
            "         [0.3882, 0.5889],\n",
            "         [0.3967, 0.5855]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 18.8ms\n",
            "Speed: 2.4ms preprocess, 18.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8624, 0.4565, 0.8774, 0.1717, 0.8719, 0.9525, 0.9937, 0.8366, 0.9865, 0.8150, 0.9586, 0.9879, 0.9945, 0.9674, 0.9850, 0.9402, 0.9608]], device='cuda:0')\n",
            "data: tensor([[[4.5254e+02, 2.4706e+02, 8.6240e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 4.5653e-01],\n",
            "         [4.5585e+02, 2.4105e+02, 8.7736e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.7175e-01],\n",
            "         [4.4369e+02, 2.2835e+02, 8.7193e-01],\n",
            "         [4.1961e+02, 2.4339e+02, 9.5249e-01],\n",
            "         [4.0066e+02, 2.2665e+02, 9.9374e-01],\n",
            "         [4.0147e+02, 2.6460e+02, 8.3655e-01],\n",
            "         [3.4555e+02, 2.4820e+02, 9.8646e-01],\n",
            "         [4.2203e+02, 2.8321e+02, 8.1500e-01],\n",
            "         [3.5551e+02, 3.0272e+02, 9.5858e-01],\n",
            "         [3.2858e+02, 2.4073e+02, 9.8787e-01],\n",
            "         [3.1739e+02, 2.2984e+02, 9.9451e-01],\n",
            "         [2.8481e+02, 2.5056e+02, 9.6736e-01],\n",
            "         [2.7655e+02, 2.4477e+02, 9.8505e-01],\n",
            "         [2.4866e+02, 2.2276e+02, 9.4015e-01],\n",
            "         [2.4478e+02, 2.2314e+02, 9.6076e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[452.5446, 247.0640],\n",
            "         [  0.0000,   0.0000],\n",
            "         [455.8519, 241.0505],\n",
            "         [  0.0000,   0.0000],\n",
            "         [443.6870, 228.3476],\n",
            "         [419.6108, 243.3879],\n",
            "         [400.6588, 226.6514],\n",
            "         [401.4716, 264.5978],\n",
            "         [345.5487, 248.2044],\n",
            "         [422.0341, 283.2059],\n",
            "         [355.5064, 302.7214],\n",
            "         [328.5814, 240.7300],\n",
            "         [317.3883, 229.8358],\n",
            "         [284.8135, 250.5633],\n",
            "         [276.5550, 244.7678],\n",
            "         [248.6576, 222.7560],\n",
            "         [244.7758, 223.1354]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7071, 0.6434],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7123, 0.6277],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6933, 0.5947],\n",
            "         [0.6556, 0.6338],\n",
            "         [0.6260, 0.5902],\n",
            "         [0.6273, 0.6891],\n",
            "         [0.5399, 0.6464],\n",
            "         [0.6594, 0.7375],\n",
            "         [0.5555, 0.7883],\n",
            "         [0.5134, 0.6269],\n",
            "         [0.4959, 0.5985],\n",
            "         [0.4450, 0.6525],\n",
            "         [0.4321, 0.6374],\n",
            "         [0.3885, 0.5801],\n",
            "         [0.3825, 0.5811]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 1.5ms preprocess, 15.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9286, 0.6344, 0.9358, 0.2264, 0.9023, 0.9628, 0.9947, 0.8520, 0.9873, 0.8045, 0.9566, 0.9831, 0.9924, 0.9453, 0.9747, 0.8884, 0.9248]], device='cuda:0')\n",
            "data: tensor([[[4.5049e+02, 2.4268e+02, 9.2857e-01],\n",
            "         [4.5642e+02, 2.4041e+02, 6.3438e-01],\n",
            "         [4.5220e+02, 2.3532e+02, 9.3575e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.2643e-01],\n",
            "         [4.3882e+02, 2.2089e+02, 9.0234e-01],\n",
            "         [4.2324e+02, 2.3504e+02, 9.6282e-01],\n",
            "         [3.9876e+02, 2.2166e+02, 9.9474e-01],\n",
            "         [4.1214e+02, 2.5211e+02, 8.5204e-01],\n",
            "         [3.4527e+02, 2.4446e+02, 9.8727e-01],\n",
            "         [4.2438e+02, 2.8445e+02, 8.0453e-01],\n",
            "         [3.4861e+02, 3.0088e+02, 9.5663e-01],\n",
            "         [3.3515e+02, 2.3851e+02, 9.8313e-01],\n",
            "         [3.2004e+02, 2.2902e+02, 9.9241e-01],\n",
            "         [2.9857e+02, 2.4787e+02, 9.4525e-01],\n",
            "         [2.7979e+02, 2.4429e+02, 9.7473e-01],\n",
            "         [2.5258e+02, 2.2228e+02, 8.8835e-01],\n",
            "         [2.4450e+02, 2.2412e+02, 9.2481e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[450.4910, 242.6760],\n",
            "         [456.4243, 240.4138],\n",
            "         [452.1987, 235.3243],\n",
            "         [  0.0000,   0.0000],\n",
            "         [438.8166, 220.8923],\n",
            "         [423.2420, 235.0352],\n",
            "         [398.7588, 221.6633],\n",
            "         [412.1419, 252.1081],\n",
            "         [345.2730, 244.4633],\n",
            "         [424.3810, 284.4462],\n",
            "         [348.6103, 300.8755],\n",
            "         [335.1493, 238.5065],\n",
            "         [320.0391, 229.0172],\n",
            "         [298.5656, 247.8735],\n",
            "         [279.7901, 244.2851],\n",
            "         [252.5802, 222.2811],\n",
            "         [244.5001, 224.1211]]], device='cuda:0')\n",
            "xyn: tensor([[[0.7039, 0.6320],\n",
            "         [0.7132, 0.6261],\n",
            "         [0.7066, 0.6128],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6857, 0.5752],\n",
            "         [0.6613, 0.6121],\n",
            "         [0.6231, 0.5772],\n",
            "         [0.6440, 0.6565],\n",
            "         [0.5395, 0.6366],\n",
            "         [0.6631, 0.7407],\n",
            "         [0.5447, 0.7835],\n",
            "         [0.5237, 0.6211],\n",
            "         [0.5001, 0.5964],\n",
            "         [0.4665, 0.6455],\n",
            "         [0.4372, 0.6362],\n",
            "         [0.3947, 0.5789],\n",
            "         [0.3820, 0.5836]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 1.4ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8775, 0.4987, 0.8786, 0.1745, 0.8544, 0.9577, 0.9937, 0.8647, 0.9869, 0.8343, 0.9602, 0.9894, 0.9949, 0.9661, 0.9836, 0.9321, 0.9538]], device='cuda:0')\n",
            "data: tensor([[[4.4648e+02, 2.3423e+02, 8.7746e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 4.9871e-01],\n",
            "         [4.4837e+02, 2.2739e+02, 8.7864e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.7446e-01],\n",
            "         [4.3579e+02, 2.1300e+02, 8.5440e-01],\n",
            "         [4.1953e+02, 2.2692e+02, 9.5770e-01],\n",
            "         [3.9713e+02, 2.1349e+02, 9.9370e-01],\n",
            "         [4.0647e+02, 2.5383e+02, 8.6474e-01],\n",
            "         [3.4748e+02, 2.4389e+02, 9.8687e-01],\n",
            "         [4.2072e+02, 2.8361e+02, 8.3431e-01],\n",
            "         [3.5434e+02, 3.0113e+02, 9.6016e-01],\n",
            "         [3.3325e+02, 2.3236e+02, 9.8941e-01],\n",
            "         [3.1923e+02, 2.2254e+02, 9.9486e-01],\n",
            "         [2.9574e+02, 2.4837e+02, 9.6606e-01],\n",
            "         [2.7992e+02, 2.4365e+02, 9.8360e-01],\n",
            "         [2.5143e+02, 2.2196e+02, 9.3215e-01],\n",
            "         [2.3885e+02, 2.2216e+02, 9.5381e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[446.4815, 234.2334],\n",
            "         [  0.0000,   0.0000],\n",
            "         [448.3731, 227.3879],\n",
            "         [  0.0000,   0.0000],\n",
            "         [435.7916, 212.9987],\n",
            "         [419.5288, 226.9206],\n",
            "         [397.1350, 213.4912],\n",
            "         [406.4709, 253.8321],\n",
            "         [347.4818, 243.8881],\n",
            "         [420.7205, 283.6060],\n",
            "         [354.3403, 301.1309],\n",
            "         [333.2536, 232.3631],\n",
            "         [319.2348, 222.5434],\n",
            "         [295.7439, 248.3685],\n",
            "         [279.9205, 243.6533],\n",
            "         [251.4320, 221.9573],\n",
            "         [238.8455, 222.1608]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6976, 0.6100],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.7006, 0.5922],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6809, 0.5547],\n",
            "         [0.6555, 0.5909],\n",
            "         [0.6205, 0.5560],\n",
            "         [0.6351, 0.6610],\n",
            "         [0.5429, 0.6351],\n",
            "         [0.6574, 0.7386],\n",
            "         [0.5537, 0.7842],\n",
            "         [0.5207, 0.6051],\n",
            "         [0.4988, 0.5795],\n",
            "         [0.4621, 0.6468],\n",
            "         [0.4374, 0.6345],\n",
            "         [0.3929, 0.5780],\n",
            "         [0.3732, 0.5785]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 1.4ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9284, 0.6013, 0.9324, 0.1828, 0.9016, 0.9663, 0.9954, 0.8764, 0.9897, 0.8305, 0.9661, 0.9878, 0.9945, 0.9556, 0.9796, 0.9050, 0.9364]], device='cuda:0')\n",
            "data: tensor([[[4.4785e+02, 2.2688e+02, 9.2843e-01],\n",
            "         [4.5150e+02, 2.2358e+02, 6.0130e-01],\n",
            "         [4.4824e+02, 2.1949e+02, 9.3242e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.8284e-01],\n",
            "         [4.3442e+02, 2.0321e+02, 9.0156e-01],\n",
            "         [4.2183e+02, 2.1794e+02, 9.6626e-01],\n",
            "         [3.9731e+02, 2.0462e+02, 9.9543e-01],\n",
            "         [4.0856e+02, 2.4794e+02, 8.7642e-01],\n",
            "         [3.5051e+02, 2.3944e+02, 9.8968e-01],\n",
            "         [4.1953e+02, 2.8266e+02, 8.3047e-01],\n",
            "         [3.5336e+02, 2.9396e+02, 9.6606e-01],\n",
            "         [3.3721e+02, 2.3286e+02, 9.8780e-01],\n",
            "         [3.2253e+02, 2.2254e+02, 9.9451e-01],\n",
            "         [3.0546e+02, 2.5007e+02, 9.5561e-01],\n",
            "         [2.8765e+02, 2.4071e+02, 9.7956e-01],\n",
            "         [2.5349e+02, 2.3628e+02, 9.0501e-01],\n",
            "         [2.4379e+02, 2.2807e+02, 9.3644e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[447.8535, 226.8753],\n",
            "         [451.4952, 223.5840],\n",
            "         [448.2411, 219.4867],\n",
            "         [  0.0000,   0.0000],\n",
            "         [434.4229, 203.2060],\n",
            "         [421.8275, 217.9367],\n",
            "         [397.3089, 204.6223],\n",
            "         [408.5581, 247.9383],\n",
            "         [350.5114, 239.4433],\n",
            "         [419.5305, 282.6602],\n",
            "         [353.3585, 293.9579],\n",
            "         [337.2061, 232.8624],\n",
            "         [322.5289, 222.5448],\n",
            "         [305.4590, 250.0724],\n",
            "         [287.6469, 240.7086],\n",
            "         [253.4864, 236.2753],\n",
            "         [243.7904, 228.0652]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6998, 0.5908],\n",
            "         [0.7055, 0.5822],\n",
            "         [0.7004, 0.5716],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6788, 0.5292],\n",
            "         [0.6591, 0.5675],\n",
            "         [0.6208, 0.5329],\n",
            "         [0.6384, 0.6457],\n",
            "         [0.5477, 0.6236],\n",
            "         [0.6555, 0.7361],\n",
            "         [0.5521, 0.7655],\n",
            "         [0.5269, 0.6064],\n",
            "         [0.5040, 0.5795],\n",
            "         [0.4773, 0.6512],\n",
            "         [0.4494, 0.6268],\n",
            "         [0.3961, 0.6153],\n",
            "         [0.3809, 0.5939]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.3ms preprocess, 11.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9140, 0.5366, 0.9174, 0.1479, 0.8878, 0.9629, 0.9950, 0.8790, 0.9899, 0.8361, 0.9677, 0.9891, 0.9951, 0.9581, 0.9808, 0.9104, 0.9397]], device='cuda:0')\n",
            "data: tensor([[[4.4598e+02, 2.1988e+02, 9.1403e-01],\n",
            "         [4.4862e+02, 2.1583e+02, 5.3658e-01],\n",
            "         [4.4530e+02, 2.1299e+02, 9.1742e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.4792e-01],\n",
            "         [4.3053e+02, 1.9728e+02, 8.8782e-01],\n",
            "         [4.2047e+02, 2.0898e+02, 9.6293e-01],\n",
            "         [3.9618e+02, 1.9942e+02, 9.9499e-01],\n",
            "         [4.0940e+02, 2.4098e+02, 8.7901e-01],\n",
            "         [3.5166e+02, 2.3666e+02, 9.8987e-01],\n",
            "         [4.1801e+02, 2.8084e+02, 8.3605e-01],\n",
            "         [3.5252e+02, 2.9337e+02, 9.6771e-01],\n",
            "         [3.3892e+02, 2.2952e+02, 9.8907e-01],\n",
            "         [3.2419e+02, 2.2108e+02, 9.9510e-01],\n",
            "         [3.0782e+02, 2.4845e+02, 9.5809e-01],\n",
            "         [2.9169e+02, 2.4288e+02, 9.8075e-01],\n",
            "         [2.5581e+02, 2.3084e+02, 9.1045e-01],\n",
            "         [2.4613e+02, 2.2617e+02, 9.3975e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[445.9778, 219.8770],\n",
            "         [448.6213, 215.8288],\n",
            "         [445.3034, 212.9884],\n",
            "         [  0.0000,   0.0000],\n",
            "         [430.5266, 197.2765],\n",
            "         [420.4655, 208.9765],\n",
            "         [396.1771, 199.4182],\n",
            "         [409.4025, 240.9830],\n",
            "         [351.6612, 236.6578],\n",
            "         [418.0150, 280.8403],\n",
            "         [352.5225, 293.3669],\n",
            "         [338.9244, 229.5186],\n",
            "         [324.1907, 221.0830],\n",
            "         [307.8216, 248.4459],\n",
            "         [291.6913, 242.8769],\n",
            "         [255.8106, 230.8389],\n",
            "         [246.1257, 226.1740]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6968, 0.5726],\n",
            "         [0.7010, 0.5621],\n",
            "         [0.6958, 0.5547],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6727, 0.5137],\n",
            "         [0.6570, 0.5442],\n",
            "         [0.6190, 0.5193],\n",
            "         [0.6397, 0.6276],\n",
            "         [0.5495, 0.6163],\n",
            "         [0.6531, 0.7314],\n",
            "         [0.5508, 0.7640],\n",
            "         [0.5296, 0.5977],\n",
            "         [0.5065, 0.5757],\n",
            "         [0.4810, 0.6470],\n",
            "         [0.4558, 0.6325],\n",
            "         [0.3997, 0.6011],\n",
            "         [0.3846, 0.5890]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.5ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9226, 0.5744, 0.9193, 0.1632, 0.8837, 0.9719, 0.9953, 0.9074, 0.9893, 0.8587, 0.9648, 0.9922, 0.9960, 0.9681, 0.9832, 0.9272, 0.9470]], device='cuda:0')\n",
            "data: tensor([[[4.4684e+02, 2.1311e+02, 9.2261e-01],\n",
            "         [4.4934e+02, 2.0890e+02, 5.7440e-01],\n",
            "         [4.4574e+02, 2.0645e+02, 9.1927e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.6320e-01],\n",
            "         [4.2999e+02, 1.9156e+02, 8.8366e-01],\n",
            "         [4.2325e+02, 2.0203e+02, 9.7189e-01],\n",
            "         [3.9464e+02, 1.9606e+02, 9.9526e-01],\n",
            "         [4.1290e+02, 2.3392e+02, 9.0741e-01],\n",
            "         [3.5408e+02, 2.3669e+02, 9.8931e-01],\n",
            "         [4.1737e+02, 2.7960e+02, 8.5866e-01],\n",
            "         [3.5270e+02, 2.9327e+02, 9.6480e-01],\n",
            "         [3.4136e+02, 2.2754e+02, 9.9224e-01],\n",
            "         [3.2338e+02, 2.2006e+02, 9.9604e-01],\n",
            "         [3.1053e+02, 2.5045e+02, 9.6806e-01],\n",
            "         [2.8828e+02, 2.4397e+02, 9.8324e-01],\n",
            "         [2.6160e+02, 2.3354e+02, 9.2723e-01],\n",
            "         [2.4595e+02, 2.2562e+02, 9.4699e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[446.8403, 213.1147],\n",
            "         [449.3438, 208.9008],\n",
            "         [445.7400, 206.4542],\n",
            "         [  0.0000,   0.0000],\n",
            "         [429.9907, 191.5625],\n",
            "         [423.2492, 202.0265],\n",
            "         [394.6400, 196.0562],\n",
            "         [412.8956, 233.9166],\n",
            "         [354.0765, 236.6941],\n",
            "         [417.3728, 279.5964],\n",
            "         [352.6961, 293.2659],\n",
            "         [341.3560, 227.5443],\n",
            "         [323.3814, 220.0595],\n",
            "         [310.5252, 250.4530],\n",
            "         [288.2760, 243.9663],\n",
            "         [261.5997, 233.5356],\n",
            "         [245.9486, 225.6162]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6982, 0.5550],\n",
            "         [0.7021, 0.5440],\n",
            "         [0.6965, 0.5376],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6719, 0.4989],\n",
            "         [0.6613, 0.5261],\n",
            "         [0.6166, 0.5106],\n",
            "         [0.6451, 0.6092],\n",
            "         [0.5532, 0.6164],\n",
            "         [0.6521, 0.7281],\n",
            "         [0.5511, 0.7637],\n",
            "         [0.5334, 0.5926],\n",
            "         [0.5053, 0.5731],\n",
            "         [0.4852, 0.6522],\n",
            "         [0.4504, 0.6353],\n",
            "         [0.4087, 0.6082],\n",
            "         [0.3843, 0.5875]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9415, 0.6502, 0.9385, 0.1879, 0.8992, 0.9763, 0.9957, 0.9104, 0.9885, 0.8621, 0.9628, 0.9919, 0.9956, 0.9666, 0.9818, 0.9222, 0.9415]], device='cuda:0')\n",
            "data: tensor([[[4.4567e+02, 2.0613e+02, 9.4147e-01],\n",
            "         [4.4893e+02, 2.0210e+02, 6.5020e-01],\n",
            "         [4.4448e+02, 1.9857e+02, 9.3853e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.8793e-01],\n",
            "         [4.2745e+02, 1.8361e+02, 8.9924e-01],\n",
            "         [4.2240e+02, 1.9749e+02, 9.7628e-01],\n",
            "         [3.9130e+02, 1.9260e+02, 9.9566e-01],\n",
            "         [4.1540e+02, 2.2946e+02, 9.1035e-01],\n",
            "         [3.5385e+02, 2.3866e+02, 9.8848e-01],\n",
            "         [4.1855e+02, 2.7657e+02, 8.6213e-01],\n",
            "         [3.5385e+02, 2.9397e+02, 9.6281e-01],\n",
            "         [3.4026e+02, 2.2209e+02, 9.9186e-01],\n",
            "         [3.2118e+02, 2.1487e+02, 9.9562e-01],\n",
            "         [3.1179e+02, 2.4746e+02, 9.6664e-01],\n",
            "         [2.8881e+02, 2.4112e+02, 9.8175e-01],\n",
            "         [2.5403e+02, 2.3239e+02, 9.2219e-01],\n",
            "         [2.4360e+02, 2.2550e+02, 9.4155e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[445.6664, 206.1321],\n",
            "         [448.9328, 202.1013],\n",
            "         [444.4824, 198.5693],\n",
            "         [  0.0000,   0.0000],\n",
            "         [427.4529, 183.6065],\n",
            "         [422.3972, 197.4851],\n",
            "         [391.3018, 192.5955],\n",
            "         [415.3980, 229.4550],\n",
            "         [353.8504, 238.6557],\n",
            "         [418.5473, 276.5724],\n",
            "         [353.8468, 293.9678],\n",
            "         [340.2612, 222.0900],\n",
            "         [321.1826, 214.8654],\n",
            "         [311.7889, 247.4563],\n",
            "         [288.8132, 241.1230],\n",
            "         [254.0311, 232.3856],\n",
            "         [243.5955, 225.5038]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6964, 0.5368],\n",
            "         [0.7015, 0.5263],\n",
            "         [0.6945, 0.5171],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6679, 0.4781],\n",
            "         [0.6600, 0.5143],\n",
            "         [0.6114, 0.5016],\n",
            "         [0.6491, 0.5975],\n",
            "         [0.5529, 0.6215],\n",
            "         [0.6540, 0.7202],\n",
            "         [0.5529, 0.7655],\n",
            "         [0.5317, 0.5784],\n",
            "         [0.5018, 0.5595],\n",
            "         [0.4872, 0.6444],\n",
            "         [0.4513, 0.6279],\n",
            "         [0.3969, 0.6052],\n",
            "         [0.3806, 0.5872]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 2.5ms preprocess, 11.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9379, 0.6407, 0.9317, 0.1976, 0.8912, 0.9775, 0.9959, 0.9144, 0.9895, 0.8641, 0.9643, 0.9931, 0.9964, 0.9726, 0.9855, 0.9343, 0.9523]], device='cuda:0')\n",
            "data: tensor([[[4.4318e+02, 2.0117e+02, 9.3787e-01],\n",
            "         [4.4620e+02, 1.9744e+02, 6.4074e-01],\n",
            "         [4.4225e+02, 1.9371e+02, 9.3166e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 1.9758e-01],\n",
            "         [4.2658e+02, 1.7934e+02, 8.9116e-01],\n",
            "         [4.2270e+02, 1.9427e+02, 9.7745e-01],\n",
            "         [3.9174e+02, 1.8895e+02, 9.9595e-01],\n",
            "         [4.1732e+02, 2.2892e+02, 9.1438e-01],\n",
            "         [3.5805e+02, 2.3775e+02, 9.8949e-01],\n",
            "         [4.1946e+02, 2.7544e+02, 8.6412e-01],\n",
            "         [3.5444e+02, 2.9350e+02, 9.6426e-01],\n",
            "         [3.4206e+02, 2.1829e+02, 9.9307e-01],\n",
            "         [3.2300e+02, 2.1031e+02, 9.9635e-01],\n",
            "         [3.1570e+02, 2.4578e+02, 9.7265e-01],\n",
            "         [2.9045e+02, 2.3680e+02, 9.8552e-01],\n",
            "         [2.5835e+02, 2.3604e+02, 9.3432e-01],\n",
            "         [2.4392e+02, 2.2646e+02, 9.5226e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[443.1785, 201.1707],\n",
            "         [446.2024, 197.4383],\n",
            "         [442.2532, 193.7112],\n",
            "         [  0.0000,   0.0000],\n",
            "         [426.5847, 179.3385],\n",
            "         [422.6992, 194.2678],\n",
            "         [391.7389, 188.9464],\n",
            "         [417.3234, 228.9244],\n",
            "         [358.0550, 237.7470],\n",
            "         [419.4623, 275.4438],\n",
            "         [354.4445, 293.4995],\n",
            "         [342.0558, 218.2871],\n",
            "         [323.0030, 210.3076],\n",
            "         [315.6975, 245.7840],\n",
            "         [290.4507, 236.8001],\n",
            "         [258.3531, 236.0437],\n",
            "         [243.9165, 226.4615]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6925, 0.5239],\n",
            "         [0.6972, 0.5142],\n",
            "         [0.6910, 0.5045],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6665, 0.4670],\n",
            "         [0.6605, 0.5059],\n",
            "         [0.6121, 0.4920],\n",
            "         [0.6521, 0.5962],\n",
            "         [0.5595, 0.6191],\n",
            "         [0.6554, 0.7173],\n",
            "         [0.5538, 0.7643],\n",
            "         [0.5345, 0.5685],\n",
            "         [0.5047, 0.5477],\n",
            "         [0.4933, 0.6401],\n",
            "         [0.4538, 0.6167],\n",
            "         [0.4037, 0.6147],\n",
            "         [0.3811, 0.5897]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 1.5ms preprocess, 9.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9342, 0.6736, 0.9237, 0.2596, 0.8840, 0.9795, 0.9954, 0.9139, 0.9852, 0.8591, 0.9485, 0.9914, 0.9947, 0.9685, 0.9811, 0.9182, 0.9366]], device='cuda:0')\n",
            "data: tensor([[[4.4260e+02, 1.9501e+02, 9.3424e-01],\n",
            "         [4.4651e+02, 1.9097e+02, 6.7360e-01],\n",
            "         [4.4210e+02, 1.8804e+02, 9.2366e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5956e-01],\n",
            "         [4.2671e+02, 1.7613e+02, 8.8399e-01],\n",
            "         [4.2051e+02, 1.8839e+02, 9.7954e-01],\n",
            "         [3.9125e+02, 1.8942e+02, 9.9544e-01],\n",
            "         [4.1768e+02, 2.2184e+02, 9.1393e-01],\n",
            "         [3.5526e+02, 2.3991e+02, 9.8522e-01],\n",
            "         [4.2015e+02, 2.7218e+02, 8.5911e-01],\n",
            "         [3.5103e+02, 2.9910e+02, 9.4852e-01],\n",
            "         [3.3793e+02, 2.1140e+02, 9.9142e-01],\n",
            "         [3.1918e+02, 2.0709e+02, 9.9470e-01],\n",
            "         [3.0520e+02, 2.3641e+02, 9.6852e-01],\n",
            "         [2.8267e+02, 2.3707e+02, 9.8111e-01],\n",
            "         [2.5354e+02, 2.2377e+02, 9.1822e-01],\n",
            "         [2.4005e+02, 2.2617e+02, 9.3657e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[442.6010, 195.0101],\n",
            "         [446.5143, 190.9664],\n",
            "         [442.0995, 188.0394],\n",
            "         [  0.0000,   0.0000],\n",
            "         [426.7087, 176.1280],\n",
            "         [420.5069, 188.3874],\n",
            "         [391.2515, 189.4234],\n",
            "         [417.6773, 221.8357],\n",
            "         [355.2607, 239.9095],\n",
            "         [420.1545, 272.1758],\n",
            "         [351.0319, 299.1039],\n",
            "         [337.9300, 211.4040],\n",
            "         [319.1798, 207.0855],\n",
            "         [305.2019, 236.4112],\n",
            "         [282.6735, 237.0688],\n",
            "         [253.5395, 223.7667],\n",
            "         [240.0529, 226.1741]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6916, 0.5078],\n",
            "         [0.6977, 0.4973],\n",
            "         [0.6908, 0.4897],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6667, 0.4587],\n",
            "         [0.6570, 0.4906],\n",
            "         [0.6113, 0.4933],\n",
            "         [0.6526, 0.5777],\n",
            "         [0.5551, 0.6248],\n",
            "         [0.6565, 0.7088],\n",
            "         [0.5485, 0.7789],\n",
            "         [0.5280, 0.5505],\n",
            "         [0.4987, 0.5393],\n",
            "         [0.4769, 0.6157],\n",
            "         [0.4417, 0.6174],\n",
            "         [0.3962, 0.5827],\n",
            "         [0.3751, 0.5890]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 1.2ms preprocess, 11.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9302, 0.6671, 0.9180, 0.2677, 0.8772, 0.9796, 0.9956, 0.9140, 0.9858, 0.8536, 0.9482, 0.9919, 0.9951, 0.9698, 0.9824, 0.9203, 0.9396]], device='cuda:0')\n",
            "data: tensor([[[4.3980e+02, 1.9246e+02, 9.3021e-01],\n",
            "         [4.4399e+02, 1.8881e+02, 6.6708e-01],\n",
            "         [4.3983e+02, 1.8531e+02, 9.1799e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.6774e-01],\n",
            "         [4.2537e+02, 1.7315e+02, 8.7724e-01],\n",
            "         [4.1995e+02, 1.8654e+02, 9.7963e-01],\n",
            "         [3.8921e+02, 1.8757e+02, 9.9558e-01],\n",
            "         [4.1875e+02, 2.2324e+02, 9.1399e-01],\n",
            "         [3.5524e+02, 2.4285e+02, 9.8576e-01],\n",
            "         [4.2039e+02, 2.7368e+02, 8.5356e-01],\n",
            "         [3.5215e+02, 2.9919e+02, 9.4820e-01],\n",
            "         [3.3928e+02, 2.0808e+02, 9.9191e-01],\n",
            "         [3.1932e+02, 2.0388e+02, 9.9507e-01],\n",
            "         [3.1131e+02, 2.3566e+02, 9.6977e-01],\n",
            "         [2.8416e+02, 2.3646e+02, 9.8240e-01],\n",
            "         [2.5727e+02, 2.2250e+02, 9.2032e-01],\n",
            "         [2.4023e+02, 2.2615e+02, 9.3960e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[439.8044, 192.4586],\n",
            "         [443.9882, 188.8110],\n",
            "         [439.8291, 185.3079],\n",
            "         [  0.0000,   0.0000],\n",
            "         [425.3680, 173.1463],\n",
            "         [419.9502, 186.5430],\n",
            "         [389.2149, 187.5743],\n",
            "         [418.7513, 223.2418],\n",
            "         [355.2383, 242.8509],\n",
            "         [420.3897, 273.6768],\n",
            "         [352.1538, 299.1926],\n",
            "         [339.2765, 208.0775],\n",
            "         [319.3239, 203.8839],\n",
            "         [311.3073, 235.6627],\n",
            "         [284.1623, 236.4648],\n",
            "         [257.2718, 222.5049],\n",
            "         [240.2325, 226.1517]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6872, 0.5012],\n",
            "         [0.6937, 0.4917],\n",
            "         [0.6872, 0.4826],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6646, 0.4509],\n",
            "         [0.6562, 0.4858],\n",
            "         [0.6081, 0.4885],\n",
            "         [0.6543, 0.5814],\n",
            "         [0.5551, 0.6324],\n",
            "         [0.6569, 0.7127],\n",
            "         [0.5502, 0.7791],\n",
            "         [0.5301, 0.5419],\n",
            "         [0.4989, 0.5309],\n",
            "         [0.4864, 0.6137],\n",
            "         [0.4440, 0.6158],\n",
            "         [0.4020, 0.5794],\n",
            "         [0.3754, 0.5889]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 1.5ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9115, 0.6057, 0.8921, 0.2429, 0.8582, 0.9799, 0.9951, 0.9241, 0.9855, 0.8630, 0.9472, 0.9934, 0.9957, 0.9745, 0.9844, 0.9296, 0.9452]], device='cuda:0')\n",
            "data: tensor([[[4.4000e+02, 1.8903e+02, 9.1155e-01],\n",
            "         [4.4315e+02, 1.8537e+02, 6.0567e-01],\n",
            "         [4.3980e+02, 1.8236e+02, 8.9210e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4290e-01],\n",
            "         [4.2536e+02, 1.7189e+02, 8.5825e-01],\n",
            "         [4.2019e+02, 1.8426e+02, 9.7992e-01],\n",
            "         [3.8909e+02, 1.8716e+02, 9.9513e-01],\n",
            "         [4.1914e+02, 2.2169e+02, 9.2409e-01],\n",
            "         [3.5574e+02, 2.4378e+02, 9.8552e-01],\n",
            "         [4.1991e+02, 2.7334e+02, 8.6299e-01],\n",
            "         [3.5186e+02, 2.9937e+02, 9.4717e-01],\n",
            "         [3.4239e+02, 2.0687e+02, 9.9339e-01],\n",
            "         [3.2159e+02, 2.0346e+02, 9.9574e-01],\n",
            "         [3.1970e+02, 2.3553e+02, 9.7448e-01],\n",
            "         [2.8746e+02, 2.3592e+02, 9.8436e-01],\n",
            "         [2.6766e+02, 2.2456e+02, 9.2964e-01],\n",
            "         [2.4062e+02, 2.2610e+02, 9.4518e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[439.9979, 189.0309],\n",
            "         [443.1479, 185.3686],\n",
            "         [439.8015, 182.3649],\n",
            "         [  0.0000,   0.0000],\n",
            "         [425.3553, 171.8910],\n",
            "         [420.1924, 184.2617],\n",
            "         [389.0879, 187.1564],\n",
            "         [419.1394, 221.6870],\n",
            "         [355.7370, 243.7846],\n",
            "         [419.9131, 273.3359],\n",
            "         [351.8621, 299.3731],\n",
            "         [342.3875, 206.8713],\n",
            "         [321.5880, 203.4612],\n",
            "         [319.7036, 235.5296],\n",
            "         [287.4582, 235.9208],\n",
            "         [267.6560, 224.5584],\n",
            "         [240.6209, 226.0987]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6875, 0.4923],\n",
            "         [0.6924, 0.4827],\n",
            "         [0.6872, 0.4749],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6646, 0.4476],\n",
            "         [0.6566, 0.4798],\n",
            "         [0.6079, 0.4874],\n",
            "         [0.6549, 0.5773],\n",
            "         [0.5558, 0.6349],\n",
            "         [0.6561, 0.7118],\n",
            "         [0.5498, 0.7796],\n",
            "         [0.5350, 0.5387],\n",
            "         [0.5025, 0.5298],\n",
            "         [0.4995, 0.6134],\n",
            "         [0.4492, 0.6144],\n",
            "         [0.4182, 0.5848],\n",
            "         [0.3760, 0.5888]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 1.4ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9093, 0.6163, 0.8794, 0.2631, 0.8378, 0.9824, 0.9947, 0.9385, 0.9848, 0.8759, 0.9437, 0.9943, 0.9959, 0.9747, 0.9830, 0.9238, 0.9371]], device='cuda:0')\n",
            "data: tensor([[[4.3684e+02, 1.8630e+02, 9.0930e-01],\n",
            "         [4.3935e+02, 1.8244e+02, 6.1627e-01],\n",
            "         [4.3642e+02, 1.7968e+02, 8.7943e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.6314e-01],\n",
            "         [4.2301e+02, 1.7013e+02, 8.3781e-01],\n",
            "         [4.1889e+02, 1.8269e+02, 9.8242e-01],\n",
            "         [3.8834e+02, 1.8577e+02, 9.9469e-01],\n",
            "         [4.1751e+02, 2.2260e+02, 9.3852e-01],\n",
            "         [3.5683e+02, 2.4446e+02, 9.8483e-01],\n",
            "         [4.2034e+02, 2.7372e+02, 8.7586e-01],\n",
            "         [3.5372e+02, 2.9787e+02, 9.4370e-01],\n",
            "         [3.4450e+02, 2.0555e+02, 9.9430e-01],\n",
            "         [3.2277e+02, 2.0223e+02, 9.9591e-01],\n",
            "         [3.3069e+02, 2.3583e+02, 9.7469e-01],\n",
            "         [2.8809e+02, 2.3492e+02, 9.8296e-01],\n",
            "         [2.8066e+02, 2.2662e+02, 9.2381e-01],\n",
            "         [2.3384e+02, 2.2539e+02, 9.3713e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[436.8388, 186.3040],\n",
            "         [439.3522, 182.4395],\n",
            "         [436.4169, 179.6850],\n",
            "         [  0.0000,   0.0000],\n",
            "         [423.0102, 170.1328],\n",
            "         [418.8907, 182.6905],\n",
            "         [388.3355, 185.7685],\n",
            "         [417.5138, 222.6041],\n",
            "         [356.8347, 244.4637],\n",
            "         [420.3363, 273.7161],\n",
            "         [353.7217, 297.8683],\n",
            "         [344.4986, 205.5530],\n",
            "         [322.7726, 202.2277],\n",
            "         [330.6935, 235.8346],\n",
            "         [288.0940, 234.9222],\n",
            "         [280.6563, 226.6205],\n",
            "         [233.8428, 225.3892]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6826, 0.4852],\n",
            "         [0.6865, 0.4751],\n",
            "         [0.6819, 0.4679],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6610, 0.4431],\n",
            "         [0.6545, 0.4758],\n",
            "         [0.6068, 0.4838],\n",
            "         [0.6524, 0.5797],\n",
            "         [0.5576, 0.6366],\n",
            "         [0.6568, 0.7128],\n",
            "         [0.5527, 0.7757],\n",
            "         [0.5383, 0.5353],\n",
            "         [0.5043, 0.5266],\n",
            "         [0.5167, 0.6142],\n",
            "         [0.4501, 0.6118],\n",
            "         [0.4385, 0.5902],\n",
            "         [0.3654, 0.5870]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 1.4ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.8997, 0.5724, 0.8716, 0.2289, 0.8376, 0.9806, 0.9949, 0.9339, 0.9862, 0.8702, 0.9484, 0.9946, 0.9964, 0.9770, 0.9856, 0.9315, 0.9459]], device='cuda:0')\n",
            "data: tensor([[[4.3633e+02, 1.8374e+02, 8.9967e-01],\n",
            "         [4.3856e+02, 1.7935e+02, 5.7237e-01],\n",
            "         [4.3516e+02, 1.7731e+02, 8.7159e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.2887e-01],\n",
            "         [4.2089e+02, 1.6869e+02, 8.3756e-01],\n",
            "         [4.1892e+02, 1.8013e+02, 9.8062e-01],\n",
            "         [3.8693e+02, 1.8596e+02, 9.9494e-01],\n",
            "         [4.1842e+02, 2.2198e+02, 9.3386e-01],\n",
            "         [3.5659e+02, 2.4784e+02, 9.8623e-01],\n",
            "         [4.2041e+02, 2.7443e+02, 8.7025e-01],\n",
            "         [3.5277e+02, 2.9865e+02, 9.4839e-01],\n",
            "         [3.4521e+02, 2.0397e+02, 9.9461e-01],\n",
            "         [3.2265e+02, 2.0192e+02, 9.9639e-01],\n",
            "         [3.3160e+02, 2.3422e+02, 9.7702e-01],\n",
            "         [2.8900e+02, 2.3563e+02, 9.8561e-01],\n",
            "         [2.7930e+02, 2.2504e+02, 9.3151e-01],\n",
            "         [2.3329e+02, 2.2631e+02, 9.4587e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[436.3343, 183.7388],\n",
            "         [438.5558, 179.3459],\n",
            "         [435.1620, 177.3117],\n",
            "         [  0.0000,   0.0000],\n",
            "         [420.8853, 168.6945],\n",
            "         [418.9180, 180.1284],\n",
            "         [386.9304, 185.9591],\n",
            "         [418.4241, 221.9839],\n",
            "         [356.5858, 247.8435],\n",
            "         [420.4092, 274.4318],\n",
            "         [352.7728, 298.6469],\n",
            "         [345.2107, 203.9668],\n",
            "         [322.6499, 201.9223],\n",
            "         [331.6011, 234.2236],\n",
            "         [289.0030, 235.6273],\n",
            "         [279.3035, 225.0442],\n",
            "         [233.2881, 226.3130]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6818, 0.4785],\n",
            "         [0.6852, 0.4670],\n",
            "         [0.6799, 0.4617],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6576, 0.4393],\n",
            "         [0.6546, 0.4691],\n",
            "         [0.6046, 0.4843],\n",
            "         [0.6538, 0.5781],\n",
            "         [0.5572, 0.6454],\n",
            "         [0.6569, 0.7147],\n",
            "         [0.5512, 0.7777],\n",
            "         [0.5394, 0.5312],\n",
            "         [0.5041, 0.5258],\n",
            "         [0.5181, 0.6100],\n",
            "         [0.4516, 0.6136],\n",
            "         [0.4364, 0.5861],\n",
            "         [0.3645, 0.5894]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.4ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9169, 0.6310, 0.8902, 0.2483, 0.8410, 0.9831, 0.9951, 0.9423, 0.9862, 0.8802, 0.9482, 0.9952, 0.9966, 0.9781, 0.9856, 0.9323, 0.9449]], device='cuda:0')\n",
            "data: tensor([[[4.3552e+02, 1.8315e+02, 9.1688e-01],\n",
            "         [4.3783e+02, 1.7821e+02, 6.3098e-01],\n",
            "         [4.3347e+02, 1.7660e+02, 8.9021e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4830e-01],\n",
            "         [4.1845e+02, 1.6835e+02, 8.4098e-01],\n",
            "         [4.2034e+02, 1.7924e+02, 9.8308e-01],\n",
            "         [3.8546e+02, 1.8539e+02, 9.9505e-01],\n",
            "         [4.1937e+02, 2.2263e+02, 9.4230e-01],\n",
            "         [3.5648e+02, 2.4778e+02, 9.8619e-01],\n",
            "         [4.2108e+02, 2.7554e+02, 8.8025e-01],\n",
            "         [3.5346e+02, 2.9892e+02, 9.4824e-01],\n",
            "         [3.4832e+02, 2.0220e+02, 9.9518e-01],\n",
            "         [3.2293e+02, 2.0055e+02, 9.9658e-01],\n",
            "         [3.4095e+02, 2.3418e+02, 9.7811e-01],\n",
            "         [2.8987e+02, 2.3564e+02, 9.8557e-01],\n",
            "         [2.9235e+02, 2.2517e+02, 9.3234e-01],\n",
            "         [2.3214e+02, 2.2587e+02, 9.4489e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[435.5230, 183.1462],\n",
            "         [437.8279, 178.2076],\n",
            "         [433.4651, 176.5973],\n",
            "         [  0.0000,   0.0000],\n",
            "         [418.4532, 168.3523],\n",
            "         [420.3394, 179.2416],\n",
            "         [385.4574, 185.3928],\n",
            "         [419.3747, 222.6272],\n",
            "         [356.4802, 247.7802],\n",
            "         [421.0816, 275.5369],\n",
            "         [353.4555, 298.9167],\n",
            "         [348.3175, 202.1991],\n",
            "         [322.9350, 200.5516],\n",
            "         [340.9471, 234.1818],\n",
            "         [289.8710, 235.6414],\n",
            "         [292.3537, 225.1714],\n",
            "         [232.1368, 225.8708]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6805, 0.4769],\n",
            "         [0.6841, 0.4641],\n",
            "         [0.6773, 0.4599],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6538, 0.4384],\n",
            "         [0.6568, 0.4668],\n",
            "         [0.6023, 0.4828],\n",
            "         [0.6553, 0.5798],\n",
            "         [0.5570, 0.6453],\n",
            "         [0.6579, 0.7175],\n",
            "         [0.5523, 0.7784],\n",
            "         [0.5442, 0.5266],\n",
            "         [0.5046, 0.5223],\n",
            "         [0.5327, 0.6098],\n",
            "         [0.4529, 0.6136],\n",
            "         [0.4568, 0.5864],\n",
            "         [0.3627, 0.5882]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 1.4ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9251, 0.6489, 0.9048, 0.2528, 0.8607, 0.9836, 0.9958, 0.9391, 0.9877, 0.8746, 0.9520, 0.9955, 0.9970, 0.9808, 0.9882, 0.9421, 0.9550]], device='cuda:0')\n",
            "data: tensor([[[4.3478e+02, 1.8194e+02, 9.2507e-01],\n",
            "         [4.3755e+02, 1.7734e+02, 6.4887e-01],\n",
            "         [4.3282e+02, 1.7522e+02, 9.0482e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5280e-01],\n",
            "         [4.1728e+02, 1.6665e+02, 8.6070e-01],\n",
            "         [4.1931e+02, 1.7895e+02, 9.8364e-01],\n",
            "         [3.8476e+02, 1.8387e+02, 9.9578e-01],\n",
            "         [4.1983e+02, 2.2212e+02, 9.3908e-01],\n",
            "         [3.5770e+02, 2.4560e+02, 9.8769e-01],\n",
            "         [4.2122e+02, 2.7563e+02, 8.7457e-01],\n",
            "         [3.5259e+02, 2.9812e+02, 9.5200e-01],\n",
            "         [3.4813e+02, 2.0079e+02, 9.9551e-01],\n",
            "         [3.2331e+02, 1.9864e+02, 9.9702e-01],\n",
            "         [3.3873e+02, 2.3426e+02, 9.8075e-01],\n",
            "         [2.9012e+02, 2.3567e+02, 9.8818e-01],\n",
            "         [2.8933e+02, 2.2467e+02, 9.4208e-01],\n",
            "         [2.3506e+02, 2.2673e+02, 9.5501e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[434.7783, 181.9383],\n",
            "         [437.5524, 177.3366],\n",
            "         [432.8211, 175.2202],\n",
            "         [  0.0000,   0.0000],\n",
            "         [417.2752, 166.6525],\n",
            "         [419.3080, 178.9486],\n",
            "         [384.7647, 183.8737],\n",
            "         [419.8267, 222.1229],\n",
            "         [357.6959, 245.6023],\n",
            "         [421.2211, 275.6265],\n",
            "         [352.5942, 298.1202],\n",
            "         [348.1328, 200.7946],\n",
            "         [323.3064, 198.6419],\n",
            "         [338.7348, 234.2636],\n",
            "         [290.1171, 235.6697],\n",
            "         [289.3344, 224.6713],\n",
            "         [235.0575, 226.7256]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6793, 0.4738],\n",
            "         [0.6837, 0.4618],\n",
            "         [0.6763, 0.4563],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6520, 0.4340],\n",
            "         [0.6552, 0.4660],\n",
            "         [0.6012, 0.4788],\n",
            "         [0.6560, 0.5784],\n",
            "         [0.5589, 0.6396],\n",
            "         [0.6582, 0.7178],\n",
            "         [0.5509, 0.7764],\n",
            "         [0.5440, 0.5229],\n",
            "         [0.5052, 0.5173],\n",
            "         [0.5293, 0.6101],\n",
            "         [0.4533, 0.6137],\n",
            "         [0.4521, 0.5851],\n",
            "         [0.3673, 0.5904]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.4ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9215, 0.6416, 0.8983, 0.2554, 0.8533, 0.9842, 0.9956, 0.9437, 0.9872, 0.8794, 0.9498, 0.9958, 0.9971, 0.9818, 0.9883, 0.9440, 0.9553]], device='cuda:0')\n",
            "data: tensor([[[4.3409e+02, 1.8226e+02, 9.2148e-01],\n",
            "         [4.3681e+02, 1.7767e+02, 6.4156e-01],\n",
            "         [4.3238e+02, 1.7555e+02, 8.9832e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5536e-01],\n",
            "         [4.1711e+02, 1.6682e+02, 8.5332e-01],\n",
            "         [4.1842e+02, 1.7843e+02, 9.8422e-01],\n",
            "         [3.8405e+02, 1.8396e+02, 9.9556e-01],\n",
            "         [4.1905e+02, 2.2170e+02, 9.4372e-01],\n",
            "         [3.5866e+02, 2.4648e+02, 9.8718e-01],\n",
            "         [4.2100e+02, 2.7560e+02, 8.7940e-01],\n",
            "         [3.5327e+02, 2.9773e+02, 9.4976e-01],\n",
            "         [3.4794e+02, 1.9962e+02, 9.9583e-01],\n",
            "         [3.2273e+02, 1.9781e+02, 9.9710e-01],\n",
            "         [3.4245e+02, 2.3447e+02, 9.8184e-01],\n",
            "         [2.8964e+02, 2.3555e+02, 9.8832e-01],\n",
            "         [2.9695e+02, 2.2603e+02, 9.4396e-01],\n",
            "         [2.3560e+02, 2.2736e+02, 9.5529e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[434.0919, 182.2595],\n",
            "         [436.8090, 177.6713],\n",
            "         [432.3777, 175.5539],\n",
            "         [  0.0000,   0.0000],\n",
            "         [417.1066, 166.8196],\n",
            "         [418.4160, 178.4258],\n",
            "         [384.0531, 183.9636],\n",
            "         [419.0465, 221.7019],\n",
            "         [358.6633, 246.4819],\n",
            "         [421.0025, 275.5987],\n",
            "         [353.2657, 297.7343],\n",
            "         [347.9391, 199.6210],\n",
            "         [322.7261, 197.8107],\n",
            "         [342.4521, 234.4679],\n",
            "         [289.6391, 235.5534],\n",
            "         [296.9509, 226.0301],\n",
            "         [235.5978, 227.3636]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6783, 0.4746],\n",
            "         [0.6825, 0.4627],\n",
            "         [0.6756, 0.4572],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6517, 0.4344],\n",
            "         [0.6538, 0.4647],\n",
            "         [0.6001, 0.4791],\n",
            "         [0.6548, 0.5773],\n",
            "         [0.5604, 0.6419],\n",
            "         [0.6578, 0.7177],\n",
            "         [0.5520, 0.7753],\n",
            "         [0.5437, 0.5198],\n",
            "         [0.5043, 0.5151],\n",
            "         [0.5351, 0.6106],\n",
            "         [0.4526, 0.6134],\n",
            "         [0.4640, 0.5886],\n",
            "         [0.3681, 0.5921]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9186, 0.6329, 0.8959, 0.2578, 0.8544, 0.9840, 0.9957, 0.9423, 0.9875, 0.8756, 0.9494, 0.9959, 0.9972, 0.9823, 0.9888, 0.9451, 0.9568]], device='cuda:0')\n",
            "data: tensor([[[4.3315e+02, 1.8295e+02, 9.1858e-01],\n",
            "         [4.3604e+02, 1.7865e+02, 6.3288e-01],\n",
            "         [4.3187e+02, 1.7622e+02, 8.9586e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5784e-01],\n",
            "         [4.1713e+02, 1.6695e+02, 8.5442e-01],\n",
            "         [4.1731e+02, 1.7855e+02, 9.8403e-01],\n",
            "         [3.8370e+02, 1.8364e+02, 9.9565e-01],\n",
            "         [4.1823e+02, 2.2115e+02, 9.4228e-01],\n",
            "         [3.5954e+02, 2.4615e+02, 9.8746e-01],\n",
            "         [4.2085e+02, 2.7524e+02, 8.7563e-01],\n",
            "         [3.5314e+02, 2.9772e+02, 9.4942e-01],\n",
            "         [3.4531e+02, 1.9832e+02, 9.9589e-01],\n",
            "         [3.2086e+02, 1.9611e+02, 9.9719e-01],\n",
            "         [3.3941e+02, 2.3487e+02, 9.8228e-01],\n",
            "         [2.8801e+02, 2.3503e+02, 9.8883e-01],\n",
            "         [2.9321e+02, 2.2675e+02, 9.4509e-01],\n",
            "         [2.3500e+02, 2.2752e+02, 9.5682e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[433.1533, 182.9465],\n",
            "         [436.0421, 178.6457],\n",
            "         [431.8660, 176.2227],\n",
            "         [  0.0000,   0.0000],\n",
            "         [417.1322, 166.9516],\n",
            "         [417.3104, 178.5490],\n",
            "         [383.7040, 183.6439],\n",
            "         [418.2305, 221.1496],\n",
            "         [359.5356, 246.1499],\n",
            "         [420.8477, 275.2386],\n",
            "         [353.1371, 297.7160],\n",
            "         [345.3096, 198.3205],\n",
            "         [320.8646, 196.1080],\n",
            "         [339.4142, 234.8671],\n",
            "         [288.0108, 235.0334],\n",
            "         [293.2094, 226.7483],\n",
            "         [235.0029, 227.5173]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6768, 0.4764],\n",
            "         [0.6813, 0.4652],\n",
            "         [0.6748, 0.4589],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6518, 0.4348],\n",
            "         [0.6520, 0.4650],\n",
            "         [0.5995, 0.4782],\n",
            "         [0.6535, 0.5759],\n",
            "         [0.5618, 0.6410],\n",
            "         [0.6576, 0.7168],\n",
            "         [0.5518, 0.7753],\n",
            "         [0.5395, 0.5165],\n",
            "         [0.5014, 0.5107],\n",
            "         [0.5303, 0.6116],\n",
            "         [0.4500, 0.6121],\n",
            "         [0.4581, 0.5905],\n",
            "         [0.3672, 0.5925]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 1.3ms preprocess, 11.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9155, 0.6136, 0.8924, 0.2385, 0.8551, 0.9846, 0.9957, 0.9457, 0.9880, 0.8800, 0.9512, 0.9965, 0.9976, 0.9851, 0.9906, 0.9520, 0.9622]], device='cuda:0')\n",
            "data: tensor([[[4.3447e+02, 1.8216e+02, 9.1550e-01],\n",
            "         [4.3684e+02, 1.7756e+02, 6.1365e-01],\n",
            "         [4.3262e+02, 1.7554e+02, 8.9241e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.3855e-01],\n",
            "         [4.1702e+02, 1.6674e+02, 8.5513e-01],\n",
            "         [4.1850e+02, 1.7765e+02, 9.8460e-01],\n",
            "         [3.8351e+02, 1.8282e+02, 9.9573e-01],\n",
            "         [4.1868e+02, 2.2124e+02, 9.4571e-01],\n",
            "         [3.5990e+02, 2.4521e+02, 9.8804e-01],\n",
            "         [4.2088e+02, 2.7534e+02, 8.7997e-01],\n",
            "         [3.5238e+02, 2.9696e+02, 9.5123e-01],\n",
            "         [3.4601e+02, 1.9606e+02, 9.9652e-01],\n",
            "         [3.2049e+02, 1.9365e+02, 9.9760e-01],\n",
            "         [3.4189e+02, 2.3529e+02, 9.8515e-01],\n",
            "         [2.8766e+02, 2.3408e+02, 9.9057e-01],\n",
            "         [2.9755e+02, 2.2983e+02, 9.5204e-01],\n",
            "         [2.3297e+02, 2.2808e+02, 9.6220e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[434.4744, 182.1623],\n",
            "         [436.8433, 177.5553],\n",
            "         [432.6159, 175.5441],\n",
            "         [  0.0000,   0.0000],\n",
            "         [417.0211, 166.7446],\n",
            "         [418.5038, 177.6534],\n",
            "         [383.5140, 182.8222],\n",
            "         [418.6830, 221.2418],\n",
            "         [359.9036, 245.2144],\n",
            "         [420.8766, 275.3369],\n",
            "         [352.3788, 296.9639],\n",
            "         [346.0125, 196.0577],\n",
            "         [320.4899, 193.6530],\n",
            "         [341.8872, 235.2893],\n",
            "         [287.6626, 234.0769],\n",
            "         [297.5458, 229.8318],\n",
            "         [232.9749, 228.0835]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6789, 0.4744],\n",
            "         [0.6826, 0.4624],\n",
            "         [0.6760, 0.4571],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6516, 0.4342],\n",
            "         [0.6539, 0.4626],\n",
            "         [0.5992, 0.4761],\n",
            "         [0.6542, 0.5762],\n",
            "         [0.5623, 0.6386],\n",
            "         [0.6576, 0.7170],\n",
            "         [0.5506, 0.7733],\n",
            "         [0.5406, 0.5106],\n",
            "         [0.5008, 0.5043],\n",
            "         [0.5342, 0.6127],\n",
            "         [0.4495, 0.6096],\n",
            "         [0.4649, 0.5985],\n",
            "         [0.3640, 0.5940]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.3ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9226, 0.6502, 0.8979, 0.2635, 0.8496, 0.9856, 0.9957, 0.9496, 0.9876, 0.8848, 0.9495, 0.9966, 0.9976, 0.9849, 0.9901, 0.9509, 0.9605]], device='cuda:0')\n",
            "data: tensor([[[4.3293e+02, 1.8373e+02, 9.2257e-01],\n",
            "         [4.3577e+02, 1.7910e+02, 6.5024e-01],\n",
            "         [4.3114e+02, 1.7686e+02, 8.9790e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.6347e-01],\n",
            "         [4.1600e+02, 1.6736e+02, 8.4959e-01],\n",
            "         [4.1858e+02, 1.7845e+02, 9.8565e-01],\n",
            "         [3.8269e+02, 1.8304e+02, 9.9567e-01],\n",
            "         [4.1846e+02, 2.2248e+02, 9.4960e-01],\n",
            "         [3.6011e+02, 2.4590e+02, 9.8764e-01],\n",
            "         [4.2139e+02, 2.7551e+02, 8.8479e-01],\n",
            "         [3.5279e+02, 2.9633e+02, 9.4951e-01],\n",
            "         [3.4646e+02, 1.9660e+02, 9.9662e-01],\n",
            "         [3.1988e+02, 1.9401e+02, 9.9756e-01],\n",
            "         [3.4526e+02, 2.3607e+02, 9.8489e-01],\n",
            "         [2.8677e+02, 2.3422e+02, 9.9005e-01],\n",
            "         [3.0266e+02, 2.2891e+02, 9.5095e-01],\n",
            "         [2.3242e+02, 2.2664e+02, 9.6054e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[432.9250, 183.7327],\n",
            "         [435.7685, 179.1029],\n",
            "         [431.1396, 176.8611],\n",
            "         [  0.0000,   0.0000],\n",
            "         [416.0000, 167.3627],\n",
            "         [418.5839, 178.4480],\n",
            "         [382.6877, 183.0425],\n",
            "         [418.4600, 222.4761],\n",
            "         [360.1066, 245.8959],\n",
            "         [421.3931, 275.5052],\n",
            "         [352.7935, 296.3329],\n",
            "         [346.4582, 196.5965],\n",
            "         [319.8780, 194.0093],\n",
            "         [345.2628, 236.0685],\n",
            "         [286.7668, 234.2169],\n",
            "         [302.6555, 228.9104],\n",
            "         [232.4217, 226.6351]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6764, 0.4785],\n",
            "         [0.6809, 0.4664],\n",
            "         [0.6737, 0.4606],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6500, 0.4358],\n",
            "         [0.6540, 0.4647],\n",
            "         [0.5979, 0.4767],\n",
            "         [0.6538, 0.5794],\n",
            "         [0.5627, 0.6404],\n",
            "         [0.6584, 0.7175],\n",
            "         [0.5512, 0.7717],\n",
            "         [0.5413, 0.5120],\n",
            "         [0.4998, 0.5052],\n",
            "         [0.5395, 0.6148],\n",
            "         [0.4481, 0.6099],\n",
            "         [0.4729, 0.5961],\n",
            "         [0.3632, 0.5902]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.3ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9244, 0.6590, 0.8992, 0.2706, 0.8490, 0.9862, 0.9957, 0.9520, 0.9879, 0.8882, 0.9501, 0.9969, 0.9977, 0.9860, 0.9907, 0.9537, 0.9626]], device='cuda:0')\n",
            "data: tensor([[[4.3256e+02, 1.8384e+02, 9.2439e-01],\n",
            "         [4.3531e+02, 1.7930e+02, 6.5899e-01],\n",
            "         [4.3085e+02, 1.7698e+02, 8.9917e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.7063e-01],\n",
            "         [4.1595e+02, 1.6745e+02, 8.4899e-01],\n",
            "         [4.1839e+02, 1.7840e+02, 9.8622e-01],\n",
            "         [3.8276e+02, 1.8252e+02, 9.9571e-01],\n",
            "         [4.1811e+02, 2.2215e+02, 9.5198e-01],\n",
            "         [3.6027e+02, 2.4474e+02, 9.8789e-01],\n",
            "         [4.2150e+02, 2.7516e+02, 8.8824e-01],\n",
            "         [3.5313e+02, 2.9609e+02, 9.5014e-01],\n",
            "         [3.4694e+02, 1.9524e+02, 9.9686e-01],\n",
            "         [3.2031e+02, 1.9247e+02, 9.9771e-01],\n",
            "         [3.4769e+02, 2.3551e+02, 9.8597e-01],\n",
            "         [2.8734e+02, 2.3314e+02, 9.9068e-01],\n",
            "         [3.0590e+02, 2.3002e+02, 9.5372e-01],\n",
            "         [2.3175e+02, 2.2719e+02, 9.6264e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[432.5596, 183.8358],\n",
            "         [435.3079, 179.2990],\n",
            "         [430.8503, 176.9799],\n",
            "         [  0.0000,   0.0000],\n",
            "         [415.9460, 167.4492],\n",
            "         [418.3931, 178.4043],\n",
            "         [382.7647, 182.5250],\n",
            "         [418.1132, 222.1481],\n",
            "         [360.2662, 244.7431],\n",
            "         [421.4991, 275.1629],\n",
            "         [353.1333, 296.0911],\n",
            "         [346.9417, 195.2361],\n",
            "         [320.3113, 192.4735],\n",
            "         [347.6943, 235.5063],\n",
            "         [287.3380, 233.1441],\n",
            "         [305.9005, 230.0248],\n",
            "         [231.7499, 227.1948]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6759, 0.4787],\n",
            "         [0.6802, 0.4669],\n",
            "         [0.6732, 0.4609],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6499, 0.4361],\n",
            "         [0.6537, 0.4646],\n",
            "         [0.5981, 0.4753],\n",
            "         [0.6533, 0.5785],\n",
            "         [0.5629, 0.6374],\n",
            "         [0.6586, 0.7166],\n",
            "         [0.5518, 0.7711],\n",
            "         [0.5421, 0.5084],\n",
            "         [0.5005, 0.5012],\n",
            "         [0.5433, 0.6133],\n",
            "         [0.4490, 0.6071],\n",
            "         [0.4780, 0.5990],\n",
            "         [0.3621, 0.5917]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.4ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9208, 0.6469, 0.8944, 0.2635, 0.8450, 0.9860, 0.9955, 0.9526, 0.9876, 0.8884, 0.9491, 0.9969, 0.9977, 0.9857, 0.9903, 0.9526, 0.9614]], device='cuda:0')\n",
            "data: tensor([[[4.3269e+02, 1.8407e+02, 9.2076e-01],\n",
            "         [4.3517e+02, 1.7933e+02, 6.4687e-01],\n",
            "         [4.3088e+02, 1.7727e+02, 8.9439e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.6351e-01],\n",
            "         [4.1598e+02, 1.6767e+02, 8.4500e-01],\n",
            "         [4.1853e+02, 1.7756e+02, 9.8600e-01],\n",
            "         [3.8246e+02, 1.8270e+02, 9.9554e-01],\n",
            "         [4.1777e+02, 2.2118e+02, 9.5255e-01],\n",
            "         [3.5991e+02, 2.4548e+02, 9.8761e-01],\n",
            "         [4.2148e+02, 2.7525e+02, 8.8841e-01],\n",
            "         [3.5335e+02, 2.9631e+02, 9.4909e-01],\n",
            "         [3.4698e+02, 1.9489e+02, 9.9686e-01],\n",
            "         [3.1993e+02, 1.9253e+02, 9.9768e-01],\n",
            "         [3.4974e+02, 2.3553e+02, 9.8569e-01],\n",
            "         [2.8783e+02, 2.3290e+02, 9.9034e-01],\n",
            "         [3.0863e+02, 2.3006e+02, 9.5257e-01],\n",
            "         [2.3161e+02, 2.2599e+02, 9.6138e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[432.6908, 184.0672],\n",
            "         [435.1692, 179.3324],\n",
            "         [430.8781, 177.2669],\n",
            "         [  0.0000,   0.0000],\n",
            "         [415.9791, 167.6735],\n",
            "         [418.5341, 177.5567],\n",
            "         [382.4560, 182.7015],\n",
            "         [417.7729, 221.1757],\n",
            "         [359.9096, 245.4750],\n",
            "         [421.4767, 275.2489],\n",
            "         [353.3528, 296.3059],\n",
            "         [346.9847, 194.8900],\n",
            "         [319.9265, 192.5310],\n",
            "         [349.7386, 235.5305],\n",
            "         [287.8312, 232.8987],\n",
            "         [308.6274, 230.0552],\n",
            "         [231.6060, 225.9886]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6761, 0.4793],\n",
            "         [0.6800, 0.4670],\n",
            "         [0.6732, 0.4616],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6500, 0.4366],\n",
            "         [0.6540, 0.4624],\n",
            "         [0.5976, 0.4758],\n",
            "         [0.6528, 0.5760],\n",
            "         [0.5624, 0.6393],\n",
            "         [0.6586, 0.7168],\n",
            "         [0.5521, 0.7716],\n",
            "         [0.5422, 0.5075],\n",
            "         [0.4999, 0.5014],\n",
            "         [0.5465, 0.6134],\n",
            "         [0.4497, 0.6065],\n",
            "         [0.4822, 0.5991],\n",
            "         [0.3619, 0.5885]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 1.4ms preprocess, 11.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9142, 0.6154, 0.8885, 0.2418, 0.8458, 0.9853, 0.9956, 0.9516, 0.9885, 0.8862, 0.9515, 0.9971, 0.9979, 0.9866, 0.9913, 0.9551, 0.9642]], device='cuda:0')\n",
            "data: tensor([[[4.3343e+02, 1.8373e+02, 9.1417e-01],\n",
            "         [4.3555e+02, 1.7886e+02, 6.1539e-01],\n",
            "         [4.3146e+02, 1.7709e+02, 8.8845e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4180e-01],\n",
            "         [4.1637e+02, 1.6793e+02, 8.4576e-01],\n",
            "         [4.1877e+02, 1.7726e+02, 9.8531e-01],\n",
            "         [3.8261e+02, 1.8277e+02, 9.9564e-01],\n",
            "         [4.1731e+02, 2.2153e+02, 9.5160e-01],\n",
            "         [3.5994e+02, 2.4581e+02, 9.8851e-01],\n",
            "         [4.2138e+02, 2.7511e+02, 8.8617e-01],\n",
            "         [3.5350e+02, 2.9632e+02, 9.5151e-01],\n",
            "         [3.4736e+02, 1.9451e+02, 9.9708e-01],\n",
            "         [3.1995e+02, 1.9232e+02, 9.9791e-01],\n",
            "         [3.5154e+02, 2.3607e+02, 9.8664e-01],\n",
            "         [2.8762e+02, 2.3326e+02, 9.9129e-01],\n",
            "         [3.1197e+02, 2.3155e+02, 9.5507e-01],\n",
            "         [2.3035e+02, 2.2685e+02, 9.6420e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[433.4341, 183.7303],\n",
            "         [435.5533, 178.8642],\n",
            "         [431.4644, 177.0948],\n",
            "         [  0.0000,   0.0000],\n",
            "         [416.3721, 167.9314],\n",
            "         [418.7693, 177.2578],\n",
            "         [382.6057, 182.7690],\n",
            "         [417.3066, 221.5323],\n",
            "         [359.9366, 245.8067],\n",
            "         [421.3755, 275.1127],\n",
            "         [353.4996, 296.3237],\n",
            "         [347.3552, 194.5112],\n",
            "         [319.9510, 192.3194],\n",
            "         [351.5418, 236.0666],\n",
            "         [287.6207, 233.2561],\n",
            "         [311.9678, 231.5525],\n",
            "         [230.3543, 226.8460]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6772, 0.4785],\n",
            "         [0.6806, 0.4658],\n",
            "         [0.6742, 0.4612],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6506, 0.4373],\n",
            "         [0.6543, 0.4616],\n",
            "         [0.5978, 0.4760],\n",
            "         [0.6520, 0.5769],\n",
            "         [0.5624, 0.6401],\n",
            "         [0.6584, 0.7164],\n",
            "         [0.5523, 0.7717],\n",
            "         [0.5427, 0.5065],\n",
            "         [0.4999, 0.5008],\n",
            "         [0.5493, 0.6148],\n",
            "         [0.4494, 0.6074],\n",
            "         [0.4874, 0.6030],\n",
            "         [0.3599, 0.5907]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.4ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9213, 0.6439, 0.8967, 0.2600, 0.8505, 0.9862, 0.9957, 0.9536, 0.9884, 0.8867, 0.9498, 0.9971, 0.9979, 0.9860, 0.9907, 0.9522, 0.9616]], device='cuda:0')\n",
            "data: tensor([[[4.3317e+02, 1.8379e+02, 9.2130e-01],\n",
            "         [4.3546e+02, 1.7903e+02, 6.4394e-01],\n",
            "         [4.3134e+02, 1.7695e+02, 8.9668e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.6004e-01],\n",
            "         [4.1640e+02, 1.6769e+02, 8.5047e-01],\n",
            "         [4.1924e+02, 1.7779e+02, 9.8624e-01],\n",
            "         [3.8207e+02, 1.8271e+02, 9.9575e-01],\n",
            "         [4.1679e+02, 2.2177e+02, 9.5362e-01],\n",
            "         [3.6028e+02, 2.4576e+02, 9.8839e-01],\n",
            "         [4.2125e+02, 2.7494e+02, 8.8668e-01],\n",
            "         [3.5394e+02, 2.9624e+02, 9.4977e-01],\n",
            "         [3.4885e+02, 1.9440e+02, 9.9708e-01],\n",
            "         [3.2037e+02, 1.9182e+02, 9.9786e-01],\n",
            "         [3.5616e+02, 2.3718e+02, 9.8605e-01],\n",
            "         [2.8724e+02, 2.3211e+02, 9.9067e-01],\n",
            "         [3.1934e+02, 2.3364e+02, 9.5225e-01],\n",
            "         [2.3060e+02, 2.2569e+02, 9.6157e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[433.1700, 183.7872],\n",
            "         [435.4580, 179.0342],\n",
            "         [431.3382, 176.9540],\n",
            "         [  0.0000,   0.0000],\n",
            "         [416.3973, 167.6880],\n",
            "         [419.2361, 177.7945],\n",
            "         [382.0741, 182.7095],\n",
            "         [416.7869, 221.7665],\n",
            "         [360.2787, 245.7614],\n",
            "         [421.2515, 274.9408],\n",
            "         [353.9425, 296.2388],\n",
            "         [348.8465, 194.4026],\n",
            "         [320.3663, 191.8208],\n",
            "         [356.1556, 237.1830],\n",
            "         [287.2354, 232.1110],\n",
            "         [319.3449, 233.6423],\n",
            "         [230.6034, 225.6877]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6768, 0.4786],\n",
            "         [0.6804, 0.4662],\n",
            "         [0.6740, 0.4608],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6506, 0.4367],\n",
            "         [0.6551, 0.4630],\n",
            "         [0.5970, 0.4758],\n",
            "         [0.6512, 0.5775],\n",
            "         [0.5629, 0.6400],\n",
            "         [0.6582, 0.7160],\n",
            "         [0.5530, 0.7715],\n",
            "         [0.5451, 0.5063],\n",
            "         [0.5006, 0.4995],\n",
            "         [0.5565, 0.6177],\n",
            "         [0.4488, 0.6045],\n",
            "         [0.4990, 0.6084],\n",
            "         [0.3603, 0.5877]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.3ms preprocess, 10.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9232, 0.6413, 0.9023, 0.2464, 0.8580, 0.9854, 0.9958, 0.9497, 0.9887, 0.8817, 0.9516, 0.9968, 0.9978, 0.9851, 0.9905, 0.9499, 0.9606]], device='cuda:0')\n",
            "data: tensor([[[4.3376e+02, 1.8344e+02, 9.2320e-01],\n",
            "         [4.3594e+02, 1.7842e+02, 6.4130e-01],\n",
            "         [4.3154e+02, 1.7664e+02, 9.0235e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4636e-01],\n",
            "         [4.1605e+02, 1.6756e+02, 8.5804e-01],\n",
            "         [4.1958e+02, 1.7738e+02, 9.8538e-01],\n",
            "         [3.8213e+02, 1.8271e+02, 9.9584e-01],\n",
            "         [4.1753e+02, 2.2198e+02, 9.4970e-01],\n",
            "         [3.5971e+02, 2.4599e+02, 9.8871e-01],\n",
            "         [4.2154e+02, 2.7521e+02, 8.8169e-01],\n",
            "         [3.5361e+02, 2.9646e+02, 9.5163e-01],\n",
            "         [3.4863e+02, 1.9411e+02, 9.9685e-01],\n",
            "         [3.2018e+02, 1.9178e+02, 9.9779e-01],\n",
            "         [3.5453e+02, 2.3625e+02, 9.8512e-01],\n",
            "         [2.8762e+02, 2.3230e+02, 9.9046e-01],\n",
            "         [3.1628e+02, 2.3201e+02, 9.4993e-01],\n",
            "         [2.3012e+02, 2.2546e+02, 9.6060e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[433.7646, 183.4380],\n",
            "         [435.9427, 178.4187],\n",
            "         [431.5444, 176.6377],\n",
            "         [  0.0000,   0.0000],\n",
            "         [416.0525, 167.5638],\n",
            "         [419.5782, 177.3825],\n",
            "         [382.1298, 182.7083],\n",
            "         [417.5266, 221.9834],\n",
            "         [359.7054, 245.9880],\n",
            "         [421.5428, 275.2117],\n",
            "         [353.6075, 296.4561],\n",
            "         [348.6312, 194.1130],\n",
            "         [320.1787, 191.7815],\n",
            "         [354.5335, 236.2498],\n",
            "         [287.6231, 232.3046],\n",
            "         [316.2805, 232.0131],\n",
            "         [230.1248, 225.4595]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6778, 0.4777],\n",
            "         [0.6812, 0.4646],\n",
            "         [0.6743, 0.4600],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6501, 0.4364],\n",
            "         [0.6556, 0.4619],\n",
            "         [0.5971, 0.4758],\n",
            "         [0.6524, 0.5781],\n",
            "         [0.5620, 0.6406],\n",
            "         [0.6587, 0.7167],\n",
            "         [0.5525, 0.7720],\n",
            "         [0.5447, 0.5055],\n",
            "         [0.5003, 0.4994],\n",
            "         [0.5540, 0.6152],\n",
            "         [0.4494, 0.6050],\n",
            "         [0.4942, 0.6042],\n",
            "         [0.3596, 0.5871]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 1.4ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9230, 0.6411, 0.9016, 0.2475, 0.8573, 0.9856, 0.9959, 0.9504, 0.9888, 0.8824, 0.9515, 0.9969, 0.9978, 0.9854, 0.9906, 0.9506, 0.9611]], device='cuda:0')\n",
            "data: tensor([[[4.3372e+02, 1.8345e+02, 9.2303e-01],\n",
            "         [4.3589e+02, 1.7839e+02, 6.4115e-01],\n",
            "         [4.3147e+02, 1.7660e+02, 9.0160e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4753e-01],\n",
            "         [4.1600e+02, 1.6747e+02, 8.5735e-01],\n",
            "         [4.1977e+02, 1.7737e+02, 9.8559e-01],\n",
            "         [3.8200e+02, 1.8267e+02, 9.9587e-01],\n",
            "         [4.1731e+02, 2.2196e+02, 9.5044e-01],\n",
            "         [3.5982e+02, 2.4604e+02, 9.8876e-01],\n",
            "         [4.2142e+02, 2.7506e+02, 8.8242e-01],\n",
            "         [3.5368e+02, 2.9639e+02, 9.5154e-01],\n",
            "         [3.4890e+02, 1.9453e+02, 9.9692e-01],\n",
            "         [3.2019e+02, 1.9211e+02, 9.9783e-01],\n",
            "         [3.5518e+02, 2.3695e+02, 9.8538e-01],\n",
            "         [2.8750e+02, 2.3230e+02, 9.9058e-01],\n",
            "         [3.1738e+02, 2.3294e+02, 9.5061e-01],\n",
            "         [2.3020e+02, 2.2526e+02, 9.6108e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[433.7209, 183.4451],\n",
            "         [435.8932, 178.3943],\n",
            "         [431.4740, 176.5996],\n",
            "         [  0.0000,   0.0000],\n",
            "         [415.9977, 167.4716],\n",
            "         [419.7701, 177.3659],\n",
            "         [381.9982, 182.6672],\n",
            "         [417.3122, 221.9597],\n",
            "         [359.8226, 246.0379],\n",
            "         [421.4210, 275.0594],\n",
            "         [353.6810, 296.3947],\n",
            "         [348.9031, 194.5349],\n",
            "         [320.1860, 192.1093],\n",
            "         [355.1750, 236.9498],\n",
            "         [287.4966, 232.3013],\n",
            "         [317.3822, 232.9436],\n",
            "         [230.2010, 225.2608]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6777, 0.4777],\n",
            "         [0.6811, 0.4646],\n",
            "         [0.6742, 0.4599],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6500, 0.4361],\n",
            "         [0.6559, 0.4619],\n",
            "         [0.5969, 0.4757],\n",
            "         [0.6521, 0.5780],\n",
            "         [0.5622, 0.6407],\n",
            "         [0.6585, 0.7163],\n",
            "         [0.5526, 0.7719],\n",
            "         [0.5452, 0.5066],\n",
            "         [0.5003, 0.5003],\n",
            "         [0.5550, 0.6171],\n",
            "         [0.4492, 0.6050],\n",
            "         [0.4959, 0.6066],\n",
            "         [0.3597, 0.5866]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.3ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9222, 0.6406, 0.8999, 0.2516, 0.8562, 0.9856, 0.9958, 0.9499, 0.9883, 0.8829, 0.9505, 0.9968, 0.9977, 0.9851, 0.9903, 0.9499, 0.9601]], device='cuda:0')\n",
            "data: tensor([[[4.3385e+02, 1.8272e+02, 9.2220e-01],\n",
            "         [4.3621e+02, 1.7785e+02, 6.4062e-01],\n",
            "         [4.3182e+02, 1.7585e+02, 8.9988e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5159e-01],\n",
            "         [4.1634e+02, 1.6687e+02, 8.5616e-01],\n",
            "         [4.1915e+02, 1.7727e+02, 9.8556e-01],\n",
            "         [3.8236e+02, 1.8272e+02, 9.9578e-01],\n",
            "         [4.1759e+02, 2.2113e+02, 9.4986e-01],\n",
            "         [3.5986e+02, 2.4602e+02, 9.8827e-01],\n",
            "         [4.2134e+02, 2.7499e+02, 8.8293e-01],\n",
            "         [3.5354e+02, 2.9654e+02, 9.5050e-01],\n",
            "         [3.4800e+02, 1.9414e+02, 9.9678e-01],\n",
            "         [3.2028e+02, 1.9183e+02, 9.9771e-01],\n",
            "         [3.5190e+02, 2.3596e+02, 9.8509e-01],\n",
            "         [2.8760e+02, 2.3246e+02, 9.9028e-01],\n",
            "         [3.1195e+02, 2.3182e+02, 9.4995e-01],\n",
            "         [2.3080e+02, 2.2612e+02, 9.6015e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[433.8537, 182.7173],\n",
            "         [436.2068, 177.8476],\n",
            "         [431.8202, 175.8509],\n",
            "         [  0.0000,   0.0000],\n",
            "         [416.3432, 166.8726],\n",
            "         [419.1455, 177.2686],\n",
            "         [382.3631, 182.7231],\n",
            "         [417.5903, 221.1325],\n",
            "         [359.8616, 246.0166],\n",
            "         [421.3417, 274.9935],\n",
            "         [353.5407, 296.5425],\n",
            "         [348.0008, 194.1431],\n",
            "         [320.2802, 191.8322],\n",
            "         [351.9020, 235.9610],\n",
            "         [287.5967, 232.4645],\n",
            "         [311.9494, 231.8234],\n",
            "         [230.8024, 226.1183]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6779, 0.4758],\n",
            "         [0.6816, 0.4631],\n",
            "         [0.6747, 0.4579],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6505, 0.4346],\n",
            "         [0.6549, 0.4616],\n",
            "         [0.5974, 0.4758],\n",
            "         [0.6525, 0.5759],\n",
            "         [0.5623, 0.6407],\n",
            "         [0.6583, 0.7161],\n",
            "         [0.5524, 0.7722],\n",
            "         [0.5438, 0.5056],\n",
            "         [0.5004, 0.4996],\n",
            "         [0.5498, 0.6145],\n",
            "         [0.4494, 0.6054],\n",
            "         [0.4874, 0.6037],\n",
            "         [0.3606, 0.5888]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.4ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9237, 0.6389, 0.9042, 0.2445, 0.8626, 0.9850, 0.9959, 0.9470, 0.9888, 0.8786, 0.9521, 0.9967, 0.9977, 0.9847, 0.9904, 0.9493, 0.9605]], device='cuda:0')\n",
            "data: tensor([[[4.3400e+02, 1.8287e+02, 9.2365e-01],\n",
            "         [4.3644e+02, 1.7799e+02, 6.3889e-01],\n",
            "         [4.3195e+02, 1.7595e+02, 9.0422e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4454e-01],\n",
            "         [4.1630e+02, 1.6682e+02, 8.6262e-01],\n",
            "         [4.1891e+02, 1.7741e+02, 9.8503e-01],\n",
            "         [3.8240e+02, 1.8277e+02, 9.9594e-01],\n",
            "         [4.1769e+02, 2.2161e+02, 9.4699e-01],\n",
            "         [3.5985e+02, 2.4636e+02, 9.8876e-01],\n",
            "         [4.2141e+02, 2.7504e+02, 8.7862e-01],\n",
            "         [3.5321e+02, 2.9666e+02, 9.5211e-01],\n",
            "         [3.4742e+02, 1.9460e+02, 9.9668e-01],\n",
            "         [3.1993e+02, 1.9230e+02, 9.9772e-01],\n",
            "         [3.5072e+02, 2.3615e+02, 9.8474e-01],\n",
            "         [2.8724e+02, 2.3323e+02, 9.9043e-01],\n",
            "         [3.0988e+02, 2.3124e+02, 9.4933e-01],\n",
            "         [2.3028e+02, 2.2666e+02, 9.6054e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[434.0016, 182.8671],\n",
            "         [436.4444, 177.9859],\n",
            "         [431.9520, 175.9499],\n",
            "         [  0.0000,   0.0000],\n",
            "         [416.3030, 166.8211],\n",
            "         [418.9109, 177.4130],\n",
            "         [382.3971, 182.7686],\n",
            "         [417.6912, 221.6097],\n",
            "         [359.8529, 246.3618],\n",
            "         [421.4056, 275.0448],\n",
            "         [353.2136, 296.6579],\n",
            "         [347.4214, 194.6030],\n",
            "         [319.9254, 192.2993],\n",
            "         [350.7203, 236.1504],\n",
            "         [287.2374, 233.2256],\n",
            "         [309.8808, 231.2374],\n",
            "         [230.2842, 226.6554]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6781, 0.4762],\n",
            "         [0.6819, 0.4635],\n",
            "         [0.6749, 0.4582],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6505, 0.4344],\n",
            "         [0.6545, 0.4620],\n",
            "         [0.5975, 0.4760],\n",
            "         [0.6526, 0.5771],\n",
            "         [0.5623, 0.6416],\n",
            "         [0.6584, 0.7163],\n",
            "         [0.5519, 0.7725],\n",
            "         [0.5428, 0.5068],\n",
            "         [0.4999, 0.5008],\n",
            "         [0.5480, 0.6150],\n",
            "         [0.4488, 0.6074],\n",
            "         [0.4842, 0.6022],\n",
            "         [0.3598, 0.5902]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 1.5ms preprocess, 16.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9224, 0.6399, 0.9007, 0.2484, 0.8567, 0.9853, 0.9958, 0.9494, 0.9887, 0.8818, 0.9517, 0.9968, 0.9978, 0.9850, 0.9904, 0.9495, 0.9603]], device='cuda:0')\n",
            "data: tensor([[[4.3388e+02, 1.8323e+02, 9.2235e-01],\n",
            "         [4.3611e+02, 1.7831e+02, 6.3988e-01],\n",
            "         [4.3177e+02, 1.7642e+02, 9.0072e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.4842e-01],\n",
            "         [4.1642e+02, 1.6745e+02, 8.5667e-01],\n",
            "         [4.1949e+02, 1.7752e+02, 9.8529e-01],\n",
            "         [3.8264e+02, 1.8281e+02, 9.9583e-01],\n",
            "         [4.1742e+02, 2.2140e+02, 9.4936e-01],\n",
            "         [3.5944e+02, 2.4558e+02, 9.8866e-01],\n",
            "         [4.2121e+02, 2.7476e+02, 8.8184e-01],\n",
            "         [3.5306e+02, 2.9629e+02, 9.5172e-01],\n",
            "         [3.4868e+02, 1.9454e+02, 9.9683e-01],\n",
            "         [3.2073e+02, 1.9220e+02, 9.9778e-01],\n",
            "         [3.5366e+02, 2.3663e+02, 9.8501e-01],\n",
            "         [2.8810e+02, 2.3306e+02, 9.9041e-01],\n",
            "         [3.1410e+02, 2.3190e+02, 9.4949e-01],\n",
            "         [2.3012e+02, 2.2601e+02, 9.6026e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[433.8848, 183.2324],\n",
            "         [436.1098, 178.3084],\n",
            "         [431.7688, 176.4246],\n",
            "         [  0.0000,   0.0000],\n",
            "         [416.4247, 167.4452],\n",
            "         [419.4922, 177.5190],\n",
            "         [382.6430, 182.8122],\n",
            "         [417.4191, 221.3972],\n",
            "         [359.4423, 245.5782],\n",
            "         [421.2100, 274.7632],\n",
            "         [353.0637, 296.2872],\n",
            "         [348.6802, 194.5379],\n",
            "         [320.7314, 192.1964],\n",
            "         [353.6562, 236.6310],\n",
            "         [288.1017, 233.0553],\n",
            "         [314.0999, 231.8972],\n",
            "         [230.1207, 226.0059]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6779, 0.4772],\n",
            "         [0.6814, 0.4643],\n",
            "         [0.6746, 0.4594],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6507, 0.4361],\n",
            "         [0.6555, 0.4623],\n",
            "         [0.5979, 0.4761],\n",
            "         [0.6522, 0.5766],\n",
            "         [0.5616, 0.6395],\n",
            "         [0.6581, 0.7155],\n",
            "         [0.5517, 0.7716],\n",
            "         [0.5448, 0.5066],\n",
            "         [0.5011, 0.5005],\n",
            "         [0.5526, 0.6162],\n",
            "         [0.4502, 0.6069],\n",
            "         [0.4908, 0.6039],\n",
            "         [0.3596, 0.5886]]], device='cuda:0')\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 1.6ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "ultralytics.engine.results.Keypoints object with attributes:\n",
            "\n",
            "conf: tensor([[0.9210, 0.6443, 0.8956, 0.2594, 0.8479, 0.9860, 0.9957, 0.9530, 0.9883, 0.8876, 0.9508, 0.9970, 0.9978, 0.9859, 0.9906, 0.9513, 0.9608]], device='cuda:0')\n",
            "data: tensor([[[4.3357e+02, 1.8345e+02, 9.2099e-01],\n",
            "         [4.3573e+02, 1.7863e+02, 6.4431e-01],\n",
            "         [4.3158e+02, 1.7671e+02, 8.9562e-01],\n",
            "         [0.0000e+00, 0.0000e+00, 2.5945e-01],\n",
            "         [4.1667e+02, 1.6782e+02, 8.4790e-01],\n",
            "         [4.1973e+02, 1.7773e+02, 9.8596e-01],\n",
            "         [3.8292e+02, 1.8288e+02, 9.9566e-01],\n",
            "         [4.1747e+02, 2.2128e+02, 9.5296e-01],\n",
            "         [3.5968e+02, 2.4509e+02, 9.8831e-01],\n",
            "         [4.2132e+02, 2.7475e+02, 8.8759e-01],\n",
            "         [3.5383e+02, 2.9555e+02, 9.5079e-01],\n",
            "         [3.4966e+02, 1.9404e+02, 9.9704e-01],\n",
            "         [3.2155e+02, 1.9167e+02, 9.9785e-01],\n",
            "         [3.5637e+02, 2.3682e+02, 9.8586e-01],\n",
            "         [2.8916e+02, 2.3305e+02, 9.9062e-01],\n",
            "         [3.1758e+02, 2.3271e+02, 9.5126e-01],\n",
            "         [2.3039e+02, 2.2655e+02, 9.6084e-01]]], device='cuda:0')\n",
            "has_visible: True\n",
            "orig_shape: (384, 640)\n",
            "shape: torch.Size([1, 17, 3])\n",
            "xy: tensor([[[433.5709, 183.4481],\n",
            "         [435.7277, 178.6257],\n",
            "         [431.5843, 176.7055],\n",
            "         [  0.0000,   0.0000],\n",
            "         [416.6743, 167.8218],\n",
            "         [419.7316, 177.7299],\n",
            "         [382.9238, 182.8760],\n",
            "         [417.4654, 221.2754],\n",
            "         [359.6766, 245.0864],\n",
            "         [421.3220, 274.7531],\n",
            "         [353.8348, 295.5538],\n",
            "         [349.6617, 194.0376],\n",
            "         [321.5461, 191.6729],\n",
            "         [356.3658, 236.8212],\n",
            "         [289.1613, 233.0472],\n",
            "         [317.5766, 232.7107],\n",
            "         [230.3885, 226.5532]]], device='cuda:0')\n",
            "xyn: tensor([[[0.6775, 0.4777],\n",
            "         [0.6808, 0.4652],\n",
            "         [0.6744, 0.4602],\n",
            "         [0.0000, 0.0000],\n",
            "         [0.6511, 0.4370],\n",
            "         [0.6558, 0.4628],\n",
            "         [0.5983, 0.4762],\n",
            "         [0.6523, 0.5762],\n",
            "         [0.5620, 0.6382],\n",
            "         [0.6583, 0.7155],\n",
            "         [0.5529, 0.7697],\n",
            "         [0.5463, 0.5053],\n",
            "         [0.5024, 0.4991],\n",
            "         [0.5568, 0.6167],\n",
            "         [0.4518, 0.6069],\n",
            "         [0.4962, 0.6060],\n",
            "         [0.3600, 0.5900]]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Bicep**"
      ],
      "metadata": {
        "id": "hUc7WiMRPVIW"
      },
      "id": "hUc7WiMRPVIW"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 Pose model\n",
        "model = YOLO('yolov8n-pose.pt')  # or 'yolov8x-pose.pt' for a larger model\n",
        "video_path = '/content/Bicep 4.mp4'  # Path to your input video\n",
        "out_path = 'results_bicep_curls.mp4'  # Path to save the output video\n",
        "\n",
        "def calculate_angle(p1, p2, p3):\n",
        "    \"\"\" Calculate the angle between three points. \"\"\"\n",
        "    a = np.array(p1)\n",
        "    b = np.array(p2)\n",
        "    c = np.array(p3)\n",
        "    ab = a - b\n",
        "    bc = c - b\n",
        "    angle = np.arccos(np.clip(np.dot(ab, bc) / (np.linalg.norm(ab) * np.linalg.norm(bc)), -1.0, 1.0))\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def draw_keypoints(frame, keypoints, indices):\n",
        "    \"\"\" Draw specific keypoints on the frame. \"\"\"\n",
        "    for i in indices:\n",
        "        point = keypoints[i]\n",
        "        cv2.circle(frame, tuple(map(int, point)), 10, (255, 0, 0), -1)  # Blue points for selected keypoints\n",
        "\n",
        "def draw_connections(frame, keypoints, connections):\n",
        "    \"\"\" Draw lines between specific keypoints to visualize connections. \"\"\"\n",
        "    for start_idx, end_idx in connections:\n",
        "        start_point = tuple(map(int, keypoints[start_idx]))\n",
        "        end_point = tuple(map(int, keypoints[end_idx]))\n",
        "        cv2.line(frame, start_point, end_point, (0, 255, 0), 5)  # Green lines for connections\n",
        "\n",
        "def main():\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        return\n",
        "\n",
        "    # Get original video dimensions\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Initialize VideoWriter with original dimensions\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'mp4v' for .mp4 format\n",
        "    out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))  # Use original dimensions\n",
        "\n",
        "    curl_count = 0\n",
        "    curl_state = \"down\"\n",
        "\n",
        "    # Define connections based on specific pose estimation keypoints (shoulder, elbow, wrist, and hip)\n",
        "    connections = [\n",
        "        (5, 7),  # Shoulder to Elbow\n",
        "        (7, 9),  # Elbow to Wrist\n",
        "        (5, 11)  # Shoulder to Hip (to show body alignment)\n",
        "    ]\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Preprocess frame for YOLOv8 Pose\n",
        "        results = model(frame)\n",
        "\n",
        "        # Extract keypoints\n",
        "        keypoints = np.array(results[0].keypoints.xy.tolist()).reshape(-1, 2)  # Assuming keypoints are in the first result\n",
        "\n",
        "        if len(keypoints) >= 12:  # Ensure enough keypoints are detected\n",
        "            # Extract keypoints (shoulder, elbow, wrist, and hip)\n",
        "            shoulder = keypoints[5]\n",
        "            elbow = keypoints[7]\n",
        "            wrist = keypoints[9]\n",
        "            hip = keypoints[11]\n",
        "\n",
        "            arm_angle = calculate_angle(shoulder, elbow, wrist)\n",
        "            body_arm_angle = calculate_angle(hip, shoulder, elbow)\n",
        "            correct_postion = True\n",
        "\n",
        "            # Determine curl state based on arm angle, only count if body-arm angle is less than or equal to 20 degrees\n",
        "            if body_arm_angle <= 20:\n",
        "                if arm_angle < 60:  # Adjust angle threshold based on your observation\n",
        "                    if curl_state == \"down\":\n",
        "                        curl_count += 1\n",
        "                        curl_state = \"up\"\n",
        "                elif arm_angle > 140:  # Adjust angle threshold based on your observation\n",
        "                    if curl_state == \"up\":\n",
        "                        curl_state = \"down\"\n",
        "            else:\n",
        "                correct_postion = False\n",
        "\n",
        "            # Draw keypoints and connections\n",
        "            draw_keypoints(frame, keypoints, [5, 7, 9, 11])\n",
        "            draw_connections(frame, keypoints, connections)\n",
        "\n",
        "            # Display the angles on the frame\n",
        "            cv2.putText(frame, f\"Arm: {arm_angle:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
        "            cv2.putText(frame, f\"Bo: {body_arm_angle:.2f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Display the count and state on the frame\n",
        "        cv2.putText(frame, f\"Curls: {curl_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv2.LINE_AA)\n",
        "        cv2.putText(frame, f\"State: {curl_state}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2, cv2.LINE_AA)\n",
        "        cv2.putText(frame, f\"Correct: {'Yes' if correct_postion else 'No'}\", (30, 140), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0) if correct_postion else (0, 0, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Write the frame to the output video\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TKrZO-Vg9pJ",
        "outputId": "f82dd4b3-fff1-4f88-bd01-829fb6e45fc5"
      },
      "id": "7TKrZO-Vg9pJ",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.6ms preprocess, 10.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.5ms\n",
            "Speed: 2.8ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.3ms\n",
            "Speed: 1.8ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.1ms\n",
            "Speed: 1.6ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.3ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.2ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.4ms preprocess, 7.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 1.6ms preprocess, 8.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 1.5ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.4ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.3ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 2.2ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.1ms\n",
            "Speed: 2.4ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 2.3ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 1.6ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.6ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.0ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.4ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.7ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.7ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.5ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.3ms\n",
            "Speed: 1.6ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 1.3ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.9ms preprocess, 7.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 1.5ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.1ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 2.4ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.1ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.8ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.7ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.2ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.1ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 1.3ms preprocess, 16.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.9ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.7ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.8ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.4ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.3ms preprocess, 11.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.3ms\n",
            "Speed: 1.4ms preprocess, 19.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.5ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.4ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.2ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.4ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.2ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.5ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.2ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 1.5ms preprocess, 11.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 1.4ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.7ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.5ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 1.4ms preprocess, 15.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 1.5ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.5ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.5ms preprocess, 10.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.5ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.3ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.1ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 4.2ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.5ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.4ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 2.7ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.3ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.7ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 2.5ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 2.2ms preprocess, 14.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 1.6ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.2ms\n",
            "Speed: 1.6ms preprocess, 20.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 1.4ms preprocess, 16.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 1.4ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 1.3ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.4ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.5ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.4ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 2.4ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.4ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.2ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.8ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 1.4ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 0.9ms preprocess, 8.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 2.1ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 1.4ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.3ms preprocess, 8.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.7ms\n",
            "Speed: 1.4ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.3ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 1.5ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.4ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 1.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.4ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 1.5ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 1.4ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.4ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.3ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.4ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 1.5ms preprocess, 12.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.3ms\n",
            "Speed: 2.3ms preprocess, 17.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 1.4ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.6ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.5ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 1.6ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 1.3ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 1.4ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.9ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.4ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 1.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.4ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.1ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.1ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 2.0ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.6ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.4ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.4ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.3ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.4ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.3ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.3ms preprocess, 7.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.3ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.2ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.4ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.5ms\n",
            "Speed: 1.4ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 2.8ms preprocess, 16.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.5ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 1.3ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.3ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.4ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 1.4ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.5ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 1.5ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 1.7ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.7ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 4.7ms preprocess, 14.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 1.5ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.4ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.5ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 1.2ms preprocess, 12.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.5ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.4ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.7ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 1.6ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 2.2ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.8ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.6ms preprocess, 7.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.6ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 1.8ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.5ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 1.3ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 1.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.2ms\n",
            "Speed: 1.4ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.3ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 1.1ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.5ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.6ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.6ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.3ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 1.2ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 3.1ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.5ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.4ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 1.5ms preprocess, 16.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.8ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 1.7ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 1.4ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.5ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 1.5ms preprocess, 12.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.2ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 1.4ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 1.4ms preprocess, 11.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.5ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.4ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.4ms\n",
            "Speed: 1.4ms preprocess, 11.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.7ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.7ms\n",
            "Speed: 2.7ms preprocess, 9.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.5ms\n",
            "Speed: 1.5ms preprocess, 9.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.4ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 1.3ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.1ms\n",
            "Speed: 1.6ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.1ms\n",
            "Speed: 1.3ms preprocess, 10.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 8.0ms\n",
            "Speed: 1.3ms preprocess, 8.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-3ba716cb5731>:17: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  angle = np.arccos(np.clip(np.dot(ab, bc) / (np.linalg.norm(ab) * np.linalg.norm(bc)), -1.0, 1.0))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 (no detections), 8.7ms\n",
            "Speed: 1.3ms preprocess, 8.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 9.9ms\n",
            "Speed: 1.3ms preprocess, 9.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.5ms\n",
            "Speed: 1.4ms preprocess, 10.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.7ms preprocess, 12.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 11.2ms\n",
            "Speed: 1.4ms preprocess, 11.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 (no detections), 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Squats**"
      ],
      "metadata": {
        "id": "fjOil-LiPeLt"
      },
      "id": "fjOil-LiPeLt"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 Pose model\n",
        "model = YOLO('yolov8n-pose.pt')  # or 'yolov8x-pose.pt' for a larger model\n",
        "video_path = '/content/squat.mp4'  # Path to your input video\n",
        "out_path = 'results_squats.mp4'  # Path to save the output video\n",
        "\n",
        "def calculate_angle(p1, p2, p3):\n",
        "    \"\"\" Calculate the angle between three points. \"\"\"\n",
        "    a = np.array(p1)\n",
        "    b = np.array(p2)\n",
        "    c = np.array(p3)\n",
        "    ab = a - b\n",
        "    bc = c - b\n",
        "    angle = np.arccos(np.clip(np.dot(ab, bc) / (np.linalg.norm(ab) * np.linalg.norm(bc)), -1.0, 1.0))\n",
        "    return np.degrees(angle)\n",
        "\n",
        "def draw_keypoints(frame, keypoints, indices):\n",
        "    \"\"\" Draw specific keypoints on the frame. \"\"\"\n",
        "    for i in indices:\n",
        "        point = keypoints[i]\n",
        "        cv2.circle(frame, tuple(map(int, point)), 7, (255, 0, 0), -1)  # Blue points for selected keypoints\n",
        "\n",
        "def draw_connections(frame, keypoints, connections, color):\n",
        "    \"\"\" Draw lines between specific keypoints to visualize connections. \"\"\"\n",
        "    for start_idx, end_idx in connections:\n",
        "        start_point = tuple(map(int, keypoints[start_idx]))\n",
        "        end_point = tuple(map(int, keypoints[end_idx]))\n",
        "        cv2.line(frame, start_point, end_point, color, 3)  # Color-coded lines for connections\n",
        "\n",
        "def main():\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Could not open video.\")\n",
        "        return\n",
        "\n",
        "    # Get original video dimensions\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Initialize VideoWriter with original dimensions\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use 'mp4v' for .mp4 format\n",
        "    out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))  # Use original dimensions\n",
        "\n",
        "    squat_count = 0\n",
        "    squat_state = \"up\"\n",
        "\n",
        "    # Define connections for keypoints: (shoulder, hip, knee, ankle)\n",
        "    connections = [\n",
        "        (11, 13),  # Hip to Knee\n",
        "        (13, 15),  # Knee to Ankle\n",
        "        (12, 11),  # Shoulder to Hip\n",
        "        (5, 11),   # Neck to Hip\n",
        "    ]\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Preprocess frame for YOLOv8 Pose\n",
        "        results = model(frame)\n",
        "\n",
        "        # Extract keypoints\n",
        "        keypoints = np.array(results[0].keypoints.xy.tolist()).reshape(-1, 2)  # Assuming keypoints are in the first result\n",
        "        if len(keypoints) >= 16:  # Ensure enough keypoints are detected\n",
        "            # Extract keypoints (shoulder, hip, knee, ankle)\n",
        "            shoulder = keypoints[12]  # Shoulder keypoint\n",
        "            hip = keypoints[11]       # Hip keypoint\n",
        "            hip2 = keypoints[12]      # Shoulder keypoint\n",
        "            knee = keypoints[13]      # Knee keypoint\n",
        "            ankle = keypoints[15]     # Ankle keypoint\n",
        "\n",
        "            # Calculate angles\n",
        "            knee_angle = calculate_angle(hip, knee, ankle)\n",
        "            shoulder_hip_knee_angle = calculate_angle(shoulder, hip, knee)\n",
        "            hip_hip_knee_angle = calculate_angle(hip2, hip, knee)\n",
        "\n",
        "            # Determine squat state based on knee angle\n",
        "            if knee_angle < 125:  # Adjusted angle threshold for squat down position\n",
        "                if squat_state == \"up\":\n",
        "                    squat_count += 1\n",
        "                    squat_state = \"down\"\n",
        "            elif knee_angle > 160:  # Adjusted angle threshold for squat up position\n",
        "                if squat_state == \"down\":\n",
        "                    squat_state = \"up\"\n",
        "\n",
        "            # Check leg position based on hip-hip-knee angle\n",
        "            correct_leg_position = True\n",
        "            if hip_hip_knee_angle < 90 :\n",
        "                correct_leg_position = False  # Leg should be more extended in the \"up\" position\n",
        "\n",
        "            # Draw keypoints and connections with specific colors for angles\n",
        "            draw_keypoints(frame, keypoints, [12, 11, 13, 15])\n",
        "            draw_connections(frame, keypoints, [(11, 13), (13, 15)], (0, 255, 255))  # Yellow for knee angle\n",
        "            # draw_connections(frame, keypoints, [(12, 11)], (0, 255, 0))  # Green for shoulder-hip-knee angle\n",
        "            draw_connections(frame, keypoints, [(12,11)], (255, 0, 0))  # Blue for hip-hip-knee angle\n",
        "\n",
        "            # Display the angles in a white box at the upper right corner\n",
        "            cv2.rectangle(frame, (width - 220, 10), (width - 10, 150), (255, 255, 255), -1)\n",
        "            cv2.putText(frame, f\"KA: {knee_angle:.2f}\", (width - 210, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2, cv2.LINE_AA)\n",
        "            cv2.putText(frame, f\"HHK: {hip_hip_knee_angle:.2f}\", (width - 210, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
        "            # cv2.putText(frame, f\"SHK: {shoulder_hip_knee_angle:.2f}\", (width - 210, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "            # Display the correct positions for legs and back\n",
        "            cv2.putText(frame, f\"Legs: {'Yes' if correct_leg_position else 'No'}\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0) if correct_leg_position else (0, 0, 255), 2, cv2.LINE_AA)\n",
        "            # cv2.putText(frame, f\"Back: {'Yes' if correct_back_position else 'No'}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0) if correct_back_position else (0, 0, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Display the count and state on the frame\n",
        "        cv2.putText(frame, f\"Squats: {squat_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2, cv2.LINE_AA)\n",
        "        cv2.putText(frame, f\"State: {squat_state}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Write the frame to the output video\n",
        "        out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2St2TR95ln3F",
        "outputId": "c7606049-ab22-4e82-9b53-2c456d724b18"
      },
      "id": "2St2TR95ln3F",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.1ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 1.4ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.3ms\n",
            "Speed: 1.4ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 2.5ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.3ms\n",
            "Speed: 2.4ms preprocess, 7.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 1.8ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 1.8ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.5ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 2.3ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.7ms\n",
            "Speed: 1.4ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.7ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 1.6ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.4ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.3ms preprocess, 10.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 1.5ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.3ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 1.4ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 3.1ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.5ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.4ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.7ms preprocess, 9.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 3.1ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 1.2ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.3ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 1.6ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.3ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 1.5ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.8ms\n",
            "Speed: 1.9ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 1.4ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.6ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 1.7ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 1.3ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.9ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 1.3ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.3ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.4ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 1.3ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.5ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 1.3ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 1.3ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 1.3ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.5ms preprocess, 11.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.6ms preprocess, 15.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 2.4ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.5ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.5ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.5ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 1.3ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.4ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.9ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 2.7ms preprocess, 17.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.3ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.3ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.5ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.2ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.3ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.4ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 1.4ms preprocess, 12.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.5ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 1.2ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.4ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.9ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 1.8ms preprocess, 13.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 1.8ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 1.4ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.3ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.4ms preprocess, 10.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.4ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.3ms preprocess, 7.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.4ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.9ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 2.4ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.6ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 1.9ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 1.3ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.4ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.3ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.4ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.3ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.3ms preprocess, 7.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 1.3ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.3ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.5ms\n",
            "Speed: 1.7ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 2.4ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.3ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.3ms\n",
            "Speed: 2.5ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 1.2ms preprocess, 9.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 1.4ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 1.5ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.4ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.5ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.8ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 1.4ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.4ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.5ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.8ms\n",
            "Speed: 1.7ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.7ms\n",
            "Speed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 1.5ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.8ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 1.4ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 1.2ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.4ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.3ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.1ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.3ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.3ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.3ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 1.2ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.2ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 1.4ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 1.3ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 2.5ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.8ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 1.8ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.6ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.3ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 2.9ms preprocess, 10.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 1.3ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 1.3ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.6ms\n",
            "Speed: 2.7ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 1.4ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.7ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.3ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.3ms preprocess, 10.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.6ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 1.5ms preprocess, 11.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.7ms preprocess, 10.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.6ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.7ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 1.5ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 3.0ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.3ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.6ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 1.4ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 1.3ms preprocess, 17.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.6ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.3ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.3ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.6ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 3.5ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 1.4ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.3ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.6ms preprocess, 10.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.7ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.3ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.3ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.3ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.4ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.3ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.3ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.9ms preprocess, 11.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.1ms\n",
            "Speed: 1.4ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.4ms preprocess, 11.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.8ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 1.4ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 1.5ms preprocess, 16.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.6ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.6ms preprocess, 10.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.6ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 1.3ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 2.6ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.5ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 2.7ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 1.5ms preprocess, 11.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 2.6ms preprocess, 16.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 1.4ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.4ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.7ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 2.0ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.4ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 1.8ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 1.5ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.6ms\n",
            "Speed: 1.9ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 1.6ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.2ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.2ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.4ms\n",
            "Speed: 1.3ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.2ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.3ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.2ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.3ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 1.3ms preprocess, 9.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 1.3ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.2ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.2ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.5ms\n",
            "Speed: 1.3ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.2ms preprocess, 10.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 1.5ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.4ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.4ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 1.4ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.2ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.3ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 1.3ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.8ms\n",
            "Speed: 1.6ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 1.2ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 1.3ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.8ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.3ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 1.4ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.7ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.7ms\n",
            "Speed: 1.5ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.5ms preprocess, 8.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 1.4ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 1.2ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.7ms\n",
            "Speed: 1.2ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.4ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.6ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 1.4ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.4ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.5ms preprocess, 8.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.4ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.4ms preprocess, 8.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.4ms preprocess, 8.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.7ms\n",
            "Speed: 1.3ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 1.3ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 1.3ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 1.3ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.7ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 1.4ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.4ms\n",
            "Speed: 1.3ms preprocess, 18.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 4.5ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.6ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.5ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 1.3ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 1.4ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.3ms preprocess, 10.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.5ms\n",
            "Speed: 3.0ms preprocess, 16.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.6ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 1.7ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.3ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 4.1ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.6ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.7ms preprocess, 10.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 1.4ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 1.4ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 3.0ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 1.4ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.3ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.4ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.7ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 1.3ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.3ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.3ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.3ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.3ms preprocess, 10.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.5ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.5ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.6ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.9ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.7ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.4ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.7ms\n",
            "Speed: 1.8ms preprocess, 16.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.8ms\n",
            "Speed: 1.4ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 2.0ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.5ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.3ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.3ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 1.4ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.8ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.4ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.4ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 1.3ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 1.4ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 1.5ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.5ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.4ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 1.9ms preprocess, 17.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 1.5ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 5.3ms preprocess, 12.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.7ms\n",
            "Speed: 1.4ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 1.4ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.4ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.4ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.3ms preprocess, 10.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.4ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.4ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.2ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 1.5ms preprocess, 13.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 1.5ms preprocess, 14.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 1.4ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 1.4ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.5ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 1.5ms preprocess, 13.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.7ms\n",
            "Speed: 1.6ms preprocess, 18.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 1.6ms preprocess, 14.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.6ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 1.3ms preprocess, 14.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 1.4ms preprocess, 16.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 1.4ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.4ms preprocess, 11.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 1.4ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.5ms\n",
            "Speed: 1.7ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.4ms\n",
            "Speed: 1.3ms preprocess, 10.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 1.3ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.4ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.3ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 3.6ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.4ms\n",
            "Speed: 1.3ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.3ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 1.3ms preprocess, 9.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.4ms\n",
            "Speed: 1.4ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 1.4ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 3.7ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 1.3ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 1.6ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 1.3ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.1ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.6ms\n",
            "Speed: 1.4ms preprocess, 16.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.9ms\n",
            "Speed: 2.0ms preprocess, 13.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 2.6ms preprocess, 15.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 1.5ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 1.5ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 1.5ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 1.5ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.5ms\n",
            "Speed: 1.8ms preprocess, 19.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.9ms\n",
            "Speed: 1.4ms preprocess, 20.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.3ms\n",
            "Speed: 3.0ms preprocess, 22.3ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 4.0ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 1.4ms preprocess, 17.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 3.5ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 1.3ms preprocess, 18.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.1ms\n",
            "Speed: 1.5ms preprocess, 14.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.9ms\n",
            "Speed: 1.5ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.9ms\n",
            "Speed: 1.5ms preprocess, 17.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.8ms\n",
            "Speed: 1.5ms preprocess, 18.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.2ms\n",
            "Speed: 1.4ms preprocess, 14.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.4ms\n",
            "Speed: 1.4ms preprocess, 16.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.0ms\n",
            "Speed: 1.5ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.3ms\n",
            "Speed: 4.9ms preprocess, 16.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.3ms\n",
            "Speed: 1.4ms preprocess, 18.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 19.8ms\n",
            "Speed: 1.4ms preprocess, 19.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 4.7ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 1.4ms preprocess, 17.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 1.4ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.6ms\n",
            "Speed: 1.3ms preprocess, 17.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.8ms\n",
            "Speed: 1.4ms preprocess, 12.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.1ms\n",
            "Speed: 1.4ms preprocess, 15.1ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 1.3ms preprocess, 15.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.0ms\n",
            "Speed: 1.4ms preprocess, 14.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.5ms\n",
            "Speed: 1.3ms preprocess, 13.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.2ms\n",
            "Speed: 1.3ms preprocess, 20.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 1.6ms preprocess, 15.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 1.2ms preprocess, 12.6ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.4ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 3.6ms preprocess, 11.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.9ms\n",
            "Speed: 1.4ms preprocess, 15.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 1.3ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 3.7ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 1.4ms preprocess, 13.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 1.4ms preprocess, 14.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.5ms\n",
            "Speed: 1.4ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 1.5ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 1.4ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.3ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 1.4ms preprocess, 14.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 1.2ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.4ms\n",
            "Speed: 1.3ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 1.3ms preprocess, 15.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.2ms\n",
            "Speed: 2.3ms preprocess, 17.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.7ms\n",
            "Speed: 1.4ms preprocess, 17.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.1ms\n",
            "Speed: 2.9ms preprocess, 17.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.6ms\n",
            "Speed: 1.4ms preprocess, 18.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.1ms\n",
            "Speed: 2.0ms preprocess, 21.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 3.3ms preprocess, 13.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.8ms\n",
            "Speed: 1.3ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.2ms\n",
            "Speed: 1.3ms preprocess, 16.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 2.2ms preprocess, 13.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.4ms\n",
            "Speed: 1.3ms preprocess, 13.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.4ms\n",
            "Speed: 2.7ms preprocess, 15.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 17.8ms\n",
            "Speed: 1.5ms preprocess, 17.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 16.0ms\n",
            "Speed: 3.8ms preprocess, 16.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.6ms\n",
            "Speed: 1.5ms preprocess, 15.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.3ms\n",
            "Speed: 1.9ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.0ms\n",
            "Speed: 1.7ms preprocess, 18.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.1ms\n",
            "Speed: 1.5ms preprocess, 18.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 20.7ms\n",
            "Speed: 1.8ms preprocess, 20.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 18.9ms\n",
            "Speed: 1.3ms preprocess, 18.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 25.1ms\n",
            "Speed: 2.0ms preprocess, 25.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 22.5ms\n",
            "Speed: 1.4ms preprocess, 22.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 1.4ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 1.5ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.6ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.3ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 1.3ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 2.8ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.8ms\n",
            "Speed: 2.8ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 1.6ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 1.9ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.8ms\n",
            "Speed: 1.4ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 1.6ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 1.4ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 1.5ms preprocess, 10.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.7ms\n",
            "Speed: 1.5ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.3ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.4ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.9ms\n",
            "Speed: 1.3ms preprocess, 9.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.3ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 1.2ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 1.4ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 1.7ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.6ms\n",
            "Speed: 1.9ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 1.5ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.2ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.3ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 1.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.9ms\n",
            "Speed: 1.6ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.0ms\n",
            "Speed: 1.3ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.2ms\n",
            "Speed: 1.2ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.3ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.3ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 2.1ms preprocess, 7.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 1.3ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.3ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 1.4ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.7ms\n",
            "Speed: 1.3ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.1ms\n",
            "Speed: 1.3ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 1.3ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.5ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.3ms\n",
            "Speed: 1.5ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.2ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 1.7ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.9ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.4ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 3.2ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 2.5ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 1.3ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 1.4ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.1ms\n",
            "Speed: 1.4ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 1.7ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.4ms\n",
            "Speed: 1.4ms preprocess, 12.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.5ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.5ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 1.2ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.9ms\n",
            "Speed: 1.9ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.6ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.2ms\n",
            "Speed: 1.3ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.6ms\n",
            "Speed: 1.9ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 1.3ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.0ms\n",
            "Speed: 1.4ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.5ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 1.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.3ms preprocess, 12.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.2ms\n",
            "Speed: 1.7ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 1.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.4ms preprocess, 10.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.8ms\n",
            "Speed: 1.3ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.5ms\n",
            "Speed: 1.3ms preprocess, 15.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 21.2ms\n",
            "Speed: 1.4ms preprocess, 21.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 3.2ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 3.2ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 15.0ms\n",
            "Speed: 1.7ms preprocess, 15.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.9ms\n",
            "Speed: 1.5ms preprocess, 12.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.1ms\n",
            "Speed: 3.7ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.6ms\n",
            "Speed: 1.3ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.9ms\n",
            "Speed: 2.1ms preprocess, 14.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.5ms\n",
            "Speed: 1.4ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 3.3ms preprocess, 11.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 1.2ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.5ms\n",
            "Speed: 1.3ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.3ms\n",
            "Speed: 1.6ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.9ms\n",
            "Speed: 1.3ms preprocess, 11.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.7ms\n",
            "Speed: 1.7ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 1.3ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.1ms\n",
            "Speed: 2.9ms preprocess, 11.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.3ms\n",
            "Speed: 1.5ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.3ms\n",
            "Speed: 1.4ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 13.6ms\n",
            "Speed: 1.4ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.6ms\n",
            "Speed: 1.5ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.7ms\n",
            "Speed: 1.3ms preprocess, 11.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 11.3ms\n",
            "Speed: 1.3ms preprocess, 11.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.0ms\n",
            "Speed: 2.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.6ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.5ms\n",
            "Speed: 1.5ms preprocess, 8.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.8ms\n",
            "Speed: 1.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.8ms\n",
            "Speed: 1.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.5ms\n",
            "Speed: 1.5ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 10.2ms\n",
            "Speed: 1.4ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.6ms\n",
            "Speed: 1.6ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.8ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.4ms\n",
            "Speed: 1.3ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.5ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.2ms\n",
            "Speed: 4.4ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 14.4ms\n",
            "Speed: 1.2ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 12.3ms\n",
            "Speed: 1.3ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 9.3ms\n",
            "Speed: 1.6ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 7.9ms\n",
            "Speed: 1.5ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.1ms\n",
            "Speed: 1.6ms preprocess, 8.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 8.6ms\n",
            "Speed: 1.7ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}